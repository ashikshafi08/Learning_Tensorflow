{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "🛠 10. Time series fundamentals and Milestone Project 3: BitPredict 💰📈 Exercise Solutions.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOkEWYw5rbOWaD+TGgS8aJu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning_Tensorflow/blob/main/%F0%9F%9B%A0_10_Time_series_fundamentals_and_Milestone_Project_3_BitPredict_%F0%9F%92%B0%F0%9F%93%88_Exercise_Solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9BhPZ1Tx4bm"
      },
      "source": [
        "# 🛠 10. Time series fundamentals and Milestone Project 3: BitPredict 💰📈 Exercise Solutions \n",
        "\n",
        "1. Does scaling the data help for univariate/multivariate data? (e.g. getting all of the values between 0 & 1)\n",
        "    * Try doing this for a univariate model (e.g. model_1) and a multivariate model (e.g. model_6) and see if it effects model training or evaluation results.\n",
        "2. Get the most up to date data on Bitcoin, train a model & see how it goes (our data goes up to May 18 2021).\n",
        "    * You can download the Bitcoin historical data for free from  [coindesk.com/price/bitcoin](https://www.coindesk.com/price/bitcoin)  and clicking “Export Data” -> “CSV”.\n",
        "3. For most of our models we used WINDOW_SIZE=7, but is there a better window size?\n",
        "    * Setup a series of experiments to find whether or not there’s a better window size.\n",
        "    * For example, you might train 10 different models with HORIZON=1 but with window sizes ranging from 2-12.\n",
        "4. Create a windowed dataset just like the ones we used for model_1 using  [tf.keras.preprocessing.timeseries_dataset_from_array()](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/timeseries_dataset_from_array)  and retrain model_1 using the recreated dataset.\n",
        "5. For our multivariate modelling experiment, we added the Bitcoin block reward size as an extra feature to make our time series multivariate.\n",
        "    * Are there any other features you think you could add?\n",
        "    * If so, try it out, how do these affect the model?\n",
        "6. Make prediction intervals for future forecasts. To do so, one way would be to train an ensemble model on all of the data, make future forecasts with it and calculate the prediction intervals of the ensemble just like we did for model_8.\n",
        "7. For future predictions, try to make a prediction, retrain a model on the predictions, make a prediction, retrain a model, make a prediction, retrain a model, make a prediction (retrain a model each time a new prediction is made). Plot the results, how do they look compared to the future predictions where a model wasn’t retrained for every forecast (model_9)?\n",
        "8. Throughout this notebook, we’ve only tried algorithms we’ve handcrafted ourselves. But it’s worth seeing how a purpose built forecasting algorithm goes.\n",
        "    * Try out one of the extra algorithms listed in the modelling experiments part such as:\n",
        "\t*  [Facebook’s Kats library](https://github.com/facebookresearch/Kats)  - there are many models in here, remember the machine learning practioner’s motto: experiment, experiment, experiment.\n",
        "\t*  [LinkedIn’s Greykite library](https://github.com/linkedin/greykite) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VT9614RIyCCl"
      },
      "source": [
        "## Downloading the data and preprocessing it "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "aZe0Y63IyQgT",
        "outputId": "01ff4afc-a1a0-48f0-efb1-5c6fedfb50c7"
      },
      "source": [
        "# Download Bitcoin historical data from GitHub \n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\n",
        "\n",
        "# Import with pandas \n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\", \n",
        "                 parse_dates=[\"Date\"], \n",
        "                 index_col=[\"Date\"]) # parse the date column (tell pandas column 1 is a datetime)\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-11 06:09:45--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 178509 (174K) [text/plain]\n",
            "Saving to: ‘BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv’\n",
            "\n",
            "\r          BTC_USD_2   0%[                    ]       0  --.-KB/s               \rBTC_USD_2013-10-01_ 100%[===================>] 174.33K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2021-09-11 06:09:46 (73.5 MB/s) - ‘BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv’ saved [178509/178509]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Currency</th>\n",
              "      <th>Closing Price (USD)</th>\n",
              "      <th>24h Open (USD)</th>\n",
              "      <th>24h High (USD)</th>\n",
              "      <th>24h Low (USD)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-01</th>\n",
              "      <td>BTC</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>124.30466</td>\n",
              "      <td>124.75166</td>\n",
              "      <td>122.56349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-02</th>\n",
              "      <td>BTC</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>125.75850</td>\n",
              "      <td>123.63383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-03</th>\n",
              "      <td>BTC</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>125.66566</td>\n",
              "      <td>83.32833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-04</th>\n",
              "      <td>BTC</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>118.67500</td>\n",
              "      <td>107.05816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-05</th>\n",
              "      <td>BTC</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>121.93633</td>\n",
              "      <td>118.00566</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Currency  Closing Price (USD)  ...  24h High (USD)  24h Low (USD)\n",
              "Date                                      ...                               \n",
              "2013-10-01      BTC            123.65499  ...       124.75166      122.56349\n",
              "2013-10-02      BTC            125.45500  ...       125.75850      123.63383\n",
              "2013-10-03      BTC            108.58483  ...       125.66566       83.32833\n",
              "2013-10-04      BTC            118.67466  ...       118.67500      107.05816\n",
              "2013-10-05      BTC            121.33866  ...       121.93633      118.00566\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LQW1xGSyYDv",
        "outputId": "8783c734-5738-4e13-8cb7-7b4782d6c786"
      },
      "source": [
        "# Only want closing price for each day \n",
        "bitcoin_prices = pd.DataFrame(df[\"Closing Price (USD)\"]).rename(columns={\"Closing Price (USD)\": \"Price\"})\n",
        "bitcoin_prices.head() , bitcoin_prices.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                Price\n",
              " Date                 \n",
              " 2013-10-01  123.65499\n",
              " 2013-10-02  125.45500\n",
              " 2013-10-03  108.58483\n",
              " 2013-10-04  118.67466\n",
              " 2013-10-05  121.33866, (2787, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIlIWPTWD6z_"
      },
      "source": [
        "# Get the data in array \n",
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import layers\n",
        "\n",
        "timesteps = bitcoin_prices.index.to_numpy()\n",
        "prices = bitcoin_prices['Price'].to_numpy()\n",
        "\n",
        "# Instantiating the sklearn MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler() "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eynNXXID68q"
      },
      "source": [
        "# Create function to view NumPy arrays as windows \n",
        "\n",
        "def get_labelled_windows(x , horizon):\n",
        "  return x[:, :-horizon] ,x[: , -horizon:]\n",
        "\n",
        "\n",
        "def make_windows_scaled(x, window_size=7, horizon=1):\n",
        "  \"\"\"\n",
        "  Turns a 1D array into a 2D array of sequential windows of window_size. Also applies the standard scaler\n",
        "  \"\"\"\n",
        "  scaler.fit(np.expand_dims(x , axis =1))\n",
        "  scaled_x = scaler.transform(np.expand_dims(x , axis = 1))\n",
        "  scaled_x = np.squeeze(scaled_x)\n",
        "  \n",
        "  window_step = np.expand_dims(np.arange(window_size+horizon), axis=0)\n",
        "  window_indexes = window_step + np.expand_dims(np.arange(len(scaled_x)-(window_size+horizon-1)), axis=0).T # create 2D array of windows of size window_size\n",
        "  windowed_array = scaled_x[window_indexes]\n",
        "  windows, labels = get_labelled_windows(windowed_array, horizon=horizon)\n",
        "\n",
        "  return windows, labels\n",
        "\n",
        "\n",
        "# Make the splits \n",
        "def make_train_test_splits(windows , labels , test_split = 0.2):\n",
        "  split_size = int(len(windows) * (1 - test_split))\n",
        "  train_windows = windows[:split_size]\n",
        "  train_labels = labels[:split_size]\n",
        "  test_windows = windows[split_size:]\n",
        "  test_labels = labels[split_size:]\n",
        "\n",
        "  return train_windows ,  test_windows ,train_labels,  test_labels"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dItohLM1Ozr"
      },
      "source": [
        "### 1. Does scaling the data help for univariate/multivariate data? (e.g. getting all of the values between 0 & 1)\n",
        "* Try doing this for a univariate model (e.g. model_1) and a multivariate model (e.g. model_6) and see if it effects model training or evaluation results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S-J_3Tkzfto",
        "outputId": "d925d051-7bdd-4cde-d6bd-d358df0dac7c"
      },
      "source": [
        "# Model 1 (Horizon = 1 , Window_size = 7)\n",
        "HORIZON = 1 \n",
        "WINDOW_SIZE = 7 \n",
        "\n",
        "\n",
        "full_windows , full_labels = make_windows_scaled(prices , window_size = WINDOW_SIZE , horizon = HORIZON)\n",
        "full_windows.shape , full_labels.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2780, 7), (2780, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL8e6Iz9NOUX",
        "outputId": "a11b0525-20b0-4488-b3a4-afb830b25c79"
      },
      "source": [
        "# Looking at few examples of how price is scaled\n",
        "for i in range(3):\n",
        "  print(f'Window: {full_windows[i]} --> Label {full_labels[i]}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Window: [0.00023831 0.00026677 0.         0.00015955 0.00020168 0.00019087\n",
            " 0.0002089 ] --> Label [0.00022847]\n",
            "Window: [0.00026677 0.         0.00015955 0.00020168 0.00019087 0.0002089\n",
            " 0.00022847] --> Label [0.00024454]\n",
            "Window: [0.         0.00015955 0.00020168 0.00019087 0.0002089  0.00022847\n",
            " 0.00024454] --> Label [0.00027478]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmHd26QZFZDU",
        "outputId": "6eb0ce2e-e93e-4b88-8c8b-7308ec95a096"
      },
      "source": [
        "# Making train and test splits \n",
        "train_windows , test_windows , train_labels , test_labels = make_train_test_splits(full_windows , full_labels)\n",
        "len(train_windows), len(test_windows), len(train_labels), len(test_labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2224, 556, 2224, 556)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2dT3_hqyejt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "045a14fa-2a07-45d5-d88f-4d202a2351ab"
      },
      "source": [
        "# Building the Model 1 \n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Construct the model \n",
        "model_1 = tf.keras.Sequential([\n",
        "  layers.Dense(128, activation= 'relu') ,\n",
        "  layers.Dense(HORIZON , activation = 'linear')\n",
        "])\n",
        "\n",
        "# Compiling the model \n",
        "model_1.compile(loss = 'mae' , \n",
        "                optimizer = tf.keras.optimizers.Adam() , \n",
        "                metrics = ['mae'])\n",
        "\n",
        "# Fit the model \n",
        "model_1.fit(x = train_windows , \n",
        "            y = train_labels , \n",
        "            epochs = 100 , batch_size = 128 , verbose = 0 , \n",
        "            validation_data = (test_windows , test_labels))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d9732ae10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MwuA2gI0t2B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd36928-544b-43fd-8234-911612f4d985"
      },
      "source": [
        "# Evaluate the model on test data \n",
        "model_1.evaluate(test_windows , test_labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 1ms/step - loss: 0.0093 - mae: 0.0093\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.00931711308658123, 0.00931711308658123]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh7sqPOjNo8V"
      },
      "source": [
        "model_1_preds = tf.squeeze(model_1.predict(test_windows))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMNXeHUWXcEI"
      },
      "source": [
        "Now doing the same for the Multivariate data especially for the Model 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "6HoW1S6TXhvD",
        "outputId": "25fb3a6d-4ddb-48e0-b34a-a2de230f708f"
      },
      "source": [
        "# Block reward values\n",
        "block_reward_1 = 50 # 3 January 2009 \n",
        "block_reward_2 = 25 # 28 November 2012 \n",
        "block_reward_3 = 12.5 # 9 July 2016\n",
        "block_reward_4 = 6.25 # 11 May 2020\n",
        "\n",
        "# Block reward dates (datetime form of the above date stamps)\n",
        "block_reward_2_datetime = np.datetime64(\"2012-11-28\")\n",
        "block_reward_3_datetime = np.datetime64(\"2016-07-09\")\n",
        "block_reward_4_datetime = np.datetime64(\"2020-05-11\")\n",
        "\n",
        "# Get date indexes for when to add in different block dates\n",
        "block_reward_2_days = (block_reward_3_datetime - bitcoin_prices.index[0]).days\n",
        "block_reward_3_days = (block_reward_4_datetime - bitcoin_prices.index[0]).days\n",
        "block_reward_2_days, block_reward_3_days\n",
        "\n",
        "# Add block_reward column\n",
        "bitcoin_prices_block = bitcoin_prices.copy()\n",
        "bitcoin_prices_block[\"block_reward\"] = None\n",
        "\n",
        "# Set values of block_reward column (it's the last column hence -1 indexing on iloc)\n",
        "bitcoin_prices_block.iloc[:block_reward_2_days, -1] = block_reward_2\n",
        "bitcoin_prices_block.iloc[block_reward_2_days:block_reward_3_days, -1] = block_reward_3\n",
        "bitcoin_prices_block.iloc[block_reward_3_days:, -1] = block_reward_4\n",
        "bitcoin_prices_block.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>block_reward</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-01</th>\n",
              "      <td>123.65499</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-02</th>\n",
              "      <td>125.45500</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-03</th>\n",
              "      <td>108.58483</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-04</th>\n",
              "      <td>118.67466</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-05</th>\n",
              "      <td>121.33866</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Price block_reward\n",
              "Date                              \n",
              "2013-10-01  123.65499           25\n",
              "2013-10-02  125.45500           25\n",
              "2013-10-03  108.58483           25\n",
              "2013-10-04  118.67466           25\n",
              "2013-10-05  121.33866           25"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "4NQkP9EmX2Xt",
        "outputId": "216415b3-3c44-4e52-96bb-6e1414886638"
      },
      "source": [
        "# Make a copy of the Bitcoin historical data with block reward feature\n",
        "bitcoin_prices_windowed = bitcoin_prices_block.copy()\n",
        "\n",
        "# Add windowed columns\n",
        "for i in range(WINDOW_SIZE): \n",
        "  bitcoin_prices_windowed[f\"Price+{i+1}\"] = bitcoin_prices_windowed[\"Price\"].shift(periods=i+1)\n",
        "bitcoin_prices_windowed.head(10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>block_reward</th>\n",
              "      <th>Price+1</th>\n",
              "      <th>Price+2</th>\n",
              "      <th>Price+3</th>\n",
              "      <th>Price+4</th>\n",
              "      <th>Price+5</th>\n",
              "      <th>Price+6</th>\n",
              "      <th>Price+7</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-01</th>\n",
              "      <td>123.65499</td>\n",
              "      <td>25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-02</th>\n",
              "      <td>125.45500</td>\n",
              "      <td>25</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-03</th>\n",
              "      <td>108.58483</td>\n",
              "      <td>25</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-04</th>\n",
              "      <td>118.67466</td>\n",
              "      <td>25</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-05</th>\n",
              "      <td>121.33866</td>\n",
              "      <td>25</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-06</th>\n",
              "      <td>120.65533</td>\n",
              "      <td>25</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-07</th>\n",
              "      <td>121.79500</td>\n",
              "      <td>25</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-08</th>\n",
              "      <td>123.03300</td>\n",
              "      <td>25</td>\n",
              "      <td>121.79500</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-09</th>\n",
              "      <td>124.04900</td>\n",
              "      <td>25</td>\n",
              "      <td>123.03300</td>\n",
              "      <td>121.79500</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-10</th>\n",
              "      <td>125.96116</td>\n",
              "      <td>25</td>\n",
              "      <td>124.04900</td>\n",
              "      <td>123.03300</td>\n",
              "      <td>121.79500</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Price block_reward    Price+1  ...    Price+5    Price+6    Price+7\n",
              "Date                                           ...                                 \n",
              "2013-10-01  123.65499           25        NaN  ...        NaN        NaN        NaN\n",
              "2013-10-02  125.45500           25  123.65499  ...        NaN        NaN        NaN\n",
              "2013-10-03  108.58483           25  125.45500  ...        NaN        NaN        NaN\n",
              "2013-10-04  118.67466           25  108.58483  ...        NaN        NaN        NaN\n",
              "2013-10-05  121.33866           25  118.67466  ...        NaN        NaN        NaN\n",
              "2013-10-06  120.65533           25  121.33866  ...  123.65499        NaN        NaN\n",
              "2013-10-07  121.79500           25  120.65533  ...  125.45500  123.65499        NaN\n",
              "2013-10-08  123.03300           25  121.79500  ...  108.58483  125.45500  123.65499\n",
              "2013-10-09  124.04900           25  123.03300  ...  118.67466  108.58483  125.45500\n",
              "2013-10-10  125.96116           25  124.04900  ...  121.33866  118.67466  108.58483\n",
              "\n",
              "[10 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "73jAFAVeYpD-",
        "outputId": "9fa4ab23-e39c-40f3-d1b0-97a17ac27b1f"
      },
      "source": [
        "# Let's create X & y, remove the NaN's and convert to float32 to prevent TensorFlow errors \n",
        "X = bitcoin_prices_windowed.dropna().drop(\"Price\", axis=1).astype(np.float32) \n",
        "y = bitcoin_prices_windowed.dropna()[\"Price\"].astype(np.float32)\n",
        "X.head()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>block_reward</th>\n",
              "      <th>Price+1</th>\n",
              "      <th>Price+2</th>\n",
              "      <th>Price+3</th>\n",
              "      <th>Price+4</th>\n",
              "      <th>Price+5</th>\n",
              "      <th>Price+6</th>\n",
              "      <th>Price+7</th>\n",
              "      <th>day_of_week</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-08</th>\n",
              "      <td>25.0</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>108.584831</td>\n",
              "      <td>125.455002</td>\n",
              "      <td>123.654991</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-09</th>\n",
              "      <td>25.0</td>\n",
              "      <td>123.032997</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>108.584831</td>\n",
              "      <td>125.455002</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-10</th>\n",
              "      <td>25.0</td>\n",
              "      <td>124.049004</td>\n",
              "      <td>123.032997</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>108.584831</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-11</th>\n",
              "      <td>25.0</td>\n",
              "      <td>125.961159</td>\n",
              "      <td>124.049004</td>\n",
              "      <td>123.032997</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-12</th>\n",
              "      <td>25.0</td>\n",
              "      <td>125.279663</td>\n",
              "      <td>125.961159</td>\n",
              "      <td>124.049004</td>\n",
              "      <td>123.032997</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            block_reward     Price+1  ...     Price+7  day_of_week\n",
              "Date                                  ...                         \n",
              "2013-10-08          25.0  121.794998  ...  123.654991          1.0\n",
              "2013-10-09          25.0  123.032997  ...  125.455002          2.0\n",
              "2013-10-10          25.0  124.049004  ...  108.584831          3.0\n",
              "2013-10-11          25.0  125.961159  ...  118.674660          4.0\n",
              "2013-10-12          25.0  125.279663  ...  121.338661          5.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SdPXx_SauLC"
      },
      "source": [
        "# Scaling the X data \n",
        "X_scaled = scaler.fit_transform(X)\n",
        "y_scaled = scaler.fit_transform(np.expand_dims(y , axis = 1))\n",
        "y_scaled = np.squeeze(y_scaled)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M8UVLaIa1km",
        "outputId": "a45ac9c7-9ba6-467b-8a85-dbde3b8979d1"
      },
      "source": [
        "# Make train and test sets\n",
        "split_size = int(len(X) * 0.8)\n",
        "X_train, y_train = X_scaled[:split_size], y_scaled[:split_size]\n",
        "X_test, y_test = X_scaled[split_size:], y_scaled[split_size:]\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2224, 2224, 556, 556)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sXgRZ1Ka-TT",
        "outputId": "19fd9826-9452-4dce-9090-a23eafbcb1f2"
      },
      "source": [
        "# Building a Multivariate time series model and fitting it\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model_6 = tf.keras.Sequential([\n",
        "  layers.Dense(128 , activation= 'relu'), \n",
        "  layers.Dense(HORIZON)\n",
        "])\n",
        "\n",
        "model_6.compile(loss = 'mae' , \n",
        "                optimizer = tf.keras.optimizers.Adam())\n",
        "\n",
        "model_6.fit(X_train , y_train , \n",
        "          epochs = 100 ,\n",
        "          verbose = 0 , batch_size = 128, \n",
        "          validation_data = (X_test , y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d92b95690>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs_ZDtr1b3-N",
        "outputId": "67f8ea8e-71f8-4231-d117-9bc0b62ff092"
      },
      "source": [
        "# Evaluate the model 6 \n",
        "model_6.evaluate(X_test , y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 1ms/step - loss: 0.0735\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07352113723754883"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqlPT_dXfuQf"
      },
      "source": [
        "### 2. Get the most up to date data on Bitcoin, train a model & see how it goes (our data goes up to May 18 2021)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUKI8td_b_F_",
        "outputId": "af03e9e5-c737-421d-e071-8763e0d22fbb"
      },
      "source": [
        "# Loading the in the latest csv from Coindesk\n",
        "df_updated = pd.read_csv('/content/BTC_USD_2014-11-02_2021-09-09-CoinDesk.csv' , \n",
        "                 parse_dates = ['Date'] , \n",
        "                 index_col = ['Date'])\n",
        "\n",
        "bitcoin_prices_updated = pd.DataFrame(df_updated[\"Closing Price (USD)\"]).rename(columns={\"Closing Price (USD)\": \"Price\"})\n",
        "bitcoin_prices_updated.head(10) , bitcoin_prices_updated.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                Price\n",
              " Date                 \n",
              " 2014-11-02  325.22633\n",
              " 2014-11-03  331.60083\n",
              " 2014-11-04  324.71833\n",
              " 2014-11-05  332.45666\n",
              " 2014-11-06  336.58500\n",
              " 2014-11-07  346.77500\n",
              " 2014-11-08  344.81166\n",
              " 2014-11-09  343.06500\n",
              " 2014-11-10  358.50166\n",
              " 2014-11-11  368.07666, (2503, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52OylhbEiIII"
      },
      "source": [
        "prices_updated = bitcoin_prices_updated['Price'].to_numpy()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZYgYStegy7E"
      },
      "source": [
        "def make_windows(x, window_size=7, horizon=1):\n",
        "  \"\"\"\n",
        "  Turns a 1D array into a 2D array of sequential windows of window_size.\n",
        "  \"\"\"\n",
        "  \n",
        "  window_step = np.expand_dims(np.arange(window_size+horizon), axis=0)\n",
        "  window_indexes = window_step + np.expand_dims(np.arange(len(x)-(window_size+horizon-1)), axis=0).T # create 2D array of windows of size window_size\n",
        "  windowed_array = x[window_indexes]\n",
        "  windows, labels = get_labelled_windows(windowed_array, horizon=horizon)\n",
        "\n",
        "  return windows, labels"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBzAx_9nhfGF",
        "outputId": "0a5507ea-3bde-4b9f-ac9e-390dd319f9cb"
      },
      "source": [
        "full_windows , full_labels = make_windows(prices_updated)\n",
        "len(full_windows), len(full_labels)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2496, 2496)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ5Iir7jvLeY",
        "outputId": "00f33b4f-8b5b-4751-b92c-4459661c0f34"
      },
      "source": [
        "# Looking at few examples of how price is scaled\n",
        "for i in range(3):\n",
        "  print(f'Window: {full_windows[i]} --> Label {full_labels[i]}')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Window: [325.22633 331.60083 324.71833 332.45666 336.585   346.775   344.81166] --> Label [343.065]\n",
            "Window: [331.60083 324.71833 332.45666 336.585   346.775   344.81166 343.065  ] --> Label [358.50166]\n",
            "Window: [324.71833 332.45666 336.585   346.775   344.81166 343.065   358.50166] --> Label [368.07666]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HCIuZdxh-GC",
        "outputId": "2d30caaf-604f-4874-ce80-689bc48a9a3c"
      },
      "source": [
        "# Making train and test splits\n",
        "train_windows ,  test_windows ,train_labels,  test_labels =  make_train_test_splits(full_windows , full_labels)\n",
        "\n",
        "len(train_windows) ,  len(test_windows) , len(train_labels),  len(test_labels) "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1996, 500, 1996, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1Ve_RGCm5Ez"
      },
      "source": [
        "Now we're building the same Model 1 with the new coindesk data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IytoXshkhJE",
        "outputId": "808913f1-6a23-4f7c-b04d-bb622da47cad"
      },
      "source": [
        "# Building the Model 1 with the updated data\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Construct the model \n",
        "model_1 = tf.keras.Sequential([\n",
        "  layers.Dense(128, activation= 'relu') ,\n",
        "  layers.Dense(HORIZON , activation = 'linear')\n",
        "])\n",
        "\n",
        "# Compiling the model \n",
        "model_1.compile(loss = 'mae' , \n",
        "                optimizer = tf.keras.optimizers.Adam() , \n",
        "                metrics = ['mae'])\n",
        "\n",
        "# Fit the model \n",
        "model_1.fit(x = train_windows , \n",
        "            y = train_labels , \n",
        "            epochs = 100 , batch_size = 128 , verbose = 0 , \n",
        "            validation_data = (test_windows , test_labels))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d973cb210>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq-4_z0rm_Gc",
        "outputId": "d0579474-a3c6-423e-b132-926c3d0093a8"
      },
      "source": [
        "# Evaluating the model \n",
        "model_1.evaluate(test_windows , test_labels)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 1ms/step - loss: 884.0138 - mae: 884.0138\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[884.0137939453125, 884.0137939453125]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIuiLp-PnYlS"
      },
      "source": [
        "### 3. For most of our models we used WINDOW_SIZE=7, but is there a better window size?\n",
        "\n",
        "* Setup a series of experiments to find whether or not there’s a better window size.\n",
        "* For example, you might train 10 different models with HORIZON=1 but with window sizes ranging from 2-12."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P08KPQgG6op2"
      },
      "source": [
        "# Writing a evaluation function based on the preds and targets \n",
        "def evaluate_preds(y_true , y_pred):\n",
        "\n",
        "  # Casting the values to float32 \n",
        "  y_true = tf.cast(y_true , tf.float32)\n",
        "  y_pred = tf.cast(y_pred , tf.float32)\n",
        "\n",
        "\n",
        "  # Calculate the metrics \n",
        "  mae = tf.keras.metrics.mean_absolute_error(y_true , y_pred)\n",
        "  mse = tf.keras.metrics.mean_squared_error(y_true , y_pred)\n",
        "  rmse = tf.sqrt(mse)\n",
        "  mape = tf.keras.metrics.mean_absolute_percentage_error(y_true , y_pred)\n",
        "  \n",
        "  # For longer horizons \n",
        "  if mae.ndim > 0:\n",
        "    mae = tf.reduce_sum(mae)\n",
        "    mse = tf.reduce_sum(mse)\n",
        "    rmse = tf.reduce_sum(rmse)\n",
        "    mape = tf.reduce_sum(mape)\n",
        "\n",
        "  return {'mae' : mae.numpy() , \n",
        "          'mse': mse.numpy() , \n",
        "          'rmse': rmse.numpy() , \n",
        "          'mape': mape.numpy() }"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x11lEVED6d9A",
        "outputId": "57a99294-3eb4-4d9c-9fdb-6649443c50d1"
      },
      "source": [
        "# Writing a for loop to iterate over the Window size and build 10 different models\n",
        "\n",
        "# 10 Different models with window size ranging from (2 - 12) and store the results\n",
        "model_results_list = []\n",
        "\n",
        "from tqdm import tqdm\n",
        "for size in tqdm(range(2,12)):\n",
        "  HORIZON = 1 \n",
        "  WINDOW_SIZE = size\n",
        "\n",
        "  # Making window and labels \n",
        "  full_windows , full_labels = make_windows(prices, window_size= WINDOW_SIZE , horizon= HORIZON)\n",
        "  \n",
        "\n",
        "  # Splitting the data in train and test\n",
        "  train_windows ,  test_windows ,train_labels,  test_labels = make_train_test_splits(full_windows , full_labels)\n",
        "\n",
        "\n",
        "  # Building a simple dense model\n",
        "  input = layers.Input(shape = (WINDOW_SIZE ,) , name = 'Input_layer')\n",
        "  x = layers.Dense(128 , activation= 'relu')(input)\n",
        "  output = layers.Dense(HORIZON , activation= 'linear')(x)\n",
        "\n",
        "  # Packing into a model \n",
        "  model = tf.keras.Model(input , output , name = f'model_windowed_{size}')\n",
        "\n",
        "  # Compiling and fitting the model \n",
        "  model.compile(loss = 'mae' , optimizer = 'adam' , metrics = 'mae')\n",
        "\n",
        "  model.fit(train_windows , train_labels , \n",
        "            epochs = 100 , verbose = 0 , \n",
        "            batch_size = 128 , \n",
        "            validation_data = (test_windows , test_labels))\n",
        "  \n",
        "\n",
        "  # Making predictions \n",
        "  preds_ = model.predict(test_windows)\n",
        "  y_preds = tf.squeeze(preds_)\n",
        "\n",
        "  results = evaluate_preds(tf.squeeze(test_labels) , y_preds)\n",
        "  model_results_list.append(results)\n",
        " "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:51<00:00,  5.18s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qyp-2gqoUipn",
        "outputId": "8acb0d4e-9991-45da-d248-7ae1b6339ac2"
      },
      "source": [
        "# Below are the 10 different models result \n",
        "model_results_list"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'mae': 569.1506, 'mape': 2.5277913, 'mse': 1159396.5, 'rmse': 1076.7528},\n",
              " {'mae': 565.61, 'mape': 2.5274613, 'mse': 1139677.6, 'rmse': 1067.5569},\n",
              " {'mae': 623.44543, 'mape': 2.8342037, 'mse': 1266272.0, 'rmse': 1125.2875},\n",
              " {'mae': 565.61096, 'mape': 2.5193882, 'mse': 1157946.9, 'rmse': 1076.0793},\n",
              " {'mae': 575.82715, 'mape': 2.5713227, 'mse': 1181491.9, 'rmse': 1086.9645},\n",
              " {'mae': 624.65094, 'mape': 2.8559413, 'mse': 1279308.5, 'rmse': 1131.0652},\n",
              " {'mae': 673.8483, 'mape': 3.1560009, 'mse': 1401001.9, 'rmse': 1183.6393},\n",
              " {'mae': 661.0718, 'mape': 3.0542161, 'mse': 1343192.1, 'rmse': 1158.9617},\n",
              " {'mae': 583.37537, 'mape': 2.6407204, 'mse': 1204248.0, 'rmse': 1097.3823},\n",
              " {'mae': 701.84753, 'mape': 3.2888033, 'mse': 1443914.4, 'rmse': 1201.6299}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzH981vjL-fT"
      },
      "source": [
        "### 4. Create a windowed dataset just like the ones we used for model_1 using  [tf.keras.preprocessing.timeseries_dataset_from_array()](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/timeseries_dataset_from_array)  and retrain model_1 using the recreated dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcRI4RcIYnYE"
      },
      "source": [
        "WINDOW_SIZE = 7 \n",
        "HORIZON = 1"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zakDAvtCY32O"
      },
      "source": [
        "# Make the splits \n",
        "def make_train_test_splits(windows , labels , test_split = 0.2):\n",
        "  split_size = int(len(windows) * (1 - test_split))\n",
        "  train_windows = windows[:split_size]\n",
        "  train_labels = labels[:split_size]\n",
        "  test_windows = windows[split_size:]\n",
        "  test_labels = labels[split_size:]\n",
        "\n",
        "  return train_windows ,  test_windows ,train_labels,  test_labels"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujv0D7izXNhn"
      },
      "source": [
        "ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    data = prices , targets = prices , sequence_length = WINDOW_SIZE , sequence_stride = HORIZON, \n",
        "    batch_size = 128\n",
        ")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha5sXVH-ctoF"
      },
      "source": [
        "train_size , test_size = int(0.8 * len(ds)) ,int(0.2 * len(ds))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlzXwk84cxp6"
      },
      "source": [
        "train_ds = ds.take(train_size)\n",
        "test_ds = ds.skip(train_size).take(test_size)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcTn-l1Idl3t",
        "outputId": "215a2147-f9d4-4551-d7c7-f4003b47671f"
      },
      "source": [
        "for x , y in train_ds.take(1):\n",
        "  print(x[:2] , y[:2])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[123.65499 125.455   108.58483 118.67466 121.33866 120.65533 121.795  ]\n",
            " [125.455   108.58483 118.67466 121.33866 120.65533 121.795   123.033  ]], shape=(2, 7), dtype=float64) tf.Tensor([123.65499 125.455  ], shape=(2,), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuP5_htZduAu",
        "outputId": "2922db66-c8b8-4be8-d18a-758ce7b25535"
      },
      "source": [
        "for x , y in test_ds.take(1):\n",
        "  print(x[:2] , y[:2])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[10302.19071368 10301.65965169 10231.42151196 10168.28770938\n",
            "  10223.5055788  10138.33520522  9984.52051597]\n",
            " [10301.65965169 10231.42151196 10168.28770938 10223.5055788\n",
            "  10138.33520522  9984.52051597 10031.86670899]], shape=(2, 7), dtype=float64) tf.Tensor([10302.19071368 10301.65965169], shape=(2,), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4VD9kgYdyCB",
        "outputId": "cf8f2926-d962-4aa5-e0ec-88d28b193b07"
      },
      "source": [
        "len(test_ds) + len(train_ds)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkBv9LaBeAc4",
        "outputId": "0f3fb8d6-1e4e-4d50-83c3-586719c40835"
      },
      "source": [
        "len(test_ds) , test_size"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieBAnXs0eJAy",
        "outputId": "54b2e4f7-a5ab-4fc8-8784-06eb8f42ec2c"
      },
      "source": [
        "# Building the Model 1 with the updated data\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Building a simple dense model\n",
        "input = layers.Input(shape = (WINDOW_SIZE ,) , name = 'Input_layer' , dtype = tf.float32)\n",
        "x = layers.Dense(128 , activation= 'relu')(input)\n",
        "output = layers.Dense(HORIZON , activation= 'linear')(x)\n",
        "\n",
        "# Packing into a model \n",
        "model = tf.keras.Model(input , output)\n",
        "\n",
        "# Compiling the model \n",
        "model.compile(loss = 'mae' , \n",
        "                optimizer = tf.keras.optimizers.Adam() , \n",
        "                metrics = ['mae'])\n",
        "\n",
        "# Fit the model \n",
        "model.fit(train_ds ,\n",
        "          epochs = 100 , verbose = 0 , \n",
        "            validation_data = test_ds)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d9679fbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPBtfK2diAkV",
        "outputId": "b5720b04-ebac-4208-8190-2798a10b0567"
      },
      "source": [
        "model.evaluate(test_ds)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 21ms/step - loss: 643.4305 - mae: 643.4305\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[643.4305419921875, 643.4305419921875]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GONHDDlhwKr"
      },
      "source": [
        "### 5. For our multivariate modelling experiment, we added the Bitcoin block reward size as an extra feature to make our time series multivariate.\n",
        "\n",
        "  * Are there any other features you think you could add?\n",
        "  * If so, try it out, how do these affect the model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA-51-MMxzNO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "outputId": "5d20c957-37c8-4f85-8513-e71d4f1dcce2"
      },
      "source": [
        "df"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Currency</th>\n",
              "      <th>Closing Price (USD)</th>\n",
              "      <th>24h Open (USD)</th>\n",
              "      <th>24h High (USD)</th>\n",
              "      <th>24h Low (USD)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-01</th>\n",
              "      <td>BTC</td>\n",
              "      <td>123.654990</td>\n",
              "      <td>124.304660</td>\n",
              "      <td>124.751660</td>\n",
              "      <td>122.563490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-02</th>\n",
              "      <td>BTC</td>\n",
              "      <td>125.455000</td>\n",
              "      <td>123.654990</td>\n",
              "      <td>125.758500</td>\n",
              "      <td>123.633830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-03</th>\n",
              "      <td>BTC</td>\n",
              "      <td>108.584830</td>\n",
              "      <td>125.455000</td>\n",
              "      <td>125.665660</td>\n",
              "      <td>83.328330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-04</th>\n",
              "      <td>BTC</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>108.584830</td>\n",
              "      <td>118.675000</td>\n",
              "      <td>107.058160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-05</th>\n",
              "      <td>BTC</td>\n",
              "      <td>121.338660</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>121.936330</td>\n",
              "      <td>118.005660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-14</th>\n",
              "      <td>BTC</td>\n",
              "      <td>49764.132082</td>\n",
              "      <td>49596.778891</td>\n",
              "      <td>51448.798576</td>\n",
              "      <td>46294.720180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-15</th>\n",
              "      <td>BTC</td>\n",
              "      <td>50032.693137</td>\n",
              "      <td>49717.354353</td>\n",
              "      <td>51578.312545</td>\n",
              "      <td>48944.346536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-16</th>\n",
              "      <td>BTC</td>\n",
              "      <td>47885.625255</td>\n",
              "      <td>49926.035067</td>\n",
              "      <td>50690.802950</td>\n",
              "      <td>47005.102292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-17</th>\n",
              "      <td>BTC</td>\n",
              "      <td>45604.615754</td>\n",
              "      <td>46805.537852</td>\n",
              "      <td>49670.414174</td>\n",
              "      <td>43868.638969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-18</th>\n",
              "      <td>BTC</td>\n",
              "      <td>43144.471291</td>\n",
              "      <td>46439.336570</td>\n",
              "      <td>46622.853437</td>\n",
              "      <td>42102.346430</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2787 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Currency  Closing Price (USD)  ...  24h High (USD)  24h Low (USD)\n",
              "Date                                      ...                               \n",
              "2013-10-01      BTC           123.654990  ...      124.751660     122.563490\n",
              "2013-10-02      BTC           125.455000  ...      125.758500     123.633830\n",
              "2013-10-03      BTC           108.584830  ...      125.665660      83.328330\n",
              "2013-10-04      BTC           118.674660  ...      118.675000     107.058160\n",
              "2013-10-05      BTC           121.338660  ...      121.936330     118.005660\n",
              "...             ...                  ...  ...             ...            ...\n",
              "2021-05-14      BTC         49764.132082  ...    51448.798576   46294.720180\n",
              "2021-05-15      BTC         50032.693137  ...    51578.312545   48944.346536\n",
              "2021-05-16      BTC         47885.625255  ...    50690.802950   47005.102292\n",
              "2021-05-17      BTC         45604.615754  ...    49670.414174   43868.638969\n",
              "2021-05-18      BTC         43144.471291  ...    46622.853437   42102.346430\n",
              "\n",
              "[2787 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMRA5-nVmPnh"
      },
      "source": [
        "import datetime "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPIsz7vSms_7",
        "outputId": "db3e343e-37be-45f1-b9f7-39bba3703c4e"
      },
      "source": [
        "df.index[0].day_of"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Timestamp('2013-10-01 00:00:00')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "VtYlinvCm8EQ",
        "outputId": "263890f8-2650-4451-f6a6-56c201799e1e"
      },
      "source": [
        "df['day_of_week'] = df.index.dayofweek\n",
        "df.head(10)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Currency</th>\n",
              "      <th>Closing Price (USD)</th>\n",
              "      <th>24h Open (USD)</th>\n",
              "      <th>24h High (USD)</th>\n",
              "      <th>24h Low (USD)</th>\n",
              "      <th>day_of_week</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-01</th>\n",
              "      <td>BTC</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>124.30466</td>\n",
              "      <td>124.75166</td>\n",
              "      <td>122.56349</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-02</th>\n",
              "      <td>BTC</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>125.75850</td>\n",
              "      <td>123.63383</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-03</th>\n",
              "      <td>BTC</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>125.66566</td>\n",
              "      <td>83.32833</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-04</th>\n",
              "      <td>BTC</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>118.67500</td>\n",
              "      <td>107.05816</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-05</th>\n",
              "      <td>BTC</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>121.93633</td>\n",
              "      <td>118.00566</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-06</th>\n",
              "      <td>BTC</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>121.85216</td>\n",
              "      <td>120.55450</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-07</th>\n",
              "      <td>BTC</td>\n",
              "      <td>121.79500</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.99166</td>\n",
              "      <td>120.43199</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-08</th>\n",
              "      <td>BTC</td>\n",
              "      <td>123.03300</td>\n",
              "      <td>121.79500</td>\n",
              "      <td>123.64016</td>\n",
              "      <td>121.35066</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-09</th>\n",
              "      <td>BTC</td>\n",
              "      <td>124.04900</td>\n",
              "      <td>123.03300</td>\n",
              "      <td>124.78350</td>\n",
              "      <td>122.59266</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-10</th>\n",
              "      <td>BTC</td>\n",
              "      <td>125.96116</td>\n",
              "      <td>124.04900</td>\n",
              "      <td>128.01683</td>\n",
              "      <td>123.81966</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Currency  Closing Price (USD)  ...  24h Low (USD)  day_of_week\n",
              "Date                                      ...                            \n",
              "2013-10-01      BTC            123.65499  ...      122.56349            1\n",
              "2013-10-02      BTC            125.45500  ...      123.63383            2\n",
              "2013-10-03      BTC            108.58483  ...       83.32833            3\n",
              "2013-10-04      BTC            118.67466  ...      107.05816            4\n",
              "2013-10-05      BTC            121.33866  ...      118.00566            5\n",
              "2013-10-06      BTC            120.65533  ...      120.55450            6\n",
              "2013-10-07      BTC            121.79500  ...      120.43199            0\n",
              "2013-10-08      BTC            123.03300  ...      121.35066            1\n",
              "2013-10-09      BTC            124.04900  ...      122.59266            2\n",
              "2013-10-10      BTC            125.96116  ...      123.81966            3\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppVyHOd9pZUC"
      },
      "source": [
        "# Defining the hyper parameters \n",
        "HORIZON = 1 \n",
        "WINDOW_SIZE = 7 \n",
        "\n",
        "bitcoin_prices_windowed['day_of_week'] = bitcoin_prices_windowed.index.dayofweek"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6zN_LcoqCca"
      },
      "source": [
        "# Getting three kinds of data (univariate , multivariate and the day of week)\n",
        "\n",
        "# Univariate data \n",
        "full_windows , full_labels = make_windows_scaled(prices)\n",
        "train_windows , test_windows , train_labels , test_labels = make_train_test_splits(full_windows , full_labels)\n",
        "\n",
        "# Multivaritate dat \n",
        "X = bitcoin_prices_windowed.dropna().drop('Price' , axis = 1).astype(np.float32)\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "y = bitcoin_prices_windowed.dropna()['Price'].astype(np.float32)\n",
        "\n",
        "# Day of week \n",
        "day_of_week = bitcoin_prices_windowed.dropna()['day_of_week'].to_list()"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YCJnEBEzj69",
        "outputId": "0476b879-8acf-4fee-bdbb-4cfe0afe0cf1"
      },
      "source": [
        "# Checking the shapes \n",
        "print(full_windows.shape , full_labels.shape)\n",
        "print(X.shape , y.shape)\n",
        "print(len(day_of_week))"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2780, 7) (2780, 1)\n",
            "(2780, 9) (2780,)\n",
            "2780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvJBEkZR4XVp",
        "outputId": "73065803-f751-48fa-ca83-0393b22ff085"
      },
      "source": [
        "# Splitting the multivariate and the day_of_week to train and test splits \n",
        "split_size = int(len(X) * 0.8)\n",
        "train_block_rewards , test_block_rewards = X[:split_size] , X[split_size:]\n",
        "train_days , test_days = day_of_week[:split_size] , day_of_week[split_size:]\n",
        " \n",
        "len(train_block_rewards), len(train_days) , len(test_block_rewards) , len(test_days)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2224, 2224, 556, 556)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQd1NpWSzke0",
        "outputId": "eb24cf82-1acc-4692-ef41-e443c8985c79"
      },
      "source": [
        "# Building a performant dataset for train and test \n",
        "\n",
        "train_data_tribid = tf.data.Dataset.from_tensor_slices((train_windows , \n",
        "                                                        train_block_rewards , \n",
        "                                                        train_days))\n",
        "\n",
        "train_labels_tribid = tf.data.Dataset.from_tensor_slices(train_labels)\n",
        "\n",
        "# The test/val split \n",
        "test_data_tribid = tf.data.Dataset.from_tensor_slices((test_windows , \n",
        "                                                       test_block_rewards , \n",
        "                                                       test_days))\n",
        "\n",
        "test_labels_tribid = tf.data.Dataset.from_tensor_slices(test_labels)\n",
        "\n",
        "# Zipping the data and labels into one complete dataset \n",
        "tribid_train_ds = tf.data.Dataset.zip((train_data_tribid , train_labels_tribid))\n",
        "tribid_test_ds = tf.data.Dataset.zip((test_data_tribid , test_labels_tribid))\n",
        "\n",
        "# Applying prefetch and batching the dataset \n",
        "tribid_train_ds = tribid_train_ds.batch(128).prefetch(tf.data.AUTOTUNE)\n",
        "tribid_test_ds = tribid_test_ds.batch(128).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "tribid_train_ds ,tribid_test_ds"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PrefetchDataset shapes: (((None, 7), (None, 9), (None,)), (None, 1)), types: ((tf.float64, tf.float32, tf.int32), tf.float64)>,\n",
              " <PrefetchDataset shapes: (((None, 7), (None, 9), (None,)), (None, 1)), types: ((tf.float64, tf.float32, tf.int32), tf.float64)>)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyhukkUSzmu8",
        "outputId": "1a0f1095-b275-468e-f361-57a6836090fd"
      },
      "source": [
        "# Building a tribid model \n",
        "\n",
        "input_windows = layers.Input(shape = (7,) , dtype=tf.float64 , name='Window Inputs')\n",
        "exp_layer_1 = layers.Lambda(lambda x: tf.expand_dims(x , axis = 1))(input_windows)\n",
        "conv1 = layers.Conv1D(filters= 32 , kernel_size=5 , padding='causal' , activation= 'relu')(exp_layer_1)\n",
        "window_model = tf.keras.Model(input_windows , conv1 , name = 'Windowed model')\n",
        "\n",
        "input_blocks = layers.Input(shape = (9,) , dtype= tf.float32 , name ='Block rewards input')\n",
        "exp_layer_2 = layers.Lambda(lambda x: tf.expand_dims(x , axis = 1))(input_blocks)\n",
        "conv2 = layers.Conv1D(filters = 32 , kernel_size= 5 , activation= 'relu' , padding = 'causal')(exp_layer_2)\n",
        "block_model = tf.keras.Model(input_blocks , conv2 , name = 'Block rewards model')\n",
        "\n",
        "\n",
        "# Use expand dims to match the same shape output (None , 1 , 128)\n",
        "# whereas without expand dims it would be (None , 128)\n",
        "input_days = layers.Input(shape= (1,) , dtype = tf.int32 , name ='Days of week Input')\n",
        "exp_layer_3 = layers.Lambda(lambda x: tf.expand_dims(x , axis = 1))(input_days)\n",
        "dense = layers.Dense(128 , activation= 'relu')(exp_layer_3)\n",
        "days_model = tf.keras.Model(input_days , dense , name = 'Days Model')\n",
        "\n",
        "# Concatenating the inputs \n",
        "concat = layers.Concatenate(name = 'combined_outputs' )([window_model.output , \n",
        "                                                           block_model.output , \n",
        "                                                           days_model.output])\n",
        "\n",
        "# Creating the output layer \n",
        "dropout = layers.Dropout(0.4)(concat)\n",
        "output_layer = layers.Dense(1 , activation = 'linear')(dropout)\n",
        "\n",
        "# Putting everything into a model \n",
        "tribid_model = tf.keras.Model(inputs = [window_model.input , \n",
        "                                        block_model.input , \n",
        "                                        days_model.input] , \n",
        "                              outputs = output_layer)\n",
        "tribid_model.summary()\n",
        "\n"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Window Inputs (InputLayer)      [(None, 7)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Block rewards input (InputLayer [(None, 9)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Days of week Input (InputLayer) [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_26 (Lambda)              (None, 1, 7)         0           Window Inputs[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_27 (Lambda)              (None, 1, 9)         0           Block rewards input[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "lambda_28 (Lambda)              (None, 1, 1)         0           Days of week Input[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_19 (Conv1D)              (None, 1, 32)        1152        lambda_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_20 (Conv1D)              (None, 1, 32)        1472        lambda_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 1, 128)       256         lambda_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "combined_outputs (Concatenate)  (None, 1, 192)       0           conv1d_19[0][0]                  \n",
            "                                                                 conv1d_20[0][0]                  \n",
            "                                                                 dense_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 1, 192)       0           combined_outputs[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 1, 1)         193         dropout_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 3,073\n",
            "Trainable params: 3,073\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDB8vFtu17Rp",
        "outputId": "62457f54-50a8-4fda-a94c-8bcc9b83bce6"
      },
      "source": [
        "# Compiling and fitting the model \n",
        "tribid_model.compile(loss = 'mae' , \n",
        "                     optimizer = 'adam' , metrics = ['mae'])\n",
        "\n",
        "# Fitting the model \n",
        "tribid_model.fit(tribid_train_ds , \n",
        "                 epochs = 20,  \n",
        "                 validation_data = tribid_test_ds , verbose = 2)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "18/18 - 1s - loss: 29.1395 - mae: 29.1395 - val_loss: 12.8604 - val_mae: 12.8604\n",
            "Epoch 2/20\n",
            "18/18 - 0s - loss: 5.7451 - mae: 5.7451 - val_loss: 7.9342 - val_mae: 7.9342\n",
            "Epoch 3/20\n",
            "18/18 - 0s - loss: 1.1152 - mae: 1.1152 - val_loss: 3.3295 - val_mae: 3.3295\n",
            "Epoch 4/20\n",
            "18/18 - 0s - loss: 0.4115 - mae: 0.4115 - val_loss: 0.4594 - val_mae: 0.4594\n",
            "Epoch 5/20\n",
            "18/18 - 0s - loss: 0.8504 - mae: 0.8504 - val_loss: 1.9727 - val_mae: 1.9727\n",
            "Epoch 6/20\n",
            "18/18 - 0s - loss: 1.0429 - mae: 1.0429 - val_loss: 0.7200 - val_mae: 0.7200\n",
            "Epoch 7/20\n",
            "18/18 - 0s - loss: 0.8757 - mae: 0.8757 - val_loss: 2.0799 - val_mae: 2.0799\n",
            "Epoch 8/20\n",
            "18/18 - 0s - loss: 0.2225 - mae: 0.2225 - val_loss: 0.0813 - val_mae: 0.0813\n",
            "Epoch 9/20\n",
            "18/18 - 0s - loss: 0.1704 - mae: 0.1704 - val_loss: 0.1398 - val_mae: 0.1398\n",
            "Epoch 10/20\n",
            "18/18 - 0s - loss: 0.1544 - mae: 0.1544 - val_loss: 0.0908 - val_mae: 0.0908\n",
            "Epoch 11/20\n",
            "18/18 - 0s - loss: 0.1410 - mae: 0.1410 - val_loss: 0.0821 - val_mae: 0.0821\n",
            "Epoch 12/20\n",
            "18/18 - 0s - loss: 0.1284 - mae: 0.1284 - val_loss: 0.0624 - val_mae: 0.0624\n",
            "Epoch 13/20\n",
            "18/18 - 0s - loss: 0.1218 - mae: 0.1218 - val_loss: 0.0647 - val_mae: 0.0647\n",
            "Epoch 14/20\n",
            "18/18 - 0s - loss: 0.1086 - mae: 0.1086 - val_loss: 0.0442 - val_mae: 0.0442\n",
            "Epoch 15/20\n",
            "18/18 - 0s - loss: 0.1053 - mae: 0.1053 - val_loss: 0.0582 - val_mae: 0.0582\n",
            "Epoch 16/20\n",
            "18/18 - 0s - loss: 0.0953 - mae: 0.0953 - val_loss: 0.0374 - val_mae: 0.0374\n",
            "Epoch 17/20\n",
            "18/18 - 0s - loss: 0.0892 - mae: 0.0892 - val_loss: 0.0437 - val_mae: 0.0437\n",
            "Epoch 18/20\n",
            "18/18 - 0s - loss: 0.0774 - mae: 0.0774 - val_loss: 0.0319 - val_mae: 0.0319\n",
            "Epoch 19/20\n",
            "18/18 - 0s - loss: 0.0723 - mae: 0.0723 - val_loss: 0.0304 - val_mae: 0.0304\n",
            "Epoch 20/20\n",
            "18/18 - 0s - loss: 0.0643 - mae: 0.0643 - val_loss: 0.0296 - val_mae: 0.0296\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d8be37250>"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzCKgn8598cB",
        "outputId": "1fc41717-e8ed-42c0-c26b-c7e2e2583c4b"
      },
      "source": [
        "# Evaluating the model \n",
        "tribid_model.evaluate(tribid_test_ds)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0296 - mae: 0.0296\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.029597144573926926, 0.029597144573926926]"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaqbrn-xnnjW"
      },
      "source": [
        "### 6. Make prediction intervals for future forecasts. To do so, one way would be to train an ensemble model on all of the data, make future forecasts with it and calculate the prediction intervals of the ensemble just like we did for model_8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuGAuQZpovQ9"
      },
      "source": [
        "**Things to do**\n",
        "- Train an ensemble model on the whole data. \n",
        "- Make one dataset (no test/valid) which will use to predict future forecasts of bitcoins. \n",
        "- Make a function that will take the number of iterations and different loss functions to train the model with. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS_NBQuqt5Bb",
        "outputId": "225deabc-f652-4419-c00f-cfe613eeef23"
      },
      "source": [
        "# Make one whole dataset (with the updated bitcoin prices 2014 - 2021)\n",
        "\n",
        "full_windows , full_labels = make_windows(prices_updated , horizon= 1 , window_size= 7)\n",
        "\n",
        "whole_ds = tf.data.Dataset.from_tensor_slices((full_windows , full_labels))\n",
        "whole_ds = whole_ds.batch(128).prefetch(tf.data.AUTOTUNE)\n",
        "whole_ds"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, 7), (None, 1)), types: (tf.float64, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5zZCOdSvBDX"
      },
      "source": [
        "# Creating the function \n",
        "\n",
        "def get_ensemble_models(horizon = HORIZON , \n",
        "                        dataset = whole_ds , \n",
        "                        num_iter = 10 , \n",
        "                        num_epochs = 100 , \n",
        "                        loss_fns = ['mae' , 'mse' , 'mape']):\n",
        "  \n",
        "\n",
        "  # Make a empty list of the ensemble models \n",
        "  ensemble_models = []\n",
        "\n",
        "  # Create num_iter number of models per loss functions \n",
        "  for i in range(num_iter):\n",
        "    for loss_functions in loss_fns:\n",
        "      print(f'Optimizing model by reducing: {loss_functions} for {num_epochs} epochs, model number: {i}')\n",
        "\n",
        "      model = tf.keras.Sequential([\n",
        "          layers.Dense(128 , kernel_initializer='he_normal' , activation= 'relu'),\n",
        "          layers.Dense(128 , kernel_initializer= 'he_normal', activation= 'relu'),\n",
        "          layers.Dense(HORIZON)\n",
        "      ])\n",
        "\n",
        "      # Compiling the model \n",
        "      model.compile(loss = loss_functions , \n",
        "                    optimizer = 'adam' , metrics = ['mae' , 'mse'])\n",
        "      \n",
        "      # Fit the model \n",
        "      model.fit(dataset , \n",
        "                epochs = num_epochs , \n",
        "                verbose = 0,\n",
        "                callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"loss\",\n",
        "                                                            patience=200,\n",
        "                                                            restore_best_weights=True),\n",
        "                           tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\",\n",
        "                                                                patience=100,\n",
        "                                                                verbose=1)])\n",
        "      \n",
        "      ensemble_models.append(model)\n",
        "\n",
        "  return ensemble_models"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btGEQNfLvCXL",
        "outputId": "7cf8a15e-752b-4260-f4e1-dea4b249c223"
      },
      "source": [
        "# Running the above function \n",
        "ensemble_models = get_ensemble_models(num_iter= 5 , num_epochs= 1000)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizing model by reducing: mae for 1000 epochs, model number: 0\n",
            "\n",
            "Epoch 00216: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00350: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 00925: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Optimizing model by reducing: mse for 1000 epochs, model number: 0\n",
            "\n",
            "Epoch 00397: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00563: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mape for 1000 epochs, model number: 0\n",
            "\n",
            "Epoch 00266: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00368: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 00470: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "\n",
            "Epoch 00575: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "\n",
            "Epoch 00771: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "\n",
            "Epoch 00872: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
            "\n",
            "Epoch 00972: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
            "Optimizing model by reducing: mae for 1000 epochs, model number: 1\n",
            "\n",
            "Epoch 00128: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Optimizing model by reducing: mse for 1000 epochs, model number: 1\n",
            "\n",
            "Epoch 00741: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00945: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mape for 1000 epochs, model number: 1\n",
            "\n",
            "Epoch 00138: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00241: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 00343: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "\n",
            "Epoch 00445: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "\n",
            "Epoch 00647: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "\n",
            "Epoch 00748: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
            "\n",
            "Epoch 00848: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
            "\n",
            "Epoch 00948: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
            "Optimizing model by reducing: mae for 1000 epochs, model number: 2\n",
            "\n",
            "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00245: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mse for 1000 epochs, model number: 2\n",
            "\n",
            "Epoch 00117: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00426: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mape for 1000 epochs, model number: 2\n",
            "\n",
            "Epoch 00381: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00481: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mae for 1000 epochs, model number: 3\n",
            "\n",
            "Epoch 00461: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00563: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mse for 1000 epochs, model number: 3\n",
            "\n",
            "Epoch 00546: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00810: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mape for 1000 epochs, model number: 3\n",
            "\n",
            "Epoch 00301: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00401: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mae for 1000 epochs, model number: 4\n",
            "\n",
            "Epoch 00224: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00324: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mse for 1000 epochs, model number: 4\n",
            "\n",
            "Epoch 00354: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00531: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 00631: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Optimizing model by reducing: mape for 1000 epochs, model number: 4\n",
            "\n",
            "Epoch 00137: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00237: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWO1PFiAyowS"
      },
      "source": [
        "# Function to make preds on the ensemble model \n",
        "def make_ensemble_preds(ensemble_models , data):\n",
        "  ensemble_preds = []\n",
        "  for model in ensemble_models:\n",
        "    preds = model.predict(data)\n",
        "    ensemble_preds.append(preds)\n",
        "\n",
        "  return tf.constant(tf.squeeze(ensemble_preds))\n"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM4bW2EN__jH"
      },
      "source": [
        "# Making future forecastts \n",
        "def make_future_forecast(values , model_list , into_future , window_size):\n",
        "\n",
        "  future_forecast = []\n",
        "  last_window = values[-window_size:]\n",
        "\n",
        "  for _ in range(into_future):\n",
        "    for model in model_list:\n",
        "\n",
        "      future_pred = model.predict(tf.expand_dims(last_window , axis = 0))\n",
        "      #print(f'Predicing on: \\n {last_window} --> Prediction: ')\n",
        "\n",
        "      future_forecast.append(tf.squeeze(future_pred).numpy())\n",
        "\n",
        "      # Update the last window \n",
        "      last_window = np.append(last_window , future_pred)[-window_size]\n",
        "  return future_forecast"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "id": "TNvFrcqFJOV1",
        "outputId": "c637bfd3-ebd6-4b23-a3de-e95ac266fad6"
      },
      "source": [
        "make_future_forecast(full_labels , ensemble_models , \n",
        "                     into_future = 14 , \n",
        "                     window_size = 7)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-167-92a2ae0c1e51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m make_future_forecast(full_labels , ensemble_models , \n\u001b[1;32m      2\u001b[0m                      \u001b[0minto_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m14\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                      window_size = 7)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-165-8a6402970b73>\u001b[0m in \u001b[0;36mmake_future_forecast\u001b[0;34m(values, model_list, into_future, window_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0mfuture_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_window\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0;31m#print(f'Predicing on: \\n {last_window} --> Prediction: ')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1749\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1537 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py:254 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential_5 is incompatible with the layer: expected axis -1 of input shape to have value 7 but received input with shape (None, 7, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63Y4_KX7JQQy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}