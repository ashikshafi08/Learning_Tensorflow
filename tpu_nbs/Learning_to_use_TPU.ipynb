{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learning_to_use_TPU.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQBLX67ocr70Yu0yMKn8VI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning_Tensorflow/blob/main/tpu_nbs/Learning_to_use_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Vi8c0ohSYsJR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf \n",
        "import os \n",
        "import json \n",
        "import pprint\n",
        "import tensorflow_datasets as tfds "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating TF Records \n",
        "\n",
        "\n",
        "- TFRecord format is a simple format for storing a sequence of binary records. \n",
        "- Protocol messages are defined by .proto files, these are often "
      ],
      "metadata": {
        "id": "WXOcKnw0vfFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bunch of data processing \n",
        "root_dir = \"datasets\"\n",
        "tfrecords_dir = \"tfrecords\"\n",
        "images_dir = os.path.join(root_dir, \"val2017\")\n",
        "annotations_dir = os.path.join(root_dir, \"annotations\")\n",
        "annotation_file = os.path.join(annotations_dir, \"instances_val2017.json\")\n",
        "images_url = \"http://images.cocodataset.org/zips/val2017.zip\"\n",
        "annotations_url = (\n",
        "    \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
        ")\n",
        "\n",
        "# Download image files\n",
        "if not os.path.exists(images_dir):\n",
        "    image_zip = tf.keras.utils.get_file(\n",
        "        \"images.zip\", cache_dir=os.path.abspath(\".\"), origin=images_url, extract=True,\n",
        "    )\n",
        "    os.remove(image_zip)\n",
        "\n",
        "# Download caption annotation files\n",
        "if not os.path.exists(annotations_dir):\n",
        "    annotation_zip = tf.keras.utils.get_file(\n",
        "        \"captions.zip\",\n",
        "        cache_dir=os.path.abspath(\".\"),\n",
        "        origin=annotations_url,\n",
        "        extract=True,\n",
        "    )\n",
        "    os.remove(annotation_zip)\n",
        "\n",
        "print(\"The COCO dataset has been downloaded and extracted successfully.\")\n",
        "\n",
        "with open(annotation_file, \"r\") as f:\n",
        "    annotations = json.load(f)[\"annotations\"]\n",
        "\n",
        "print(f\"Number of images: {len(annotations)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt5tO-KY0YZC",
        "outputId": "1d70c748-4976-4d6a-eaa8-0981c34e74af"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The COCO dataset has been downloaded and extracted successfully.\n",
            "Number of images: 36781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(annotations[60])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWRu0gJ_0uMn",
        "outputId": "b6d7cdb5-1f1b-4753-fbaa-ebcbcaa618a6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'area': 367.89710000000014,\n",
            " 'bbox': [265.67, 222.31, 26.48, 14.71],\n",
            " 'category_id': 72,\n",
            " 'id': 34096,\n",
            " 'image_id': 525083,\n",
            " 'iscrowd': 0,\n",
            " 'segmentation': [[267.51,\n",
            "                   222.31,\n",
            "                   292.15,\n",
            "                   222.31,\n",
            "                   291.05,\n",
            "                   237.02,\n",
            "                   265.67,\n",
            "                   237.02]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_annotations = len(annotations)  # number of samples in the dataset\n",
        " \n",
        "# Number of data samples on each tf records \n",
        "num_samples = 4096 \n",
        "\n",
        "# Total number of tfrecords we will create \n",
        "num_tfrecords = len_annotations // num_samples\n",
        "print(f'Total number of tfrecords we will be creating {num_tfrecords}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deOFb2KUvfQm",
        "outputId": "77a56f4c-0797-486b-8cf3-fbd941b0c56e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of tfrecords we will be creating 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If any samples missing create a tf record for it \n",
        "if annot % num_samples: \n",
        "  num_tfrecords += 1 # add one record if there are remaining samples left \n",
        "\n",
        "num_tfrecords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXZ0_ITKvfTT",
        "outputId": "5951c287-302b-4daf-f087-e20d2b7f41a8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "tfrecords_dir = \"tfrecords\"\n",
        "\n",
        "# If there is no directory of tfrecords, thenn create it \n",
        "if not os.path.exists(tfrecords_dir):\n",
        "  os.makedirs(tfrecords_dir)"
      ],
      "metadata": {
        "id": "9yLfMsR8vfYX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Writing out TFRecords Helper Functions \n",
        "\n",
        "- Our data should be serialized (encoded as byte string) before bering written with a TFRecord. \n",
        "- The most convenient way of serializing our data is to wrap them with `tf.Example`.\n",
        "- Its more or less like a `dict` with some type of annotations. \n",
        "\n",
        "\n",
        "### Serialization \n",
        "\n",
        "- TFRecord -> is a kind of file that TensorFlow uses to store binary data. \n",
        "- TFRecords contain sequences of byte-strings. \n"
      ],
      "metadata": {
        "id": "K0CrOWbdvfcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifying the path for tfrecords \n",
        "path = 'data/data.tfrecord'\n",
        "\n",
        "\n",
        "\n",
        "with tf.io.TFRecordWriter(path = path) as f:\n",
        "   f.write(b'123') # write one record \n",
        "   f.write(b'xyzb123') # another record \n",
        "\n",
        "\n",
        "# Opening the file we've just written \n",
        "with open(path , 'rb') as f:\n",
        "  print(f.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t7iLo6Gvfgr",
        "outputId": "7634005b-125a-45f1-c125-a714f61cc74e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xb0\\x99I\\x0e123\\xce\\x0b\\xe7\\x01\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xbb\\xd7\\x9f\\x11xyzb123\\xee\\x88\\x11v'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eefj-YfAvfl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "T0zCVyvJvfpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nEmq0nALvfus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-MOD4lRwvfyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FMH8Vll3vhxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JiqPbBaPvh4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wTrv_WuJvh9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pZ_8RJM1viEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KFVwMGAIviIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dhX0tEQhviMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "z8-EHI_YviQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5H_8jh9yviXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VMYPxUF6vicv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training with TPU's "
      ],
      "metadata": {
        "id": "KOSTCq93vaMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TPU Initilization \n",
        "\n",
        "- TPU's are typically cloud TPU workers. \n",
        "- To work with TPU first we gotta initialize and connect to the remote cluster. We can do this by using `tf.distribute.cluster_resolver.TPUClusterResolver`"
      ],
      "metadata": {
        "id": "3Un2i0QlY2RM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the TPU \n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='') # responsible for making TPU clusters with GCP\n",
        "tf.config.experimental_connect_to_cluster(resolver) # connecting to the cloud instance\n",
        "\n",
        "# Initializing the TPU \n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "\n",
        "# Listing out all the TPU's available\n",
        "print(f\"All Devices: {tf.config.list_logical_devices('TPU')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Rc-K0FPZJVB",
        "outputId": "72c6e87c-24d7-4346-db49-9e6339deff7b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.125.18.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.125.18.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.125.18.82:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.125.18.82:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Devices: [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using manual placement and using one tpu for our computation. There are 8 cores available. "
      ],
      "metadata": {
        "id": "XkeaV2czZxQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "\n",
        "\n",
        "with tf.device('/TPU:0'):\n",
        "  c = tf.matmul(a , b)\n",
        "\n",
        "print(f'C Device: {c.device}')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL8GsnXBayKY",
        "outputId": "a0001695-cc92-47d4-d7b7-9b3c727491f3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C Device: /job:worker/replica:0/task:0/device:TPU:0\n",
            "tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Distribution Strategies \n",
        "\n",
        "- While training the model we run it on multiple TPU's in a data-parallel way. \n",
        "- We got 8 cores of TPU and we can run our computation on each of them parallely. \n",
        "- TensorFlow offers several distribution strategies. We will use `tf.distribute.TPUStrategy` that will lets us run tensors on TPUs. \n",
        "\n"
      ],
      "metadata": {
        "id": "9W72irmZa8vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an object of the distributive strategy \n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsWsLA-sbzkA",
        "outputId": "d9d76481-6e32-4963-b476-f6c7d46d20c2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the distribution strategies, the variable created within the strategy's scope will be replicated across all the replicas and can kept in sync during all-reduce algo. "
      ],
      "metadata": {
        "id": "vLcrnbjKcdz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# It should print out 8 times \n",
        "\n",
        "@tf.function \n",
        "def matmul_fn(x , y):\n",
        "  return tf.matmul(x , y)\n",
        "\n",
        "\n",
        "# Running on the tpu strategy where it replicate's the function 8 times \n",
        "# Pass in the function  + arguments for the function\n",
        "z = strategy.run(fn = matmul_fn , args = (a , b))\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NruKdNN5dGXs",
        "outputId": "b0c0a9cf-6d3b-4528-dfd4-340027bbf89a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PerReplica:{\n",
            "  0: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  1: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  2: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  3: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  4: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  5: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  6: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  7: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32)\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that after counting the output we get to know that it has been ran 8 times, because of 8 cores TPU we're running the function on each single TPU's \n"
      ],
      "metadata": {
        "id": "s1wzWG8aeSrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification on TPU's \n",
        "\n",
        "\n",
        "We will use the above strategy to train a Keras Classification model. \n",
        "\n",
        "> **Note**: Keras **model creation** needs to be inside the `strategy.scope` so that the variable can be created on each TPU device. Its more enabling the switch for our model to let it use the TPU services. \n",
        "\n",
        "Rest code can be outside of the `strategy.scope`"
      ],
      "metadata": {
        "id": "-3t09j4wepHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Sequential model\n",
        "\n",
        "def create_model():\n",
        "  return tf.keras.Sequential(\n",
        "      [tf.keras.layers.Conv2D(256, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "       tf.keras.layers.Conv2D(256, 3, activation='relu'),\n",
        "       tf.keras.layers.Flatten(),\n",
        "       tf.keras.layers.Dense(256, activation='relu'),\n",
        "       tf.keras.layers.Dense(128, activation='relu'),\n",
        "       tf.keras.layers.Dense(10)])"
      ],
      "metadata": {
        "id": "DN7rwAYkfaPf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the dataset \n",
        "\n",
        "- Wbile using the Cloud TPU we gotta be efficient while making a dataset with `tf.data.Dataset`, its impossible for the Cloud TPU's to work unless if we feed the data into tf.data.Dataset API real qucik. \n",
        "- "
      ],
      "metadata": {
        "id": "bV6zmyn-ff9x"
      }
    }
  ]
}