{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Customization with TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqOKe2z5lJM8DpV+UBt2Hq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning_Tensorflow/blob/main/Customization_with_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68GrDlsd35hH"
      },
      "source": [
        "This notebook will contains the code and concepts from the TensorFlow documentation on customization. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3Ze4HvCy8M-"
      },
      "source": [
        "## Eager Execution in TensorFlow \n",
        "\n",
        "TensorFlow's eager execution is an imperative programming environment that evaluates the operation immediately, without building graphs. \n",
        "\n",
        "> Operations return concrete values instead of constructing a computational graph to run later. \n",
        "\n",
        "\n",
        "Eager execution is flexible because of the following reasons: \n",
        "\n",
        "- An intuitive interface. \n",
        "- Easier debugging, use standard python debugging tools for immediate error reporting. \n",
        "- Natural control flow, using pythons control flow instead of graph control flow. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcwljHr4y8xW",
        "outputId": "99265fe1-03ca-42d9-8026-4f5beec39cf3"
      },
      "source": [
        "# Enabling the eager execution \n",
        "import tensorflow as tf \n",
        "tf.executing_eagerly()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1YZYkoTy83C"
      },
      "source": [
        "# We get the results immediately \n",
        "x = [[2.]]\n",
        "m = tf.matmul(x, x)\n",
        "print(\"hello, {}\".format(m))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMZGh1Jty9De"
      },
      "source": [
        "Enabling eafer execution changes how TensorFlow operations behave,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLmNAaDfy9PK"
      },
      "source": [
        "# TensorFlow imports\n",
        "import timeit\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "\n",
        "# Model building\n",
        "inputs = Input(shape=(28, 28)) \n",
        "x = Flatten()(inputs) \n",
        "x = Dense(256, \"relu\")(x)\n",
        "x = Dense(256, \"relu\")(x) \n",
        "x = Dense(256, \"relu\")(x) \n",
        "outputs = Dense(10, \"softmax\")(x) \n",
        "\n",
        "input_data = tf.random.uniform([100, 28, 28])\n",
        "\n",
        "# Eager Execution\n",
        "eager_model = Model(inputs=inputs, outputs=outputs)\n",
        "print(\"Eager time:\", timeit.timeit(lambda: eager_model(input_data), number=10000))\n",
        "\n",
        "#Graph Execution \n",
        "graph_model = tf.function(eager_model) # Wrap the model with tf.function \n",
        "print(\"Graph time:\", timeit.timeit(lambda: graph_model(input_data), number=10000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMBPMWp-y9f4"
      },
      "source": [
        "Eager execution is fine for building small models and rapid experimentation. But when have a complex and large model we can opt for Graph execution. \n",
        "\n",
        "In reality graph execution might be slower but more efficient than the eager execution. The default execution of TensorFlow 2x + is eager execution and we can opt for graph execution using the `tf.function()` can make graphs out of our programs. \n",
        "\n",
        "\n",
        "The `tf.function()` converts a Python function to its graph representation. So we add the `@tf.function` at top before the code or wrap the eager execution function. \n",
        "\n",
        "This will help you create performant and portable models, and it is required to use `SavedModel`.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4_8lRwgy9tF"
      },
      "source": [
        "@tf.function\n",
        "def add(a , b):\n",
        "  return a + b \n",
        "\n",
        "add(tf.ones([2, 2]) , tf.ones([2, 2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJmsxVM7y94Q"
      },
      "source": [
        "v = tf.Variable(5.0)\n",
        "\n",
        "# Using automatic differentiation \n",
        "with tf.GradientTape() as tape:\n",
        "  result = add(a = v , b = 5.0)\n",
        "tape.gradient(result , v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS6NI0Byy99c"
      },
      "source": [
        "**Why we use `tf.Variable` while creating the weights in a neural net?** \n",
        "\n",
        "The values produced by the `tf.Tensor` are immutable and we can't modify them. And we cant use these regular tensors to implement weights in a neural network and they get changed during the back prop. \n",
        "\n",
        "So thats why we use `tf.Variable`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0zOUN4Hy-JP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "901qbKD6y-UX"
      },
      "source": [
        "# Creating a tensor with tf.variable \n",
        "v = tf.Variable([[1, 2, 3,], [4 ,5 ,6]])\n",
        "v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F55HlgR5y-bd"
      },
      "source": [
        "v.assign(2 * v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9XlcbHSMs97"
      },
      "source": [
        " # Assigning in a index \n",
        " v[0 , 1].assign(14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDlRn5ZFMtCU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfhMYYfJMtK9"
      },
      "source": [
        "tf.strings.to_number('8448')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhvVnNQSMtQp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX4RMyVUMtaX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB0uSQ2iMthu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECKpeJZxMtnu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITmhBprjMtvQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-VHoWeU6A48"
      },
      "source": [
        "### Customization basics: Tensors and operations \n",
        "\n",
        "- Import the required package\n",
        "- Create and use tensors\n",
        "- Use GPU acceleration\n",
        "- Demonstrate tf.data.Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW70Jp5w6uQc"
      },
      "source": [
        "##### Tensors \n",
        "A tensor is a multi-dimensional array, which is of dtype `tf.Tensor` and has a shape. \n",
        "\n",
        "The `tf.tensor` can reside in GPU accelerator and we can use regular tensor operations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFGwYaze7lpz"
      },
      "source": [
        "import tensorflow as tf "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sxmVbpq7qZl"
      },
      "source": [
        "tf.square(2) + tf.square(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlO0lEbQ72eL"
      },
      "source": [
        "# Each tf.tensor has a shappe and a datatype \n",
        "x = tf.matmul([[1]] , [[2,3]])\n",
        "\n",
        "x.shape  , x.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz0aCe5S8ItL"
      },
      "source": [
        "Converting between a TensorFlow `tf.Tensor`s and a Numpy `ndarray` is easy: \n",
        "\n",
        "- Tensorflow operations automatically convert Numpy ndarrays to Tensors \n",
        "- Numpy operations automatically convert Tensors to Numpy ndarrays. \n",
        "\n",
        "Tensors are explicitly converted to Numpy ndarrays using their `.numpy()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo20ZQWI8ZDJ"
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "ndarray = np.ones([3 ,3])\n",
        "tensor = tf.multiply(ndarray , 42)\n",
        "print(f'{tensor} \\n')\n",
        "\n",
        "# Using the numpy operations to convrt tensors to numpy arrays \n",
        "print(f'{np.add(tensor , 1)}\\n')\n",
        "\n",
        "print(f'{tensor.numpy()}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im5Stl-F-pCT"
      },
      "source": [
        "TensorFlow automatically decides which device to execute an operation and copies tensors to the devices, if needed. \n",
        "\n",
        "> TensorFlow operations can be expilictly places on a specific devices using the `tf.device` context manager. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk_mJ9ZRAzUr"
      },
      "source": [
        "import time \n",
        "\n",
        "def time_matmul(x):\n",
        "  start = time.time()\n",
        "  for loop in range(10):\n",
        "    tf.matmul(x, x)\n",
        "\n",
        "  result = time.time() - start \n",
        "\n",
        "  print(\"10 loops: {:0.2f}ms\".format(1000*result))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVATiS_UBA4S"
      },
      "source": [
        "# Force execution on CPU \n",
        "print('On CPU:')\n",
        "\n",
        "with tf.device('CPU:0'):\n",
        "  x = tf.random.uniform([1000 , 1000])\n",
        "  assert x.device.endswith('CPU:0')\n",
        "  time_matmul(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybjQy3bzBNc7"
      },
      "source": [
        "# Forece execution on GPU (running on gpu)\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "  print('On GPU:')\n",
        "  with tf.device('GPU:0'): \n",
        "    x = tf.random.uniform([1000 , 1000])\n",
        "    assert x.device.endswith('GPU:0')\n",
        "    time_matmul(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smjbg4E6B_WO"
      },
      "source": [
        "## Custom Layers \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TbI2ZsrT55e"
      },
      "source": [
        "# Using  a pre-existing layer \n",
        "layer = tf.keras.layers.Dense(100)\n",
        "\n",
        "layer(tf.zeros([10 ,5]))[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhXsOkVVUDdt"
      },
      "source": [
        "Layers have many useful methods, for example we can inspect all variables in a layer using `layer.variables` and trainable variables using `layer.trainable_variables`. \n",
        "\n",
        "When we talk about variables, it means the weights and biases. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6-AmyEpUamo"
      },
      "source": [
        "# Accessing the weight and biases \n",
        "layer.variables[0][:1] , layer.variables[1][:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcTBaaSfUc8-"
      },
      "source": [
        "# We can even explicitly call the kernel and bias \n",
        "layer.kernel[0] , layer.bias[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQlLjG8UWbh_"
      },
      "source": [
        "### Implementing a custom layer \n",
        "\n",
        "The best way to implement our own layer is extending the `tf.keras.Layer` class and implementing: \n",
        "- The `__init__` where we can do all input-independent initialization. \n",
        "- `build` we can use this when we know the shapes of the input tensors and can do the rest of the initialization. \n",
        "- `call` where we do the forward computation. \n",
        "\n",
        "At times we can even neglect the usage of `build` and create the variables in the constructor itself. \n",
        "\n",
        "\n",
        "> Well the main advantage of using `build` is that it enables late variable creation based on the shape of the inputs the layer will operate on.\n",
        "\n",
        "> Creating variables in `__init__` would mean that shapes required to create the variables will need to be explicitly specified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o8RrovsZoc7"
      },
      "source": [
        "# Creating a custom layer \n",
        "class MyDenseLayer(tf.keras.layers.Layer):\n",
        "  \n",
        "  # The constructor \n",
        "  def __init__(self , num_outputs , **kwargs):\n",
        "    super(MyDenseLayer ,self).__init__(**kwargs)\n",
        "    self.num_outputs = num_outputs \n",
        "\n",
        "  # Defining the build function (creating the initializer etc..)\n",
        "  def build(self , input_shape):\n",
        "    self.kernel = self.add_weight(name = 'kernel_weights' , \n",
        "                                shape = [int(input_shape[-1]) , \n",
        "                                         self.num_outputs] , \n",
        "                                  initializer = tf.keras.initializers.RandomNormal() ,\n",
        "                                  trainable = True )\n",
        "    \n",
        "    self.bias = self.add_weight(name = 'bias' , \n",
        "                                shape = [self.num_outputs,] , \n",
        "                                initializer = tf.keras.initializers.Zeros())\n",
        "    \n",
        "  # Forward propagation \n",
        "  # The call method takes the input \n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs , self.kernel) + self.num_outputs # added bias to prevent zero "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETlUKxW6ahtN"
      },
      "source": [
        "# Creating an object of the layer we've created \n",
        "layer = MyDenseLayer(num_outputs= 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaQbO4wfcPay"
      },
      "source": [
        "# Passing in a dummy input to test our custom layer \n",
        "# Now we're calling the layer so the build function will get in action\n",
        "layer(tf.ones([10 , 5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG6MjMQ6cV-5"
      },
      "source": [
        "### Models: Composing layers \n",
        "\n",
        "Many machine learning models are implemented by composing the existing layers. For example, each **residual block in a resnet** is a composition of convolutions, batch normalizations and a shortcut layers. \n",
        "\n",
        "> Layers can be nested inside the other layers \n",
        "\n",
        "When we inherit from the `tf.keras.Model` we get the methods like fit , evaluate annd save. One other feature provided by the `tf.keras.Model` is that in addition to tracking the variables, as `tf.keras.Model` also tracks its internal layers, making them easier to inspect each layers. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odG00v1FxzWH"
      },
      "source": [
        "# Building a ResNet Block from the Model method \n",
        "\n",
        "class ResnetIdentityBlock(tf.keras.Model):\n",
        "\n",
        "  # Constructor \n",
        "  def __init__(self , kernel_size , filters , **kwargs):\n",
        "    super(ResnetIdentityBlock , self).__init__(**kwargs)\n",
        "\n",
        "    # Unpacking the list of filters \n",
        "    filters_1 , filters_2 , filters_3 = filters \n",
        "\n",
        "    # Initializing the layers \n",
        "    self.conv2a = tf.keras.layers.Conv2D(filters_1 ,(1 , 1))\n",
        "    self.bn2a = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    self.conv2b = tf.keras.layers.Conv2D(filters_2 , kernel_size= kernel_size , strides= (1, 1))\n",
        "    self.bn2b = tf.keras.layers.BatchNormalization() \n",
        "\n",
        "    self.conv2c = tf.keras.layers.Conv2D(filters_3 , (1 , 1))\n",
        "    self.bn2c = tf.keras.layers.BatchNormalization() \n",
        "\n",
        "\n",
        "  # The forward propagation (building the model here )\n",
        "\n",
        "  def call(self , input_tensor , training = False):\n",
        "\n",
        "    # Building a functional model of how the resnet block is connected \n",
        "    #x = tf.expand_dims(input_tensor , axis = 1)\n",
        "    print(input_tensor.shape)\n",
        "    x = self.conv2a(input_tensor)\n",
        "    print(x.shape)\n",
        "    x = self.bn2a(x , training = training)\n",
        "    print(x.shape)\n",
        "    x = tf.nn.relu(x) \n",
        "\n",
        "    print(x.shape)\n",
        "    x = self.conv2b(x)\n",
        "    print(x.shape)\n",
        "    x = self.bn2b(x , training = training)\n",
        "    print(x.shape)\n",
        "    x = tf.nn.relu(x)\n",
        "\n",
        "    print(x.shape)\n",
        "    x = self.conv2c(x)\n",
        "    print(x.shape)\n",
        "    x = self.bn2c(x , training = training)\n",
        "    print(x.shape)\n",
        "\n",
        "    x += input_tensor\n",
        "    print(x.shape)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "# Using the above model classs and creacting a Resnet Block \n",
        "block = ResnetIdentityBlock(1 , filters = [1 ,2 ,3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h2dd8-w0ZJg"
      },
      "source": [
        "# Dummy inputs \n",
        "block(tf.zeros([1 ,2 ,3 ,3]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP5KsFud1Q8c"
      },
      "source": [
        "# Accessing the block layers\n",
        "block.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DpzjJkQ1RCA"
      },
      "source": [
        "block.variables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjyKc3vP1RPj"
      },
      "source": [
        "len(block.variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwpKdPyeC6tU"
      },
      "source": [
        "# We can get the summary (because we inherited the Model class)\n",
        "block.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5DPHc6wDBbu",
        "outputId": "3d4523e4-d0f4-4fca-9b46-de2fbfa281e2"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "(X_train , y_train) , (X_test , y_test) = mnist.load_data()\n",
        "\n",
        "X_train.shape , X_test.shape , y_train.shape , y_test.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28), (60000,), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GD2ahCufi14"
      },
      "source": [
        "X_train = X_train.reshape(-1 , 28 ,28 ,1).astype('float32') / 255.0\n",
        "X_test = X_test.reshape(-1 , 28 ,28 ,1).astype('float32') / 255.0\n",
        "\n",
        "\n",
        "X_train_new = X_train.reshape(-1 , 28 *28).astype('float32') / 255.0\n",
        "X_test_new = X_test.reshape(-1 , 28*28).astype('float32') / 255.0\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNf6UBZDftEo"
      },
      "source": [
        "Lets create a block which does the following: \n",
        "- CNN \n",
        "- Batch Norm\n",
        "- ReLu \n",
        "\n",
        "But we want to do this for 10 times. To reduce the hustle we can create a class which will take care of these repititions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K9lZFX1gjBv"
      },
      "source": [
        "class CNNBlock(tf.keras.layers.Layer):\n",
        "\n",
        "    # Constructor where we initialize the things we are going to use\n",
        "    def __init__(self, out_channels , kernel_size = 3 , **kwargs):\n",
        "      super(CNNBlock , self).__init__(**kwargs)\n",
        "\n",
        "      # Creating a cnn block \n",
        "      self.conv = layers.Conv2D(out_channels , kernel_size , padding ='same')\n",
        "      self.bn = layers.BatchNormalization()\n",
        "  \n",
        "\n",
        "\n",
        "    # Forward method \n",
        "    def call(self , input_tensor , training = False):\n",
        "      \n",
        "      x = self.conv(input_tensor)\n",
        "      x = self.bn(x , training = training)\n",
        "      x = tf.nn.relu(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAQ7L6oBhu7K",
        "outputId": "fc6a404e-6953-4fde-e58b-e37fa713623f"
      },
      "source": [
        "# Reusing this multiple times \n",
        "model = tf.keras.Sequential([\n",
        "  CNNBlock(32), \n",
        "  CNNBlock(64) , \n",
        "  CNNBlock(128), \n",
        "  layers.Flatten(),\n",
        "  layers.Dense(10 , activation= 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer = 'adam' , \n",
        "              loss = tf.keras.losses.SparseCategoricalCrossentropy() , \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.fit(X_train , y_train , batch_size = 64 , epochs = 3 , verbose = 2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "938/938 - 27s - loss: 0.6023 - accuracy: 0.9451\n",
            "Epoch 2/3\n",
            "938/938 - 10s - loss: 0.0914 - accuracy: 0.9820\n",
            "Epoch 3/3\n",
            "938/938 - 10s - loss: 0.0330 - accuracy: 0.9905\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff18d4dd3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-azvTuIViElU"
      },
      "source": [
        "# We are going to create a ResBlock (similar to resnet)\n",
        "class ResBlock(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self , channels , **kwargs):\n",
        "    super(ResBlock , self).__init__(**kwargs)\n",
        "\n",
        "    self.cnn1 = CNNBlock(channels[0])\n",
        "    self.cnn2 = CNNBlock(channels[1])\n",
        "    self.cnn3 = CNNBlock(channels[2])\n",
        "    self.pooling = tf.keras.layers.MaxPool2D()\n",
        "    self.identity_mapping = layers.Conv2D(channels[1] , kernel_size=3 , padding = 'same')\n",
        "\n",
        "  def call(self, input_tensor , training = False):\n",
        "    x = self.cnn1(input_tensor , training = training)\n",
        "    x = self.cnn2(x , training = training)\n",
        "    x = self.cnn3(x + self.identity_mapping(input_tensor) , training = training) # performing the skip connection \n",
        "    return self.pooling(x)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws3MDBVj5Boi",
        "outputId": "d44715b6-948b-4b93-cb5e-e2e3077cb4e2"
      },
      "source": [
        "class ResnetLike(tf.keras.Model):\n",
        "\n",
        "  # it has the functionality of layers and additional model functionalities (model.fit, evaluate......)\n",
        "\n",
        "  def __init__(self , num_classes = 10 , **kwargs):\n",
        "    super(ResnetLike , self).__init__(**kwargs)\n",
        "\n",
        "    self.block_1 = ResBlock(channels= [32 ,32, 64])\n",
        "    self.block_2 = ResBlock([128 , 128 , 256])\n",
        "    self.block_3 = ResBlock([128 , 256 , 512])\n",
        "    self.pool = layers.GlobalAveragePooling2D() # or flatten\n",
        "    self.classifier = layers.Dense(num_classes)\n",
        "\n",
        "  def call(self, input_tensor , training = False):\n",
        "    x = self.block_1(input_tensor , training = training)\n",
        "    x = self.block_2(x , training = training)\n",
        "    x = self.block_3(x , training = training)\n",
        "    x = self.pool(x)\n",
        "    return self.classifier(x)\n",
        "\n",
        "  # This trick will print the output shapes during the model summary \n",
        "  # This will overwrite the call method \n",
        "  def model(self):\n",
        "    x = layers.Input(shape = (28 , 28 , 1))\n",
        "    return tf.keras.Model(inputs = [x] , outputs = self.call(x))\n",
        "\n",
        "resnet_model = ResnetLike()\n",
        "resnet_model.compile(optimizer = 'adam' , \n",
        "              loss = tf.keras.losses.SparseCategoricalCrossentropy() , \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "resnet_model.fit(X_train , y_train , batch_size = 64 , epochs = 10 , verbose = 2)\n",
        "resnet_model.evaluate(X_test , y_test , batch_size = 64 , verbose = 2)\n",
        "#resnet_model.model().summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "938/938 - 23s - loss: 2.5968 - accuracy: 0.1120\n",
            "Epoch 2/10\n",
            "938/938 - 22s - loss: 2.3026 - accuracy: 0.1155\n",
            "Epoch 3/10\n",
            "938/938 - 22s - loss: 2.3026 - accuracy: 0.1159\n",
            "Epoch 4/10\n",
            "938/938 - 22s - loss: 2.3026 - accuracy: 0.1163\n",
            "Epoch 5/10\n",
            "938/938 - 22s - loss: 2.3026 - accuracy: 0.1158\n",
            "Epoch 6/10\n",
            "938/938 - 22s - loss: 2.3026 - accuracy: 0.1152\n",
            "Epoch 7/10\n",
            "938/938 - 22s - loss: 2.3026 - accuracy: 0.1154\n",
            "Epoch 8/10\n",
            "938/938 - 22s - loss: 2.3026 - accuracy: 0.1163\n",
            "Epoch 9/10\n",
            "938/938 - 22s - loss: 2.3026 - accuracy: 0.1157\n",
            "Epoch 10/10\n",
            "938/938 - 23s - loss: 2.3026 - accuracy: 0.1155\n",
            "157/157 - 2s - loss: 2.3026 - accuracy: 0.1162\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3025825023651123, 0.11620000004768372]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "vkl38GSB3YTi",
        "outputId": "80a7043e-3e9c-4936-a1cc-7064d831eff7"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model \n",
        "plot_model(resnet_model.model())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mteQ4LTA4UT0",
        "outputId": "ef6127bd-1785-48a7-d765-ca03cc8a0aba"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, num_classes = 10 , **kwargs):\n",
        "    super(MyModel , self).__init__(**kwargs)\n",
        "    self.dense1 = layers.Dense(64)\n",
        "    self.dense2 = layers.Dense(num_classes)\n",
        "\n",
        "  def call(self , input_tensor):\n",
        "    x = tf.nn.relu(self.dense1(input_tensor))\n",
        "    return self.dense2(x)\n",
        "\n",
        "\n",
        "model = MyModel()\n",
        "model.compile(optimizer = 'adam' , \n",
        "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits= True) , \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.fit(X_train_new , y_train , batch_size = 32 , epochs = 3 , verbose = 2)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 - 3s - loss: 2.3015 - accuracy: 0.1117\n",
            "Epoch 2/3\n",
            "1875/1875 - 2s - loss: 2.3012 - accuracy: 0.1124\n",
            "Epoch 3/3\n",
            "1875/1875 - 2s - loss: 2.3009 - accuracy: 0.1124\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff17a7607d0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDCVWMMNHmuz"
      },
      "source": [
        "# Creating a Relu \n",
        "class MyRelu(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MyRelu , self).__init__()\n",
        "\n",
        "  def call(self , x):\n",
        "    return tf.math.maximum(x , 0)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22KIo6FgLiMw"
      },
      "source": [
        "## Making new Layers and Models via subclassing (From The docs) \n",
        "\n",
        "https://www.tensorflow.org/guide/keras/custom_layers_and_models#setup\n",
        "\n",
        "\n",
        "Writing out every single code from this doc! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjmgY-dPOEkh"
      },
      "source": [
        "# Making the imports beforehand \n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import layers "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_L0zm8GOMIa"
      },
      "source": [
        "The Layer class encapsulates both a state (layers weights) and a transformation from inputs to outputs (a call method) for forward pass."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p7xtv9WOZPy"
      },
      "source": [
        "# Building a densely connected layer \n",
        "class Linear(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self , units , input_dim, **kwargs):\n",
        "    super(Linear , self).__init__(**kwargs)\n",
        "    self.units = units \n",
        "    self.input_dim = input_dim \n",
        "\n",
        "    # Weights and biases \n",
        "    w_init = tf.random_normal_initializer()\n",
        "    self.w = tf.Variable(\n",
        "        initial_value = w_init(shape = (input_dim , units) ,  dtype = tf.float32) , trainable = True\n",
        "    )\n",
        "\n",
        "    b_init = tf.zeros_initializer()\n",
        "    self.b = tf.Variable(\n",
        "        initial_value = b_init(shape = (units ,)  , dtype = tf.float32)\n",
        "    )\n",
        "\n",
        "  # Forward propagation \n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs , self.w) + self.b"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRtbnyLPRQkC",
        "outputId": "1422069e-8dc9-4ca6-8d50-eeb8b9e400ae"
      },
      "source": [
        "# Passing a dummy input \n",
        "x = tf.ones((2 ,2))\n",
        "linear_layer = Linear(units = 4 , input_dim = 2)\n",
        "y = linear_layer(x)\n",
        "print(y)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[-0.03264646 -0.10319741  0.00261803 -0.01504993]\n",
            " [-0.03264646 -0.10319741  0.00261803 -0.01504993]], shape=(2, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oui0PGgMRwIA",
        "outputId": "c061c9f0-c76f-4c97-b131-48f614916e08"
      },
      "source": [
        "x_ = tf.ones((2 , 4))\n",
        "y_ = tf.ones((4,))\n",
        "\n",
        "#tf.matmul(x , x_)\n",
        "x.shape , x_.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([2, 2]), TensorShape([2, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLUUo0YZSCae"
      },
      "source": [
        "Using the `add_weight()` method for quicker shortcut. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkbbD761T2aJ",
        "outputId": "14e0b5a9-638f-4049-b2b5-7dc0e78be47f"
      },
      "source": [
        "class Linear(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(Linear , self).__init__()\n",
        "    self.w = self.add_weight(\n",
        "        shape = (input_dim , units) , initializer = 'glorot_uniform' , trainable = True\n",
        "    )\n",
        "    self.b = self.add_weight(\n",
        "        shape = (units,) , initializer = 'zeros' , trainable = True\n",
        "    )\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs , self.w) + self.b\n",
        "\n",
        "\n",
        "linear_layer = Linear(4 ,2)\n",
        "linear_layer(x)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
              "array([[ 0.7560086 , -0.27888823, -1.5629225 ,  0.06975794],\n",
              "       [ 0.7560086 , -0.27888823, -1.5629225 ,  0.06975794]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zNYIsrXUj8L"
      },
      "source": [
        "Besides the trainable weights, we can even add non-trainable weights to a layer as well. \n",
        "\n",
        "> Such weights won't be taken into account during backprop or while training the layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR6uaS9pVE-I"
      },
      "source": [
        "class ComputeSum(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self , input_dim , **kwargs):\n",
        "    super(ComputeSum , self).__init__(**kwargs)\n",
        "\n",
        "    self.total = tf.Variable(initial_value= tf.zeros((input_dim , )) , trainable= False)\n",
        "\n",
        "  def call(self , inputs):\n",
        "    self.total.assign_add(tf.reduce_sum(inputs , axis = 0))\n",
        "    return self.total"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMJqfrbKV1dw",
        "outputId": "17567e01-91c7-4008-99b0-f7cf0a6b3004"
      },
      "source": [
        "x = tf.ones((2 , 2))\n",
        "my_sum = ComputeSum(input_dim= 2)\n",
        "my_sum(x)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([2., 2.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1OfT4VPV5I-"
      },
      "source": [
        "#### **Best Practice** Deferring weight creation until the shape of the input is known. \n",
        "\n",
        "In many cases, we may nt know in advance the size of our inputs, and we would like to lazily create weights when the vaue becomes known, some time after instantiating the layer. \n",
        "\n",
        "We can do this by using the `build(self, input_shape)` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF_h6d0nbtRs",
        "outputId": "dfcf7c97-aa73-481c-8547-563f7352dd31"
      },
      "source": [
        "# Constructing a layer with the build method \n",
        "\n",
        "class Linear(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self , units , **kwargs):\n",
        "    super(Linear , self).__init__(**kwargs)\n",
        "\n",
        "    self.units = units \n",
        "\n",
        "  def build(self , input_shape):\n",
        "    self.w = self.add_weight(shape = (input_shape[-1] , self.units) , \n",
        "                             initializer = 'glorot_uniform' , \n",
        "                             trainable = True)\n",
        "    \n",
        "    self.b = self.add_weight(shape = (self.units ,) , \n",
        "                             initializer = 'zeros', trainable = True)\n",
        "    \n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs , self.w) + self.b\n",
        "\n",
        "x = tf.ones((2, 2))\n",
        "b_layer = Linear(units = 12)\n",
        "b_layer(x)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 12), dtype=float32, numpy=\n",
              "array([[ 0.6545361 ,  0.36266744,  0.9787259 , -0.30318925,  1.1140931 ,\n",
              "         0.6644525 , -0.00476301, -0.31749135,  0.2563127 ,  0.8250067 ,\n",
              "         0.2188679 , -0.24075866],\n",
              "       [ 0.6545361 ,  0.36266744,  0.9787259 , -0.30318925,  1.1140931 ,\n",
              "         0.6644525 , -0.00476301, -0.31749135,  0.2563127 ,  0.8250067 ,\n",
              "         0.2188679 , -0.24075866]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV1uAsu3c-QW"
      },
      "source": [
        "The `call()` method will automatically run the build the first time its called. \n",
        "\n",
        "Now our layer creates the weights through the build method and takes the dim from the input shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r8OOsnHeOuL"
      },
      "source": [
        "#### **Layers are recursively composable** \n",
        "\n",
        "We can use the Layer instance as an attribute of another Layer, the output layer will start tracking the weights of the inner layer. \n",
        "\n",
        "We will call these instances constructor or the init method. Since the sublayers will typically have a build mehtod, they will be built when the outer layer gets built. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uATczWV2kuO5",
        "outputId": "61a77a39-69a7-4558-8fba-153076a0476a"
      },
      "source": [
        "# We are re-using the Linear class which was built above \n",
        "# Make sure it has the build method \n",
        "\n",
        "\n",
        "class MLPBlock(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self , **kwargs):\n",
        "    super(MLPBlock , self).__init__(**kwargs)\n",
        "\n",
        "    self.linear_1 = Linear(32)\n",
        "    self.linear_2 = Linear(32)\n",
        "    self.linear_3 = Linear(1)\n",
        "\n",
        "  def call(self , inputs):\n",
        "    x = self.linear_1(inputs)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = self.linear_2(x)\n",
        "    x = tf.nn.relu(x)\n",
        "    return self.linear_3(x)\n",
        "  \n",
        "  def model(self , input_shape):\n",
        "    x = layers.Input(shape = input_shape)\n",
        "    return tf.keras.Model(inputs = [x] , outputs = self.call(x))\n",
        "\n",
        "mlp = MLPBlock()\n",
        "x_new = tf.ones((3 , 64))\n",
        "new_model = mlp.model(x_new.shape)\n",
        "new_model.summary()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 3, 64)]           0         \n",
            "_________________________________________________________________\n",
            "linear_41 (Linear)           (None, 3, 32)             2080      \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_2 (TFOpLambda)    (None, 3, 32)             0         \n",
            "_________________________________________________________________\n",
            "linear_42 (Linear)           (None, 3, 32)             1056      \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_3 (TFOpLambda)    (None, 3, 32)             0         \n",
            "_________________________________________________________________\n",
            "linear_43 (Linear)           (None, 3, 1)              33        \n",
            "=================================================================\n",
            "Total params: 3,169\n",
            "Trainable params: 3,169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkxGjs1glRKf",
        "outputId": "d179ca5b-876d-47a5-a3e5-72f4a82d126b"
      },
      "source": [
        "Linear(32)(x)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 32), dtype=float32, numpy=\n",
              "array([[ 0.43154544,  0.20031127,  0.05356804, -0.5117223 ,  0.23156342,\n",
              "        -0.42638555, -0.23026729,  0.21616405,  0.02342704, -0.4331713 ,\n",
              "        -0.08822438,  0.10264812,  0.5390112 , -0.26971427, -0.7056853 ,\n",
              "         0.27737316,  0.17170075, -0.01220515,  0.1279693 ,  0.3457061 ,\n",
              "        -0.47503495,  0.10932532,  0.411958  , -0.63879704,  0.0115537 ,\n",
              "        -0.28038555, -0.12765104, -0.5820263 , -0.36577123, -0.28264078,\n",
              "        -0.05403408, -0.3133632 ],\n",
              "       [ 0.43154544,  0.20031127,  0.05356804, -0.5117223 ,  0.23156342,\n",
              "        -0.42638555, -0.23026729,  0.21616405,  0.02342704, -0.4331713 ,\n",
              "        -0.08822438,  0.10264812,  0.5390112 , -0.26971427, -0.7056853 ,\n",
              "         0.27737316,  0.17170075, -0.01220515,  0.1279693 ,  0.3457061 ,\n",
              "        -0.47503495,  0.10932532,  0.411958  , -0.63879704,  0.0115537 ,\n",
              "        -0.28038555, -0.12765104, -0.5820263 , -0.36577123, -0.28264078,\n",
              "        -0.05403408, -0.3133632 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZsnBSNAlSCH"
      },
      "source": [
        "def model(self):\n",
        "    x = layers.Input(shape = (28 , 28 , 1))\n",
        "    return tf.keras.Model(inputs = [x] , outputs = self.call(x))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}