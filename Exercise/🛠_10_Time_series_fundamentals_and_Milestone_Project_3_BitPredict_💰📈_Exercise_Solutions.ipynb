{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ðŸ›  10. Time series fundamentals and Milestone Project 3: BitPredict ðŸ’°ðŸ“ˆ Exercise Solutions.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPslF58SHJwo/JHb1W+CHhO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning_Tensorflow/blob/main/Exercise/%F0%9F%9B%A0_10_Time_series_fundamentals_and_Milestone_Project_3_BitPredict_%F0%9F%92%B0%F0%9F%93%88_Exercise_Solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9BhPZ1Tx4bm"
      },
      "source": [
        "# ðŸ›  10. Time series fundamentals and Milestone Project 3: BitPredict ðŸ’°ðŸ“ˆ Exercise Solutions \n",
        "\n",
        "1. Does scaling the data help for univariate/multivariate data? (e.g. getting all of the values between 0 & 1)\n",
        "    * Try doing this for a univariate model (e.g. model_1) and a multivariate model (e.g. model_6) and see if it effects model training or evaluation results.\n",
        "2. Get the most up to date data on Bitcoin, train a model & see how it goes (our data goes up to May 18 2021).\n",
        "    * You can download the Bitcoin historical data for free from  [coindesk.com/price/bitcoin](https://www.coindesk.com/price/bitcoin)  and clicking â€œExport Dataâ€ -> â€œCSVâ€.\n",
        "3. For most of our models we used WINDOW_SIZE=7, but is there a better window size?\n",
        "    * Setup a series of experiments to find whether or not thereâ€™s a better window size.\n",
        "    * For example, you might train 10 different models with HORIZON=1 but with window sizes ranging from 2-12.\n",
        "4. Create a windowed dataset just like the ones we used for model_1 using  [tf.keras.preprocessing.timeseries_dataset_from_array()](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/timeseries_dataset_from_array)  and retrain model_1 using the recreated dataset.\n",
        "5. For our multivariate modelling experiment, we added the Bitcoin block reward size as an extra feature to make our time series multivariate.\n",
        "    * Are there any other features you think you could add?\n",
        "    * If so, try it out, how do these affect the model?\n",
        "6. Make prediction intervals for future forecasts. To do so, one way would be to train an ensemble model on all of the data, make future forecasts with it and calculate the prediction intervals of the ensemble just like we did for model_8.\n",
        "7. For future predictions, try to make a prediction, retrain a model on the predictions, make a prediction, retrain a model, make a prediction, retrain a model, make a prediction (retrain a model each time a new prediction is made). Plot the results, how do they look compared to the future predictions where a model wasnâ€™t retrained for every forecast (model_9)?\n",
        "8. Throughout this notebook, weâ€™ve only tried algorithms weâ€™ve handcrafted ourselves. But itâ€™s worth seeing how a purpose built forecasting algorithm goes.\n",
        "    * Try out one of the extra algorithms listed in the modelling experiments part such as:\n",
        "\t*  [Facebookâ€™s Kats library](https://github.com/facebookresearch/Kats)  - there are many models in here, remember the machine learning practionerâ€™s motto: experiment, experiment, experiment.\n",
        "\t*  [LinkedInâ€™s Greykite library](https://github.com/linkedin/greykite) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VT9614RIyCCl"
      },
      "source": [
        "## Downloading the data and preprocessing it "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "aZe0Y63IyQgT",
        "outputId": "01ff4afc-a1a0-48f0-efb1-5c6fedfb50c7"
      },
      "source": [
        "# Download Bitcoin historical data from GitHub \n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\n",
        "\n",
        "# Import with pandas \n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\", \n",
        "                 parse_dates=[\"Date\"], \n",
        "                 index_col=[\"Date\"]) # parse the date column (tell pandas column 1 is a datetime)\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-11 06:09:45--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 178509 (174K) [text/plain]\n",
            "Saving to: â€˜BTC_USD_2013-10-01_2021-05-18-CoinDesk.csvâ€™\n",
            "\n",
            "\r          BTC_USD_2   0%[                    ]       0  --.-KB/s               \rBTC_USD_2013-10-01_ 100%[===================>] 174.33K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2021-09-11 06:09:46 (73.5 MB/s) - â€˜BTC_USD_2013-10-01_2021-05-18-CoinDesk.csvâ€™ saved [178509/178509]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Currency</th>\n",
              "      <th>Closing Price (USD)</th>\n",
              "      <th>24h Open (USD)</th>\n",
              "      <th>24h High (USD)</th>\n",
              "      <th>24h Low (USD)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-01</th>\n",
              "      <td>BTC</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>124.30466</td>\n",
              "      <td>124.75166</td>\n",
              "      <td>122.56349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-02</th>\n",
              "      <td>BTC</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>125.75850</td>\n",
              "      <td>123.63383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-03</th>\n",
              "      <td>BTC</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>125.66566</td>\n",
              "      <td>83.32833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-04</th>\n",
              "      <td>BTC</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>118.67500</td>\n",
              "      <td>107.05816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-05</th>\n",
              "      <td>BTC</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>121.93633</td>\n",
              "      <td>118.00566</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Currency  Closing Price (USD)  ...  24h High (USD)  24h Low (USD)\n",
              "Date                                      ...                               \n",
              "2013-10-01      BTC            123.65499  ...       124.75166      122.56349\n",
              "2013-10-02      BTC            125.45500  ...       125.75850      123.63383\n",
              "2013-10-03      BTC            108.58483  ...       125.66566       83.32833\n",
              "2013-10-04      BTC            118.67466  ...       118.67500      107.05816\n",
              "2013-10-05      BTC            121.33866  ...       121.93633      118.00566\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LQW1xGSyYDv",
        "outputId": "8783c734-5738-4e13-8cb7-7b4782d6c786"
      },
      "source": [
        "# Only want closing price for each day \n",
        "bitcoin_prices = pd.DataFrame(df[\"Closing Price (USD)\"]).rename(columns={\"Closing Price (USD)\": \"Price\"})\n",
        "bitcoin_prices.head() , bitcoin_prices.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                Price\n",
              " Date                 \n",
              " 2013-10-01  123.65499\n",
              " 2013-10-02  125.45500\n",
              " 2013-10-03  108.58483\n",
              " 2013-10-04  118.67466\n",
              " 2013-10-05  121.33866, (2787, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIlIWPTWD6z_"
      },
      "source": [
        "# Get the data in array \n",
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import layers\n",
        "\n",
        "timesteps = bitcoin_prices.index.to_numpy()\n",
        "prices = bitcoin_prices['Price'].to_numpy()\n",
        "\n",
        "# Instantiating the sklearn MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler() "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eynNXXID68q"
      },
      "source": [
        "# Create function to view NumPy arrays as windows \n",
        "\n",
        "def get_labelled_windows(x , horizon):\n",
        "  return x[:, :-horizon] ,x[: , -horizon:]\n",
        "\n",
        "\n",
        "def make_windows_scaled(x, window_size=7, horizon=1):\n",
        "  \"\"\"\n",
        "  Turns a 1D array into a 2D array of sequential windows of window_size. Also applies the standard scaler\n",
        "  \"\"\"\n",
        "  scaler.fit(np.expand_dims(x , axis =1))\n",
        "  scaled_x = scaler.transform(np.expand_dims(x , axis = 1))\n",
        "  scaled_x = np.squeeze(scaled_x)\n",
        "  \n",
        "  window_step = np.expand_dims(np.arange(window_size+horizon), axis=0)\n",
        "  window_indexes = window_step + np.expand_dims(np.arange(len(scaled_x)-(window_size+horizon-1)), axis=0).T # create 2D array of windows of size window_size\n",
        "  windowed_array = scaled_x[window_indexes]\n",
        "  windows, labels = get_labelled_windows(windowed_array, horizon=horizon)\n",
        "\n",
        "  return windows, labels\n",
        "\n",
        "\n",
        "# Make the splits \n",
        "def make_train_test_splits(windows , labels , test_split = 0.2):\n",
        "  split_size = int(len(windows) * (1 - test_split))\n",
        "  train_windows = windows[:split_size]\n",
        "  train_labels = labels[:split_size]\n",
        "  test_windows = windows[split_size:]\n",
        "  test_labels = labels[split_size:]\n",
        "\n",
        "  return train_windows ,  test_windows ,train_labels,  test_labels"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dItohLM1Ozr"
      },
      "source": [
        "### 1. Does scaling the data help for univariate/multivariate data? (e.g. getting all of the values between 0 & 1)\n",
        "* Try doing this for a univariate model (e.g. model_1) and a multivariate model (e.g. model_6) and see if it effects model training or evaluation results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S-J_3Tkzfto",
        "outputId": "d925d051-7bdd-4cde-d6bd-d358df0dac7c"
      },
      "source": [
        "# Model 1 (Horizon = 1 , Window_size = 7)\n",
        "HORIZON = 1 \n",
        "WINDOW_SIZE = 7 \n",
        "\n",
        "\n",
        "full_windows , full_labels = make_windows_scaled(prices , window_size = WINDOW_SIZE , horizon = HORIZON)\n",
        "full_windows.shape , full_labels.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2780, 7), (2780, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL8e6Iz9NOUX",
        "outputId": "a11b0525-20b0-4488-b3a4-afb830b25c79"
      },
      "source": [
        "# Looking at few examples of how price is scaled\n",
        "for i in range(3):\n",
        "  print(f'Window: {full_windows[i]} --> Label {full_labels[i]}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Window: [0.00023831 0.00026677 0.         0.00015955 0.00020168 0.00019087\n",
            " 0.0002089 ] --> Label [0.00022847]\n",
            "Window: [0.00026677 0.         0.00015955 0.00020168 0.00019087 0.0002089\n",
            " 0.00022847] --> Label [0.00024454]\n",
            "Window: [0.         0.00015955 0.00020168 0.00019087 0.0002089  0.00022847\n",
            " 0.00024454] --> Label [0.00027478]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmHd26QZFZDU",
        "outputId": "6eb0ce2e-e93e-4b88-8c8b-7308ec95a096"
      },
      "source": [
        "# Making train and test splits \n",
        "train_windows , test_windows , train_labels , test_labels = make_train_test_splits(full_windows , full_labels)\n",
        "len(train_windows), len(test_windows), len(train_labels), len(test_labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2224, 556, 2224, 556)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2dT3_hqyejt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "045a14fa-2a07-45d5-d88f-4d202a2351ab"
      },
      "source": [
        "# Building the Model 1 \n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Construct the model \n",
        "model_1 = tf.keras.Sequential([\n",
        "  layers.Dense(128, activation= 'relu') ,\n",
        "  layers.Dense(HORIZON , activation = 'linear')\n",
        "])\n",
        "\n",
        "# Compiling the model \n",
        "model_1.compile(loss = 'mae' , \n",
        "                optimizer = tf.keras.optimizers.Adam() , \n",
        "                metrics = ['mae'])\n",
        "\n",
        "# Fit the model \n",
        "model_1.fit(x = train_windows , \n",
        "            y = train_labels , \n",
        "            epochs = 100 , batch_size = 128 , verbose = 0 , \n",
        "            validation_data = (test_windows , test_labels))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d9732ae10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MwuA2gI0t2B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd36928-544b-43fd-8234-911612f4d985"
      },
      "source": [
        "# Evaluate the model on test data \n",
        "model_1.evaluate(test_windows , test_labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 1ms/step - loss: 0.0093 - mae: 0.0093\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.00931711308658123, 0.00931711308658123]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh7sqPOjNo8V"
      },
      "source": [
        "model_1_preds = tf.squeeze(model_1.predict(test_windows))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMNXeHUWXcEI"
      },
      "source": [
        "Now doing the same for the Multivariate data especially for the Model 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "6HoW1S6TXhvD",
        "outputId": "25fb3a6d-4ddb-48e0-b34a-a2de230f708f"
      },
      "source": [
        "# Block reward values\n",
        "block_reward_1 = 50 # 3 January 2009 \n",
        "block_reward_2 = 25 # 28 November 2012 \n",
        "block_reward_3 = 12.5 # 9 July 2016\n",
        "block_reward_4 = 6.25 # 11 May 2020\n",
        "\n",
        "# Block reward dates (datetime form of the above date stamps)\n",
        "block_reward_2_datetime = np.datetime64(\"2012-11-28\")\n",
        "block_reward_3_datetime = np.datetime64(\"2016-07-09\")\n",
        "block_reward_4_datetime = np.datetime64(\"2020-05-11\")\n",
        "\n",
        "# Get date indexes for when to add in different block dates\n",
        "block_reward_2_days = (block_reward_3_datetime - bitcoin_prices.index[0]).days\n",
        "block_reward_3_days = (block_reward_4_datetime - bitcoin_prices.index[0]).days\n",
        "block_reward_2_days, block_reward_3_days\n",
        "\n",
        "# Add block_reward column\n",
        "bitcoin_prices_block = bitcoin_prices.copy()\n",
        "bitcoin_prices_block[\"block_reward\"] = None\n",
        "\n",
        "# Set values of block_reward column (it's the last column hence -1 indexing on iloc)\n",
        "bitcoin_prices_block.iloc[:block_reward_2_days, -1] = block_reward_2\n",
        "bitcoin_prices_block.iloc[block_reward_2_days:block_reward_3_days, -1] = block_reward_3\n",
        "bitcoin_prices_block.iloc[block_reward_3_days:, -1] = block_reward_4\n",
        "bitcoin_prices_block.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>block_reward</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-01</th>\n",
              "      <td>123.65499</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-02</th>\n",
              "      <td>125.45500</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-03</th>\n",
              "      <td>108.58483</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-04</th>\n",
              "      <td>118.67466</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-05</th>\n",
              "      <td>121.33866</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Price block_reward\n",
              "Date                              \n",
              "2013-10-01  123.65499           25\n",
              "2013-10-02  125.45500           25\n",
              "2013-10-03  108.58483           25\n",
              "2013-10-04  118.67466           25\n",
              "2013-10-05  121.33866           25"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "4NQkP9EmX2Xt",
        "outputId": "216415b3-3c44-4e52-96bb-6e1414886638"
      },
      "source": [
        "# Make a copy of the Bitcoin historical data with block reward feature\n",
        "bitcoin_prices_windowed = bitcoin_prices_block.copy()\n",
        "\n",
        "# Add windowed columns\n",
        "for i in range(WINDOW_SIZE): \n",
        "  bitcoin_prices_windowed[f\"Price+{i+1}\"] = bitcoin_prices_windowed[\"Price\"].shift(periods=i+1)\n",
        "bitcoin_prices_windowed.head(10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>block_reward</th>\n",
              "      <th>Price+1</th>\n",
              "      <th>Price+2</th>\n",
              "      <th>Price+3</th>\n",
              "      <th>Price+4</th>\n",
              "      <th>Price+5</th>\n",
              "      <th>Price+6</th>\n",
              "      <th>Price+7</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-01</th>\n",
              "      <td>123.65499</td>\n",
              "      <td>25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-02</th>\n",
              "      <td>125.45500</td>\n",
              "      <td>25</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-03</th>\n",
              "      <td>108.58483</td>\n",
              "      <td>25</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-04</th>\n",
              "      <td>118.67466</td>\n",
              "      <td>25</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-05</th>\n",
              "      <td>121.33866</td>\n",
              "      <td>25</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-06</th>\n",
              "      <td>120.65533</td>\n",
              "      <td>25</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-07</th>\n",
              "      <td>121.79500</td>\n",
              "      <td>25</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-08</th>\n",
              "      <td>123.03300</td>\n",
              "      <td>25</td>\n",
              "      <td>121.79500</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-09</th>\n",
              "      <td>124.04900</td>\n",
              "      <td>25</td>\n",
              "      <td>123.03300</td>\n",
              "      <td>121.79500</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-10</th>\n",
              "      <td>125.96116</td>\n",
              "      <td>25</td>\n",
              "      <td>124.04900</td>\n",
              "      <td>123.03300</td>\n",
              "      <td>121.79500</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Price block_reward    Price+1  ...    Price+5    Price+6    Price+7\n",
              "Date                                           ...                                 \n",
              "2013-10-01  123.65499           25        NaN  ...        NaN        NaN        NaN\n",
              "2013-10-02  125.45500           25  123.65499  ...        NaN        NaN        NaN\n",
              "2013-10-03  108.58483           25  125.45500  ...        NaN        NaN        NaN\n",
              "2013-10-04  118.67466           25  108.58483  ...        NaN        NaN        NaN\n",
              "2013-10-05  121.33866           25  118.67466  ...        NaN        NaN        NaN\n",
              "2013-10-06  120.65533           25  121.33866  ...  123.65499        NaN        NaN\n",
              "2013-10-07  121.79500           25  120.65533  ...  125.45500  123.65499        NaN\n",
              "2013-10-08  123.03300           25  121.79500  ...  108.58483  125.45500  123.65499\n",
              "2013-10-09  124.04900           25  123.03300  ...  118.67466  108.58483  125.45500\n",
              "2013-10-10  125.96116           25  124.04900  ...  121.33866  118.67466  108.58483\n",
              "\n",
              "[10 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "73jAFAVeYpD-",
        "outputId": "9fa4ab23-e39c-40f3-d1b0-97a17ac27b1f"
      },
      "source": [
        "# Let's create X & y, remove the NaN's and convert to float32 to prevent TensorFlow errors \n",
        "X = bitcoin_prices_windowed.dropna().drop(\"Price\", axis=1).astype(np.float32) \n",
        "y = bitcoin_prices_windowed.dropna()[\"Price\"].astype(np.float32)\n",
        "X.head()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>block_reward</th>\n",
              "      <th>Price+1</th>\n",
              "      <th>Price+2</th>\n",
              "      <th>Price+3</th>\n",
              "      <th>Price+4</th>\n",
              "      <th>Price+5</th>\n",
              "      <th>Price+6</th>\n",
              "      <th>Price+7</th>\n",
              "      <th>day_of_week</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-08</th>\n",
              "      <td>25.0</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>108.584831</td>\n",
              "      <td>125.455002</td>\n",
              "      <td>123.654991</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-09</th>\n",
              "      <td>25.0</td>\n",
              "      <td>123.032997</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>108.584831</td>\n",
              "      <td>125.455002</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-10</th>\n",
              "      <td>25.0</td>\n",
              "      <td>124.049004</td>\n",
              "      <td>123.032997</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>108.584831</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-11</th>\n",
              "      <td>25.0</td>\n",
              "      <td>125.961159</td>\n",
              "      <td>124.049004</td>\n",
              "      <td>123.032997</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-12</th>\n",
              "      <td>25.0</td>\n",
              "      <td>125.279663</td>\n",
              "      <td>125.961159</td>\n",
              "      <td>124.049004</td>\n",
              "      <td>123.032997</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            block_reward     Price+1  ...     Price+7  day_of_week\n",
              "Date                                  ...                         \n",
              "2013-10-08          25.0  121.794998  ...  123.654991          1.0\n",
              "2013-10-09          25.0  123.032997  ...  125.455002          2.0\n",
              "2013-10-10          25.0  124.049004  ...  108.584831          3.0\n",
              "2013-10-11          25.0  125.961159  ...  118.674660          4.0\n",
              "2013-10-12          25.0  125.279663  ...  121.338661          5.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SdPXx_SauLC"
      },
      "source": [
        "# Scaling the X data \n",
        "X_scaled = scaler.fit_transform(X)\n",
        "y_scaled = scaler.fit_transform(np.expand_dims(y , axis = 1))\n",
        "y_scaled = np.squeeze(y_scaled)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M8UVLaIa1km",
        "outputId": "a45ac9c7-9ba6-467b-8a85-dbde3b8979d1"
      },
      "source": [
        "# Make train and test sets\n",
        "split_size = int(len(X) * 0.8)\n",
        "X_train, y_train = X_scaled[:split_size], y_scaled[:split_size]\n",
        "X_test, y_test = X_scaled[split_size:], y_scaled[split_size:]\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2224, 2224, 556, 556)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sXgRZ1Ka-TT",
        "outputId": "19fd9826-9452-4dce-9090-a23eafbcb1f2"
      },
      "source": [
        "# Building a Multivariate time series model and fitting it\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model_6 = tf.keras.Sequential([\n",
        "  layers.Dense(128 , activation= 'relu'), \n",
        "  layers.Dense(HORIZON)\n",
        "])\n",
        "\n",
        "model_6.compile(loss = 'mae' , \n",
        "                optimizer = tf.keras.optimizers.Adam())\n",
        "\n",
        "model_6.fit(X_train , y_train , \n",
        "          epochs = 100 ,\n",
        "          verbose = 0 , batch_size = 128, \n",
        "          validation_data = (X_test , y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d92b95690>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs_ZDtr1b3-N",
        "outputId": "67f8ea8e-71f8-4231-d117-9bc0b62ff092"
      },
      "source": [
        "# Evaluate the model 6 \n",
        "model_6.evaluate(X_test , y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 1ms/step - loss: 0.0735\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07352113723754883"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqlPT_dXfuQf"
      },
      "source": [
        "### 2. Get the most up to date data on Bitcoin, train a model & see how it goes (our data goes up to May 18 2021)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUKI8td_b_F_",
        "outputId": "af03e9e5-c737-421d-e071-8763e0d22fbb"
      },
      "source": [
        "# Loading the in the latest csv from Coindesk\n",
        "df_updated = pd.read_csv('/content/BTC_USD_2014-11-02_2021-09-09-CoinDesk.csv' , \n",
        "                 parse_dates = ['Date'] , \n",
        "                 index_col = ['Date'])\n",
        "\n",
        "bitcoin_prices_updated = pd.DataFrame(df_updated[\"Closing Price (USD)\"]).rename(columns={\"Closing Price (USD)\": \"Price\"})\n",
        "bitcoin_prices_updated.head(10) , bitcoin_prices_updated.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                Price\n",
              " Date                 \n",
              " 2014-11-02  325.22633\n",
              " 2014-11-03  331.60083\n",
              " 2014-11-04  324.71833\n",
              " 2014-11-05  332.45666\n",
              " 2014-11-06  336.58500\n",
              " 2014-11-07  346.77500\n",
              " 2014-11-08  344.81166\n",
              " 2014-11-09  343.06500\n",
              " 2014-11-10  358.50166\n",
              " 2014-11-11  368.07666, (2503, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52OylhbEiIII"
      },
      "source": [
        "prices_updated = bitcoin_prices_updated['Price'].to_numpy()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZYgYStegy7E"
      },
      "source": [
        "def make_windows(x, window_size=7, horizon=1):\n",
        "  \"\"\"\n",
        "  Turns a 1D array into a 2D array of sequential windows of window_size.\n",
        "  \"\"\"\n",
        "  \n",
        "  window_step = np.expand_dims(np.arange(window_size+horizon), axis=0)\n",
        "  window_indexes = window_step + np.expand_dims(np.arange(len(x)-(window_size+horizon-1)), axis=0).T # create 2D array of windows of size window_size\n",
        "  windowed_array = x[window_indexes]\n",
        "  windows, labels = get_labelled_windows(windowed_array, horizon=horizon)\n",
        "\n",
        "  return windows, labels"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBzAx_9nhfGF",
        "outputId": "0a5507ea-3bde-4b9f-ac9e-390dd319f9cb"
      },
      "source": [
        "full_windows , full_labels = make_windows(prices_updated)\n",
        "len(full_windows), len(full_labels)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2496, 2496)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ5Iir7jvLeY",
        "outputId": "00f33b4f-8b5b-4751-b92c-4459661c0f34"
      },
      "source": [
        "# Looking at few examples of how price is scaled\n",
        "for i in range(3):\n",
        "  print(f'Window: {full_windows[i]} --> Label {full_labels[i]}')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Window: [325.22633 331.60083 324.71833 332.45666 336.585   346.775   344.81166] --> Label [343.065]\n",
            "Window: [331.60083 324.71833 332.45666 336.585   346.775   344.81166 343.065  ] --> Label [358.50166]\n",
            "Window: [324.71833 332.45666 336.585   346.775   344.81166 343.065   358.50166] --> Label [368.07666]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HCIuZdxh-GC",
        "outputId": "2d30caaf-604f-4874-ce80-689bc48a9a3c"
      },
      "source": [
        "# Making train and test splits\n",
        "train_windows ,  test_windows ,train_labels,  test_labels =  make_train_test_splits(full_windows , full_labels)\n",
        "\n",
        "len(train_windows) ,  len(test_windows) , len(train_labels),  len(test_labels) "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1996, 500, 1996, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1Ve_RGCm5Ez"
      },
      "source": [
        "Now we're building the same Model 1 with the new coindesk data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IytoXshkhJE",
        "outputId": "808913f1-6a23-4f7c-b04d-bb622da47cad"
      },
      "source": [
        "# Building the Model 1 with the updated data\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Construct the model \n",
        "model_1 = tf.keras.Sequential([\n",
        "  layers.Dense(128, activation= 'relu') ,\n",
        "  layers.Dense(HORIZON , activation = 'linear')\n",
        "])\n",
        "\n",
        "# Compiling the model \n",
        "model_1.compile(loss = 'mae' , \n",
        "                optimizer = tf.keras.optimizers.Adam() , \n",
        "                metrics = ['mae'])\n",
        "\n",
        "# Fit the model \n",
        "model_1.fit(x = train_windows , \n",
        "            y = train_labels , \n",
        "            epochs = 100 , batch_size = 128 , verbose = 0 , \n",
        "            validation_data = (test_windows , test_labels))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d973cb210>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq-4_z0rm_Gc",
        "outputId": "d0579474-a3c6-423e-b132-926c3d0093a8"
      },
      "source": [
        "# Evaluating the model \n",
        "model_1.evaluate(test_windows , test_labels)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 1ms/step - loss: 884.0138 - mae: 884.0138\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[884.0137939453125, 884.0137939453125]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIuiLp-PnYlS"
      },
      "source": [
        "### 3. For most of our models we used WINDOW_SIZE=7, but is there a better window size?\n",
        "\n",
        "* Setup a series of experiments to find whether or not thereâ€™s a better window size.\n",
        "* For example, you might train 10 different models with HORIZON=1 but with window sizes ranging from 2-12."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P08KPQgG6op2"
      },
      "source": [
        "# Writing a evaluation function based on the preds and targets \n",
        "def evaluate_preds(y_true , y_pred):\n",
        "\n",
        "  # Casting the values to float32 \n",
        "  y_true = tf.cast(y_true , tf.float32)\n",
        "  y_pred = tf.cast(y_pred , tf.float32)\n",
        "\n",
        "\n",
        "  # Calculate the metrics \n",
        "  mae = tf.keras.metrics.mean_absolute_error(y_true , y_pred)\n",
        "  mse = tf.keras.metrics.mean_squared_error(y_true , y_pred)\n",
        "  rmse = tf.sqrt(mse)\n",
        "  mape = tf.keras.metrics.mean_absolute_percentage_error(y_true , y_pred)\n",
        "  \n",
        "  # For longer horizons \n",
        "  if mae.ndim > 0:\n",
        "    mae = tf.reduce_sum(mae)\n",
        "    mse = tf.reduce_sum(mse)\n",
        "    rmse = tf.reduce_sum(rmse)\n",
        "    mape = tf.reduce_sum(mape)\n",
        "\n",
        "  return {'mae' : mae.numpy() , \n",
        "          'mse': mse.numpy() , \n",
        "          'rmse': rmse.numpy() , \n",
        "          'mape': mape.numpy() }"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x11lEVED6d9A",
        "outputId": "57a99294-3eb4-4d9c-9fdb-6649443c50d1"
      },
      "source": [
        "# Writing a for loop to iterate over the Window size and build 10 different models\n",
        "\n",
        "# 10 Different models with window size ranging from (2 - 12) and store the results\n",
        "model_results_list = []\n",
        "\n",
        "from tqdm import tqdm\n",
        "for size in tqdm(range(2,12)):\n",
        "  HORIZON = 1 \n",
        "  WINDOW_SIZE = size\n",
        "\n",
        "  # Making window and labels \n",
        "  full_windows , full_labels = make_windows(prices, window_size= WINDOW_SIZE , horizon= HORIZON)\n",
        "  \n",
        "\n",
        "  # Splitting the data in train and test\n",
        "  train_windows ,  test_windows ,train_labels,  test_labels = make_train_test_splits(full_windows , full_labels)\n",
        "\n",
        "\n",
        "  # Building a simple dense model\n",
        "  input = layers.Input(shape = (WINDOW_SIZE ,) , name = 'Input_layer')\n",
        "  x = layers.Dense(128 , activation= 'relu')(input)\n",
        "  output = layers.Dense(HORIZON , activation= 'linear')(x)\n",
        "\n",
        "  # Packing into a model \n",
        "  model = tf.keras.Model(input , output , name = f'model_windowed_{size}')\n",
        "\n",
        "  # Compiling and fitting the model \n",
        "  model.compile(loss = 'mae' , optimizer = 'adam' , metrics = 'mae')\n",
        "\n",
        "  model.fit(train_windows , train_labels , \n",
        "            epochs = 100 , verbose = 0 , \n",
        "            batch_size = 128 , \n",
        "            validation_data = (test_windows , test_labels))\n",
        "  \n",
        "\n",
        "  # Making predictions \n",
        "  preds_ = model.predict(test_windows)\n",
        "  y_preds = tf.squeeze(preds_)\n",
        "\n",
        "  results = evaluate_preds(tf.squeeze(test_labels) , y_preds)\n",
        "  model_results_list.append(results)\n",
        " "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:51<00:00,  5.18s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qyp-2gqoUipn",
        "outputId": "8acb0d4e-9991-45da-d248-7ae1b6339ac2"
      },
      "source": [
        "# Below are the 10 different models result \n",
        "model_results_list"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'mae': 569.1506, 'mape': 2.5277913, 'mse': 1159396.5, 'rmse': 1076.7528},\n",
              " {'mae': 565.61, 'mape': 2.5274613, 'mse': 1139677.6, 'rmse': 1067.5569},\n",
              " {'mae': 623.44543, 'mape': 2.8342037, 'mse': 1266272.0, 'rmse': 1125.2875},\n",
              " {'mae': 565.61096, 'mape': 2.5193882, 'mse': 1157946.9, 'rmse': 1076.0793},\n",
              " {'mae': 575.82715, 'mape': 2.5713227, 'mse': 1181491.9, 'rmse': 1086.9645},\n",
              " {'mae': 624.65094, 'mape': 2.8559413, 'mse': 1279308.5, 'rmse': 1131.0652},\n",
              " {'mae': 673.8483, 'mape': 3.1560009, 'mse': 1401001.9, 'rmse': 1183.6393},\n",
              " {'mae': 661.0718, 'mape': 3.0542161, 'mse': 1343192.1, 'rmse': 1158.9617},\n",
              " {'mae': 583.37537, 'mape': 2.6407204, 'mse': 1204248.0, 'rmse': 1097.3823},\n",
              " {'mae': 701.84753, 'mape': 3.2888033, 'mse': 1443914.4, 'rmse': 1201.6299}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzH981vjL-fT"
      },
      "source": [
        "### 4. Create a windowed dataset just like the ones we used for model_1 using  [tf.keras.preprocessing.timeseries_dataset_from_array()](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/timeseries_dataset_from_array)  and retrain model_1 using the recreated dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcRI4RcIYnYE"
      },
      "source": [
        "WINDOW_SIZE = 7 \n",
        "HORIZON = 1"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zakDAvtCY32O"
      },
      "source": [
        "# Make the splits \n",
        "def make_train_test_splits(windows , labels , test_split = 0.2):\n",
        "  split_size = int(len(windows) * (1 - test_split))\n",
        "  train_windows = windows[:split_size]\n",
        "  train_labels = labels[:split_size]\n",
        "  test_windows = windows[split_size:]\n",
        "  test_labels = labels[split_size:]\n",
        "\n",
        "  return train_windows ,  test_windows ,train_labels,  test_labels"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujv0D7izXNhn"
      },
      "source": [
        "ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    data = prices , targets = prices , sequence_length = WINDOW_SIZE , sequence_stride = HORIZON, \n",
        "    batch_size = 128\n",
        ")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha5sXVH-ctoF"
      },
      "source": [
        "train_size , test_size = int(0.8 * len(ds)) ,int(0.2 * len(ds))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlzXwk84cxp6"
      },
      "source": [
        "train_ds = ds.take(train_size)\n",
        "test_ds = ds.skip(train_size).take(test_size)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcTn-l1Idl3t",
        "outputId": "215a2147-f9d4-4551-d7c7-f4003b47671f"
      },
      "source": [
        "for x , y in train_ds.take(1):\n",
        "  print(x[:2] , y[:2])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[123.65499 125.455   108.58483 118.67466 121.33866 120.65533 121.795  ]\n",
            " [125.455   108.58483 118.67466 121.33866 120.65533 121.795   123.033  ]], shape=(2, 7), dtype=float64) tf.Tensor([123.65499 125.455  ], shape=(2,), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuP5_htZduAu",
        "outputId": "2922db66-c8b8-4be8-d18a-758ce7b25535"
      },
      "source": [
        "for x , y in test_ds.take(1):\n",
        "  print(x[:2] , y[:2])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[10302.19071368 10301.65965169 10231.42151196 10168.28770938\n",
            "  10223.5055788  10138.33520522  9984.52051597]\n",
            " [10301.65965169 10231.42151196 10168.28770938 10223.5055788\n",
            "  10138.33520522  9984.52051597 10031.86670899]], shape=(2, 7), dtype=float64) tf.Tensor([10302.19071368 10301.65965169], shape=(2,), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4VD9kgYdyCB",
        "outputId": "cf8f2926-d962-4aa5-e0ec-88d28b193b07"
      },
      "source": [
        "len(test_ds) + len(train_ds)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkBv9LaBeAc4",
        "outputId": "0f3fb8d6-1e4e-4d50-83c3-586719c40835"
      },
      "source": [
        "len(test_ds) , test_size"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieBAnXs0eJAy",
        "outputId": "54b2e4f7-a5ab-4fc8-8784-06eb8f42ec2c"
      },
      "source": [
        "# Building the Model 1 with the updated data\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Building a simple dense model\n",
        "input = layers.Input(shape = (WINDOW_SIZE ,) , name = 'Input_layer' , dtype = tf.float32)\n",
        "x = layers.Dense(128 , activation= 'relu')(input)\n",
        "output = layers.Dense(HORIZON , activation= 'linear')(x)\n",
        "\n",
        "# Packing into a model \n",
        "model = tf.keras.Model(input , output)\n",
        "\n",
        "# Compiling the model \n",
        "model.compile(loss = 'mae' , \n",
        "                optimizer = tf.keras.optimizers.Adam() , \n",
        "                metrics = ['mae'])\n",
        "\n",
        "# Fit the model \n",
        "model.fit(train_ds ,\n",
        "          epochs = 100 , verbose = 0 , \n",
        "            validation_data = test_ds)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d9679fbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPBtfK2diAkV",
        "outputId": "b5720b04-ebac-4208-8190-2798a10b0567"
      },
      "source": [
        "model.evaluate(test_ds)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 21ms/step - loss: 643.4305 - mae: 643.4305\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[643.4305419921875, 643.4305419921875]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GONHDDlhwKr"
      },
      "source": [
        "### 5. For our multivariate modelling experiment, we added the Bitcoin block reward size as an extra feature to make our time series multivariate.\n",
        "\n",
        "  * Are there any other features you think you could add?\n",
        "  * If so, try it out, how do these affect the model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA-51-MMxzNO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "5d20c957-37c8-4f85-8513-e71d4f1dcce2"
      },
      "source": [
        "df"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Currency</th>\n",
              "      <th>Closing Price (USD)</th>\n",
              "      <th>24h Open (USD)</th>\n",
              "      <th>24h High (USD)</th>\n",
              "      <th>24h Low (USD)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-01</th>\n",
              "      <td>BTC</td>\n",
              "      <td>123.654990</td>\n",
              "      <td>124.304660</td>\n",
              "      <td>124.751660</td>\n",
              "      <td>122.563490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-02</th>\n",
              "      <td>BTC</td>\n",
              "      <td>125.455000</td>\n",
              "      <td>123.654990</td>\n",
              "      <td>125.758500</td>\n",
              "      <td>123.633830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-03</th>\n",
              "      <td>BTC</td>\n",
              "      <td>108.584830</td>\n",
              "      <td>125.455000</td>\n",
              "      <td>125.665660</td>\n",
              "      <td>83.328330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-04</th>\n",
              "      <td>BTC</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>108.584830</td>\n",
              "      <td>118.675000</td>\n",
              "      <td>107.058160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-05</th>\n",
              "      <td>BTC</td>\n",
              "      <td>121.338660</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>121.936330</td>\n",
              "      <td>118.005660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-14</th>\n",
              "      <td>BTC</td>\n",
              "      <td>49764.132082</td>\n",
              "      <td>49596.778891</td>\n",
              "      <td>51448.798576</td>\n",
              "      <td>46294.720180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-15</th>\n",
              "      <td>BTC</td>\n",
              "      <td>50032.693137</td>\n",
              "      <td>49717.354353</td>\n",
              "      <td>51578.312545</td>\n",
              "      <td>48944.346536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-16</th>\n",
              "      <td>BTC</td>\n",
              "      <td>47885.625255</td>\n",
              "      <td>49926.035067</td>\n",
              "      <td>50690.802950</td>\n",
              "      <td>47005.102292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-17</th>\n",
              "      <td>BTC</td>\n",
              "      <td>45604.615754</td>\n",
              "      <td>46805.537852</td>\n",
              "      <td>49670.414174</td>\n",
              "      <td>43868.638969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-18</th>\n",
              "      <td>BTC</td>\n",
              "      <td>43144.471291</td>\n",
              "      <td>46439.336570</td>\n",
              "      <td>46622.853437</td>\n",
              "      <td>42102.346430</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2787 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Currency  Closing Price (USD)  ...  24h High (USD)  24h Low (USD)\n",
              "Date                                      ...                               \n",
              "2013-10-01      BTC           123.654990  ...      124.751660     122.563490\n",
              "2013-10-02      BTC           125.455000  ...      125.758500     123.633830\n",
              "2013-10-03      BTC           108.584830  ...      125.665660      83.328330\n",
              "2013-10-04      BTC           118.674660  ...      118.675000     107.058160\n",
              "2013-10-05      BTC           121.338660  ...      121.936330     118.005660\n",
              "...             ...                  ...  ...             ...            ...\n",
              "2021-05-14      BTC         49764.132082  ...    51448.798576   46294.720180\n",
              "2021-05-15      BTC         50032.693137  ...    51578.312545   48944.346536\n",
              "2021-05-16      BTC         47885.625255  ...    50690.802950   47005.102292\n",
              "2021-05-17      BTC         45604.615754  ...    49670.414174   43868.638969\n",
              "2021-05-18      BTC         43144.471291  ...    46622.853437   42102.346430\n",
              "\n",
              "[2787 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMRA5-nVmPnh"
      },
      "source": [
        "import datetime "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPIsz7vSms_7",
        "outputId": "db3e343e-37be-45f1-b9f7-39bba3703c4e"
      },
      "source": [
        "df.index[0].day_of"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Timestamp('2013-10-01 00:00:00')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "VtYlinvCm8EQ",
        "outputId": "263890f8-2650-4451-f6a6-56c201799e1e"
      },
      "source": [
        "df['day_of_week'] = df.index.dayofweek\n",
        "df.head(10)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Currency</th>\n",
              "      <th>Closing Price (USD)</th>\n",
              "      <th>24h Open (USD)</th>\n",
              "      <th>24h High (USD)</th>\n",
              "      <th>24h Low (USD)</th>\n",
              "      <th>day_of_week</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-01</th>\n",
              "      <td>BTC</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>124.30466</td>\n",
              "      <td>124.75166</td>\n",
              "      <td>122.56349</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-02</th>\n",
              "      <td>BTC</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>123.65499</td>\n",
              "      <td>125.75850</td>\n",
              "      <td>123.63383</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-03</th>\n",
              "      <td>BTC</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>125.45500</td>\n",
              "      <td>125.66566</td>\n",
              "      <td>83.32833</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-04</th>\n",
              "      <td>BTC</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>108.58483</td>\n",
              "      <td>118.67500</td>\n",
              "      <td>107.05816</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-05</th>\n",
              "      <td>BTC</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>118.67466</td>\n",
              "      <td>121.93633</td>\n",
              "      <td>118.00566</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-06</th>\n",
              "      <td>BTC</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.33866</td>\n",
              "      <td>121.85216</td>\n",
              "      <td>120.55450</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-07</th>\n",
              "      <td>BTC</td>\n",
              "      <td>121.79500</td>\n",
              "      <td>120.65533</td>\n",
              "      <td>121.99166</td>\n",
              "      <td>120.43199</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-08</th>\n",
              "      <td>BTC</td>\n",
              "      <td>123.03300</td>\n",
              "      <td>121.79500</td>\n",
              "      <td>123.64016</td>\n",
              "      <td>121.35066</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-09</th>\n",
              "      <td>BTC</td>\n",
              "      <td>124.04900</td>\n",
              "      <td>123.03300</td>\n",
              "      <td>124.78350</td>\n",
              "      <td>122.59266</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-10</th>\n",
              "      <td>BTC</td>\n",
              "      <td>125.96116</td>\n",
              "      <td>124.04900</td>\n",
              "      <td>128.01683</td>\n",
              "      <td>123.81966</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Currency  Closing Price (USD)  ...  24h Low (USD)  day_of_week\n",
              "Date                                      ...                            \n",
              "2013-10-01      BTC            123.65499  ...      122.56349            1\n",
              "2013-10-02      BTC            125.45500  ...      123.63383            2\n",
              "2013-10-03      BTC            108.58483  ...       83.32833            3\n",
              "2013-10-04      BTC            118.67466  ...      107.05816            4\n",
              "2013-10-05      BTC            121.33866  ...      118.00566            5\n",
              "2013-10-06      BTC            120.65533  ...      120.55450            6\n",
              "2013-10-07      BTC            121.79500  ...      120.43199            0\n",
              "2013-10-08      BTC            123.03300  ...      121.35066            1\n",
              "2013-10-09      BTC            124.04900  ...      122.59266            2\n",
              "2013-10-10      BTC            125.96116  ...      123.81966            3\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppVyHOd9pZUC"
      },
      "source": [
        "# Defining the hyper parameters \n",
        "HORIZON = 1 \n",
        "WINDOW_SIZE = 7 \n",
        "\n",
        "bitcoin_prices_windowed['day_of_week'] = bitcoin_prices_windowed.index.dayofweek"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6zN_LcoqCca"
      },
      "source": [
        "# Getting three kinds of data (univariate , multivariate and the day of week)\n",
        "\n",
        "# Univariate data \n",
        "full_windows , full_labels = make_windows_scaled(prices)\n",
        "train_windows , test_windows , train_labels , test_labels = make_train_test_splits(full_windows , full_labels)\n",
        "\n",
        "# Multivaritate dat \n",
        "X = bitcoin_prices_windowed.dropna().drop('Price' , axis = 1).astype(np.float32)\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "y = bitcoin_prices_windowed.dropna()['Price'].astype(np.float32)\n",
        "\n",
        "# Day of week \n",
        "day_of_week = bitcoin_prices_windowed.dropna()['day_of_week'].to_list()"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YCJnEBEzj69",
        "outputId": "0476b879-8acf-4fee-bdbb-4cfe0afe0cf1"
      },
      "source": [
        "# Checking the shapes \n",
        "print(full_windows.shape , full_labels.shape)\n",
        "print(X.shape , y.shape)\n",
        "print(len(day_of_week))"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2780, 7) (2780, 1)\n",
            "(2780, 9) (2780,)\n",
            "2780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvJBEkZR4XVp",
        "outputId": "73065803-f751-48fa-ca83-0393b22ff085"
      },
      "source": [
        "# Splitting the multivariate and the day_of_week to train and test splits \n",
        "split_size = int(len(X) * 0.8)\n",
        "train_block_rewards , test_block_rewards = X[:split_size] , X[split_size:]\n",
        "train_days , test_days = day_of_week[:split_size] , day_of_week[split_size:]\n",
        " \n",
        "len(train_block_rewards), len(train_days) , len(test_block_rewards) , len(test_days)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2224, 2224, 556, 556)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQd1NpWSzke0",
        "outputId": "eb24cf82-1acc-4692-ef41-e443c8985c79"
      },
      "source": [
        "# Building a performant dataset for train and test \n",
        "\n",
        "train_data_tribid = tf.data.Dataset.from_tensor_slices((train_windows , \n",
        "                                                        train_block_rewards , \n",
        "                                                        train_days))\n",
        "\n",
        "train_labels_tribid = tf.data.Dataset.from_tensor_slices(train_labels)\n",
        "\n",
        "# The test/val split \n",
        "test_data_tribid = tf.data.Dataset.from_tensor_slices((test_windows , \n",
        "                                                       test_block_rewards , \n",
        "                                                       test_days))\n",
        "\n",
        "test_labels_tribid = tf.data.Dataset.from_tensor_slices(test_labels)\n",
        "\n",
        "# Zipping the data and labels into one complete dataset \n",
        "tribid_train_ds = tf.data.Dataset.zip((train_data_tribid , train_labels_tribid))\n",
        "tribid_test_ds = tf.data.Dataset.zip((test_data_tribid , test_labels_tribid))\n",
        "\n",
        "# Applying prefetch and batching the dataset \n",
        "tribid_train_ds = tribid_train_ds.batch(128).prefetch(tf.data.AUTOTUNE)\n",
        "tribid_test_ds = tribid_test_ds.batch(128).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "tribid_train_ds ,tribid_test_ds"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PrefetchDataset shapes: (((None, 7), (None, 9), (None,)), (None, 1)), types: ((tf.float64, tf.float32, tf.int32), tf.float64)>,\n",
              " <PrefetchDataset shapes: (((None, 7), (None, 9), (None,)), (None, 1)), types: ((tf.float64, tf.float32, tf.int32), tf.float64)>)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyhukkUSzmu8",
        "outputId": "1a0f1095-b275-468e-f361-57a6836090fd"
      },
      "source": [
        "# Building a tribid model \n",
        "\n",
        "input_windows = layers.Input(shape = (7,) , dtype=tf.float64 , name='Window Inputs')\n",
        "exp_layer_1 = layers.Lambda(lambda x: tf.expand_dims(x , axis = 1))(input_windows)\n",
        "conv1 = layers.Conv1D(filters= 32 , kernel_size=5 , padding='causal' , activation= 'relu')(exp_layer_1)\n",
        "window_model = tf.keras.Model(input_windows , conv1 , name = 'Windowed model')\n",
        "\n",
        "input_blocks = layers.Input(shape = (9,) , dtype= tf.float32 , name ='Block rewards input')\n",
        "exp_layer_2 = layers.Lambda(lambda x: tf.expand_dims(x , axis = 1))(input_blocks)\n",
        "conv2 = layers.Conv1D(filters = 32 , kernel_size= 5 , activation= 'relu' , padding = 'causal')(exp_layer_2)\n",
        "block_model = tf.keras.Model(input_blocks , conv2 , name = 'Block rewards model')\n",
        "\n",
        "\n",
        "# Use expand dims to match the same shape output (None , 1 , 128)\n",
        "# whereas without expand dims it would be (None , 128)\n",
        "input_days = layers.Input(shape= (1,) , dtype = tf.int32 , name ='Days of week Input')\n",
        "exp_layer_3 = layers.Lambda(lambda x: tf.expand_dims(x , axis = 1))(input_days)\n",
        "dense = layers.Dense(128 , activation= 'relu')(exp_layer_3)\n",
        "days_model = tf.keras.Model(input_days , dense , name = 'Days Model')\n",
        "\n",
        "# Concatenating the inputs \n",
        "concat = layers.Concatenate(name = 'combined_outputs' )([window_model.output , \n",
        "                                                           block_model.output , \n",
        "                                                           days_model.output])\n",
        "\n",
        "# Creating the output layer \n",
        "dropout = layers.Dropout(0.4)(concat)\n",
        "output_layer = layers.Dense(1 , activation = 'linear')(dropout)\n",
        "\n",
        "# Putting everything into a model \n",
        "tribid_model = tf.keras.Model(inputs = [window_model.input , \n",
        "                                        block_model.input , \n",
        "                                        days_model.input] , \n",
        "                              outputs = output_layer)\n",
        "tribid_model.summary()\n",
        "\n"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Window Inputs (InputLayer)      [(None, 7)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Block rewards input (InputLayer [(None, 9)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Days of week Input (InputLayer) [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_26 (Lambda)              (None, 1, 7)         0           Window Inputs[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_27 (Lambda)              (None, 1, 9)         0           Block rewards input[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "lambda_28 (Lambda)              (None, 1, 1)         0           Days of week Input[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_19 (Conv1D)              (None, 1, 32)        1152        lambda_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_20 (Conv1D)              (None, 1, 32)        1472        lambda_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 1, 128)       256         lambda_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "combined_outputs (Concatenate)  (None, 1, 192)       0           conv1d_19[0][0]                  \n",
            "                                                                 conv1d_20[0][0]                  \n",
            "                                                                 dense_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 1, 192)       0           combined_outputs[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 1, 1)         193         dropout_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 3,073\n",
            "Trainable params: 3,073\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDB8vFtu17Rp",
        "outputId": "62457f54-50a8-4fda-a94c-8bcc9b83bce6"
      },
      "source": [
        "# Compiling and fitting the model \n",
        "tribid_model.compile(loss = 'mae' , \n",
        "                     optimizer = 'adam' , metrics = ['mae'])\n",
        "\n",
        "# Fitting the model \n",
        "tribid_model.fit(tribid_train_ds , \n",
        "                 epochs = 20,  \n",
        "                 validation_data = tribid_test_ds , verbose = 2)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "18/18 - 1s - loss: 29.1395 - mae: 29.1395 - val_loss: 12.8604 - val_mae: 12.8604\n",
            "Epoch 2/20\n",
            "18/18 - 0s - loss: 5.7451 - mae: 5.7451 - val_loss: 7.9342 - val_mae: 7.9342\n",
            "Epoch 3/20\n",
            "18/18 - 0s - loss: 1.1152 - mae: 1.1152 - val_loss: 3.3295 - val_mae: 3.3295\n",
            "Epoch 4/20\n",
            "18/18 - 0s - loss: 0.4115 - mae: 0.4115 - val_loss: 0.4594 - val_mae: 0.4594\n",
            "Epoch 5/20\n",
            "18/18 - 0s - loss: 0.8504 - mae: 0.8504 - val_loss: 1.9727 - val_mae: 1.9727\n",
            "Epoch 6/20\n",
            "18/18 - 0s - loss: 1.0429 - mae: 1.0429 - val_loss: 0.7200 - val_mae: 0.7200\n",
            "Epoch 7/20\n",
            "18/18 - 0s - loss: 0.8757 - mae: 0.8757 - val_loss: 2.0799 - val_mae: 2.0799\n",
            "Epoch 8/20\n",
            "18/18 - 0s - loss: 0.2225 - mae: 0.2225 - val_loss: 0.0813 - val_mae: 0.0813\n",
            "Epoch 9/20\n",
            "18/18 - 0s - loss: 0.1704 - mae: 0.1704 - val_loss: 0.1398 - val_mae: 0.1398\n",
            "Epoch 10/20\n",
            "18/18 - 0s - loss: 0.1544 - mae: 0.1544 - val_loss: 0.0908 - val_mae: 0.0908\n",
            "Epoch 11/20\n",
            "18/18 - 0s - loss: 0.1410 - mae: 0.1410 - val_loss: 0.0821 - val_mae: 0.0821\n",
            "Epoch 12/20\n",
            "18/18 - 0s - loss: 0.1284 - mae: 0.1284 - val_loss: 0.0624 - val_mae: 0.0624\n",
            "Epoch 13/20\n",
            "18/18 - 0s - loss: 0.1218 - mae: 0.1218 - val_loss: 0.0647 - val_mae: 0.0647\n",
            "Epoch 14/20\n",
            "18/18 - 0s - loss: 0.1086 - mae: 0.1086 - val_loss: 0.0442 - val_mae: 0.0442\n",
            "Epoch 15/20\n",
            "18/18 - 0s - loss: 0.1053 - mae: 0.1053 - val_loss: 0.0582 - val_mae: 0.0582\n",
            "Epoch 16/20\n",
            "18/18 - 0s - loss: 0.0953 - mae: 0.0953 - val_loss: 0.0374 - val_mae: 0.0374\n",
            "Epoch 17/20\n",
            "18/18 - 0s - loss: 0.0892 - mae: 0.0892 - val_loss: 0.0437 - val_mae: 0.0437\n",
            "Epoch 18/20\n",
            "18/18 - 0s - loss: 0.0774 - mae: 0.0774 - val_loss: 0.0319 - val_mae: 0.0319\n",
            "Epoch 19/20\n",
            "18/18 - 0s - loss: 0.0723 - mae: 0.0723 - val_loss: 0.0304 - val_mae: 0.0304\n",
            "Epoch 20/20\n",
            "18/18 - 0s - loss: 0.0643 - mae: 0.0643 - val_loss: 0.0296 - val_mae: 0.0296\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d8be37250>"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzCKgn8598cB",
        "outputId": "1fc41717-e8ed-42c0-c26b-c7e2e2583c4b"
      },
      "source": [
        "# Evaluating the model \n",
        "tribid_model.evaluate(tribid_test_ds)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0296 - mae: 0.0296\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.029597144573926926, 0.029597144573926926]"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaqbrn-xnnjW"
      },
      "source": [
        "### 6. Make prediction intervals for future forecasts. To do so, one way would be to train an ensemble model on all of the data, make future forecasts with it and calculate the prediction intervals of the ensemble just like we did for model_8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuGAuQZpovQ9"
      },
      "source": [
        "**Things to do**\n",
        "- Train an ensemble model on the whole data. \n",
        "- Make one dataset (no test/valid) which will use to predict future forecasts of bitcoins. \n",
        "- Make a function that will take the number of iterations and different loss functions to train the model with. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS_NBQuqt5Bb",
        "outputId": "398f40e4-c141-4ff1-adc9-460502c786e1"
      },
      "source": [
        "# Make one whole dataset (with the updated bitcoin prices 2014 - 2021)\n",
        "\n",
        "X_all = bitcoin_prices_windowed.drop(['Price' , 'block_reward' , 'day_of_week'] , axis = 1).dropna().to_numpy()\n",
        "y_all = bitcoin_prices_windowed.dropna()['Price'].to_numpy()\n",
        "\n",
        "whole_ds = tf.data.Dataset.from_tensor_slices((X_all , y_all))\n",
        "whole_ds = whole_ds.batch(128).prefetch(tf.data.AUTOTUNE)\n",
        "whole_ds"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, 7), (None,)), types: (tf.float64, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5zZCOdSvBDX"
      },
      "source": [
        "# Creating the function \n",
        "\n",
        "def get_ensemble_models(horizon = HORIZON , \n",
        "                        dataset = whole_ds , \n",
        "                        num_iter = 10 , \n",
        "                        num_epochs = 100 , \n",
        "                        loss_fns = ['mae' , 'mse' , 'mape']):\n",
        "  \n",
        "\n",
        "  # Make a empty list of the ensemble models \n",
        "  ensemble_models = []\n",
        "\n",
        "  # Create num_iter number of models per loss functions \n",
        "  for i in range(num_iter):\n",
        "    for loss_functions in loss_fns:\n",
        "      print(f'Optimizing model by reducing: {loss_functions} for {num_epochs} epochs, model number: {i}')\n",
        "\n",
        "      model = tf.keras.Sequential([\n",
        "          layers.Dense(128 , kernel_initializer='he_normal' , activation= 'relu'),\n",
        "          layers.Dense(128 , kernel_initializer= 'he_normal', activation= 'relu'),\n",
        "          layers.Dense(HORIZON)\n",
        "      ])\n",
        "\n",
        "      # Compiling the model \n",
        "      model.compile(loss = loss_functions , \n",
        "                    optimizer = 'adam' , metrics = ['mae' , 'mse'])\n",
        "      \n",
        "      # Fit the model \n",
        "      model.fit(dataset , \n",
        "                epochs = num_epochs , \n",
        "                verbose = 0,\n",
        "                callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"loss\",\n",
        "                                                            patience=200,\n",
        "                                                            restore_best_weights=True),\n",
        "                           tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\",\n",
        "                                                                patience=100,\n",
        "                                                                verbose=1)])\n",
        "      \n",
        "      ensemble_models.append(model)\n",
        "\n",
        "  return ensemble_models"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btGEQNfLvCXL",
        "outputId": "ce60a801-4b4b-4da1-b213-232c3b45690c"
      },
      "source": [
        "# Running the above function \n",
        "ensemble_models = get_ensemble_models(num_iter=5 , num_epochs= 1000 , horizon = 1)"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizing model by reducing: mae for 1000 epochs, model number: 0\n",
            "\n",
            "Epoch 00229: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00351: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mse for 1000 epochs, model number: 0\n",
            "\n",
            "Epoch 00146: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00429: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mape for 1000 epochs, model number: 0\n",
            "\n",
            "Epoch 00157: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00259: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 00380: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Optimizing model by reducing: mae for 1000 epochs, model number: 1\n",
            "\n",
            "Epoch 00313: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00440: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mse for 1000 epochs, model number: 1\n",
            "\n",
            "Epoch 00127: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00417: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mape for 1000 epochs, model number: 1\n",
            "\n",
            "Epoch 00139: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00241: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 00342: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Optimizing model by reducing: mae for 1000 epochs, model number: 2\n",
            "\n",
            "Epoch 00262: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00387: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mse for 1000 epochs, model number: 2\n",
            "\n",
            "Epoch 00109: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00387: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mape for 1000 epochs, model number: 2\n",
            "\n",
            "Epoch 00226: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00328: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 00429: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Optimizing model by reducing: mae for 1000 epochs, model number: 3\n",
            "\n",
            "Epoch 00334: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00492: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mse for 1000 epochs, model number: 3\n",
            "\n",
            "Epoch 00104: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00389: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mape for 1000 epochs, model number: 3\n",
            "\n",
            "Epoch 00491: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00591: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mae for 1000 epochs, model number: 4\n",
            "\n",
            "Epoch 00301: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00420: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mse for 1000 epochs, model number: 4\n",
            "\n",
            "Epoch 00180: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00475: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Optimizing model by reducing: mape for 1000 epochs, model number: 4\n",
            "\n",
            "Epoch 00363: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00465: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 00566: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM4bW2EN__jH"
      },
      "source": [
        "# Making future forecastts \n",
        "def make_future_forecast(values , model_list , into_future , window_size):\n",
        "\n",
        "  future_forecast = []\n",
        "  last_window = values[-window_size:]\n",
        "\n",
        "  for _ in range(into_future): \n",
        "    for model in model_list:\n",
        "    \n",
        "      future_pred = model.predict(tf.expand_dims(last_window, axis= 0))\n",
        "      #future_pred = model.predict(last_window)\n",
        "      print(f'Predicing on: \\n {last_window} --> Prediction: {tf.squeeze(future_pred).numpy()}\\n')\n",
        "\n",
        "      future_forecast.append(tf.squeeze(future_pred).numpy())\n",
        "\n",
        "      # Update the last window \n",
        "      last_window = np.append(last_window , future_pred)[-window_size:]\n",
        "  return future_forecast"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG-C8sGguG-o",
        "outputId": "f4102c4d-ac2b-42d0-d59f-a821b58ae54d"
      },
      "source": [
        "# Getting the future forecast \n",
        "future_forecast = make_future_forecast(y_all , ensemble_models , into_future= 14 , window_size = 7 )"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicing on: \n",
            " [56573.5554719  52147.82118698 49764.1320816  50032.69313676\n",
            " 47885.62525472 45604.61575361 43144.47129086] --> Prediction: 56227.828125\n",
            "\n",
            "Predicing on: \n",
            " [52147.82118698 49764.1320816  50032.69313676 47885.62525472\n",
            " 45604.61575361 43144.47129086 56227.828125  ] --> Prediction: 49828.5390625\n",
            "\n",
            "Predicing on: \n",
            " [49764.1320816  50032.69313676 47885.62525472 45604.61575361\n",
            " 43144.47129086 56227.828125   49828.5390625 ] --> Prediction: 50025.203125\n",
            "\n",
            "Predicing on: \n",
            " [50032.69313676 47885.62525472 45604.61575361 43144.47129086\n",
            " 56227.828125   49828.5390625  50025.203125  ] --> Prediction: 50599.34765625\n",
            "\n",
            "Predicing on: \n",
            " [47885.62525472 45604.61575361 43144.47129086 56227.828125\n",
            " 49828.5390625  50025.203125   50599.34765625] --> Prediction: 48159.0078125\n",
            "\n",
            "Predicing on: \n",
            " [45604.61575361 43144.47129086 56227.828125   49828.5390625\n",
            " 50025.203125   50599.34765625 48159.0078125 ] --> Prediction: 46780.62109375\n",
            "\n",
            "Predicing on: \n",
            " [43144.47129086 56227.828125   49828.5390625  50025.203125\n",
            " 50599.34765625 48159.0078125  46780.62109375] --> Prediction: 45299.06640625\n",
            "\n",
            "Predicing on: \n",
            " [56227.828125   49828.5390625  50025.203125   50599.34765625\n",
            " 48159.0078125  46780.62109375 45299.06640625] --> Prediction: 56340.25\n",
            "\n",
            "Predicing on: \n",
            " [49828.5390625  50025.203125   50599.34765625 48159.0078125\n",
            " 46780.62109375 45299.06640625 56340.25      ] --> Prediction: 49518.02734375\n",
            "\n",
            "Predicing on: \n",
            " [50025.203125   50599.34765625 48159.0078125  46780.62109375\n",
            " 45299.06640625 56340.25       49518.02734375] --> Prediction: 51237.00390625\n",
            "\n",
            "Predicing on: \n",
            " [50599.34765625 48159.0078125  46780.62109375 45299.06640625\n",
            " 56340.25       49518.02734375 51237.00390625] --> Prediction: 50680.80859375\n",
            "\n",
            "Predicing on: \n",
            " [48159.0078125  46780.62109375 45299.06640625 56340.25\n",
            " 49518.02734375 51237.00390625 50680.80859375] --> Prediction: 48158.44140625\n",
            "\n",
            "Predicing on: \n",
            " [46780.62109375 45299.06640625 56340.25       49518.02734375\n",
            " 51237.00390625 50680.80859375 48158.44140625] --> Prediction: 46740.5546875\n",
            "\n",
            "Predicing on: \n",
            " [45299.06640625 56340.25       49518.02734375 51237.00390625\n",
            " 50680.80859375 48158.44140625 46740.5546875 ] --> Prediction: 47897.1328125\n",
            "\n",
            "Predicing on: \n",
            " [56340.25       49518.02734375 51237.00390625 50680.80859375\n",
            " 48158.44140625 46740.5546875  47897.1328125 ] --> Prediction: 56218.0703125\n",
            "\n",
            "Predicing on: \n",
            " [49518.02734375 51237.00390625 50680.80859375 48158.44140625\n",
            " 46740.5546875  47897.1328125  56218.0703125 ] --> Prediction: 49063.52734375\n",
            "\n",
            "Predicing on: \n",
            " [51237.00390625 50680.80859375 48158.44140625 46740.5546875\n",
            " 47897.1328125  56218.0703125  49063.52734375] --> Prediction: 53053.09765625\n",
            "\n",
            "Predicing on: \n",
            " [50680.80859375 48158.44140625 46740.5546875  47897.1328125\n",
            " 56218.0703125  49063.52734375 53053.09765625] --> Prediction: 50549.11328125\n",
            "\n",
            "Predicing on: \n",
            " [48158.44140625 46740.5546875  47897.1328125  56218.0703125\n",
            " 49063.52734375 53053.09765625 50549.11328125] --> Prediction: 47712.7734375\n",
            "\n",
            "Predicing on: \n",
            " [46740.5546875  47897.1328125  56218.0703125  49063.52734375\n",
            " 53053.09765625 50549.11328125 47712.7734375 ] --> Prediction: 46142.48828125\n",
            "\n",
            "Predicing on: \n",
            " [47897.1328125  56218.0703125  49063.52734375 53053.09765625\n",
            " 50549.11328125 47712.7734375  46142.48828125] --> Prediction: 48763.32421875\n",
            "\n",
            "Predicing on: \n",
            " [56218.0703125  49063.52734375 53053.09765625 50549.11328125\n",
            " 47712.7734375  46142.48828125 48763.32421875] --> Prediction: 55409.8671875\n",
            "\n",
            "Predicing on: \n",
            " [49063.52734375 53053.09765625 50549.11328125 47712.7734375\n",
            " 46142.48828125 48763.32421875 55409.8671875 ] --> Prediction: 50567.01953125\n",
            "\n",
            "Predicing on: \n",
            " [53053.09765625 50549.11328125 47712.7734375  46142.48828125\n",
            " 48763.32421875 55409.8671875  50567.01953125] --> Prediction: 52846.25390625\n",
            "\n",
            "Predicing on: \n",
            " [50549.11328125 47712.7734375  46142.48828125 48763.32421875\n",
            " 55409.8671875  50567.01953125 52846.25390625] --> Prediction: 50168.2109375\n",
            "\n",
            "Predicing on: \n",
            " [47712.7734375  46142.48828125 48763.32421875 55409.8671875\n",
            " 50567.01953125 52846.25390625 50168.2109375 ] --> Prediction: 47173.1015625\n",
            "\n",
            "Predicing on: \n",
            " [46142.48828125 48763.32421875 55409.8671875  50567.01953125\n",
            " 52846.25390625 50168.2109375  47173.1015625 ] --> Prediction: 46356.50390625\n",
            "\n",
            "Predicing on: \n",
            " [48763.32421875 55409.8671875  50567.01953125 52846.25390625\n",
            " 50168.2109375  47173.1015625  46356.50390625] --> Prediction: 49590.3671875\n",
            "\n",
            "Predicing on: \n",
            " [55409.8671875  50567.01953125 52846.25390625 50168.2109375\n",
            " 47173.1015625  46356.50390625 49590.3671875 ] --> Prediction: 55333.7265625\n",
            "\n",
            "Predicing on: \n",
            " [50567.01953125 52846.25390625 50168.2109375  47173.1015625\n",
            " 46356.50390625 49590.3671875  55333.7265625 ] --> Prediction: 50657.3515625\n",
            "\n",
            "Predicing on: \n",
            " [52846.25390625 50168.2109375  47173.1015625  46356.50390625\n",
            " 49590.3671875  55333.7265625  50657.3515625 ] --> Prediction: 53008.36328125\n",
            "\n",
            "Predicing on: \n",
            " [50168.2109375  47173.1015625  46356.50390625 49590.3671875\n",
            " 55333.7265625  50657.3515625  53008.36328125] --> Prediction: 50298.07421875\n",
            "\n",
            "Predicing on: \n",
            " [47173.1015625  46356.50390625 49590.3671875  55333.7265625\n",
            " 50657.3515625  53008.36328125 50298.07421875] --> Prediction: 46832.69140625\n",
            "\n",
            "Predicing on: \n",
            " [46356.50390625 49590.3671875  55333.7265625  50657.3515625\n",
            " 53008.36328125 50298.07421875 46832.69140625] --> Prediction: 46764.9140625\n",
            "\n",
            "Predicing on: \n",
            " [49590.3671875  55333.7265625  50657.3515625  53008.36328125\n",
            " 50298.07421875 46832.69140625 46764.9140625 ] --> Prediction: 50185.4765625\n",
            "\n",
            "Predicing on: \n",
            " [55333.7265625  50657.3515625  53008.36328125 50298.07421875\n",
            " 46832.69140625 46764.9140625  50185.4765625 ] --> Prediction: 56248.953125\n",
            "\n",
            "Predicing on: \n",
            " [50657.3515625  53008.36328125 50298.07421875 46832.69140625\n",
            " 46764.9140625  50185.4765625  56248.953125  ] --> Prediction: 50930.5625\n",
            "\n",
            "Predicing on: \n",
            " [53008.36328125 50298.07421875 46832.69140625 46764.9140625\n",
            " 50185.4765625  56248.953125   50930.5625    ] --> Prediction: 53073.8046875\n",
            "\n",
            "Predicing on: \n",
            " [50298.07421875 46832.69140625 46764.9140625  50185.4765625\n",
            " 56248.953125   50930.5625     53073.8046875 ] --> Prediction: 49743.7578125\n",
            "\n",
            "Predicing on: \n",
            " [46832.69140625 46764.9140625  50185.4765625  56248.953125\n",
            " 50930.5625     53073.8046875  49743.7578125 ] --> Prediction: 46636.63671875\n",
            "\n",
            "Predicing on: \n",
            " [46764.9140625  50185.4765625  56248.953125   50930.5625\n",
            " 53073.8046875  49743.7578125  46636.63671875] --> Prediction: 46772.04296875\n",
            "\n",
            "Predicing on: \n",
            " [50185.4765625  56248.953125   50930.5625     53073.8046875\n",
            " 49743.7578125  46636.63671875 46772.04296875] --> Prediction: 50631.6484375\n",
            "\n",
            "Predicing on: \n",
            " [56248.953125   50930.5625     53073.8046875  49743.7578125\n",
            " 46636.63671875 46772.04296875 50631.6484375 ] --> Prediction: 55741.62109375\n",
            "\n",
            "Predicing on: \n",
            " [50930.5625     53073.8046875  49743.7578125  46636.63671875\n",
            " 46772.04296875 50631.6484375  55741.62109375] --> Prediction: 50724.6171875\n",
            "\n",
            "Predicing on: \n",
            " [53073.8046875  49743.7578125  46636.63671875 46772.04296875\n",
            " 50631.6484375  55741.62109375 50724.6171875 ] --> Prediction: 53062.9609375\n",
            "\n",
            "Predicing on: \n",
            " [49743.7578125  46636.63671875 46772.04296875 50631.6484375\n",
            " 55741.62109375 50724.6171875  53062.9609375 ] --> Prediction: 49040.25\n",
            "\n",
            "Predicing on: \n",
            " [46636.63671875 46772.04296875 50631.6484375  55741.62109375\n",
            " 50724.6171875  53062.9609375  49040.25      ] --> Prediction: 47358.484375\n",
            "\n",
            "Predicing on: \n",
            " [46772.04296875 50631.6484375  55741.62109375 50724.6171875\n",
            " 53062.9609375  49040.25       47358.484375  ] --> Prediction: 47173.15234375\n",
            "\n",
            "Predicing on: \n",
            " [50631.6484375  55741.62109375 50724.6171875  53062.9609375\n",
            " 49040.25       47358.484375   47173.15234375] --> Prediction: 51284.609375\n",
            "\n",
            "Predicing on: \n",
            " [55741.62109375 50724.6171875  53062.9609375  49040.25\n",
            " 47358.484375   47173.15234375 51284.609375  ] --> Prediction: 55764.17578125\n",
            "\n",
            "Predicing on: \n",
            " [50724.6171875  53062.9609375  49040.25       47358.484375\n",
            " 47173.15234375 51284.609375   55764.17578125] --> Prediction: 50457.828125\n",
            "\n",
            "Predicing on: \n",
            " [53062.9609375  49040.25       47358.484375   47173.15234375\n",
            " 51284.609375   55764.17578125 50457.828125  ] --> Prediction: 52901.89453125\n",
            "\n",
            "Predicing on: \n",
            " [49040.25       47358.484375   47173.15234375 51284.609375\n",
            " 55764.17578125 50457.828125   52901.89453125] --> Prediction: 47626.50390625\n",
            "\n",
            "Predicing on: \n",
            " [47358.484375   47173.15234375 51284.609375   55764.17578125\n",
            " 50457.828125   52901.89453125 47626.50390625] --> Prediction: 47265.00390625\n",
            "\n",
            "Predicing on: \n",
            " [47173.15234375 51284.609375   55764.17578125 50457.828125\n",
            " 52901.89453125 47626.50390625 47265.00390625] --> Prediction: 47882.171875\n",
            "\n",
            "Predicing on: \n",
            " [51284.609375   55764.17578125 50457.828125   52901.89453125\n",
            " 47626.50390625 47265.00390625 47882.171875  ] --> Prediction: 51134.34375\n",
            "\n",
            "Predicing on: \n",
            " [55764.17578125 50457.828125   52901.89453125 47626.50390625\n",
            " 47265.00390625 47882.171875   51134.34375   ] --> Prediction: 55489.82421875\n",
            "\n",
            "Predicing on: \n",
            " [50457.828125   52901.89453125 47626.50390625 47265.00390625\n",
            " 47882.171875   51134.34375    55489.82421875] --> Prediction: 50258.734375\n",
            "\n",
            "Predicing on: \n",
            " [52901.89453125 47626.50390625 47265.00390625 47882.171875\n",
            " 51134.34375    55489.82421875 50258.734375  ] --> Prediction: 53402.42578125\n",
            "\n",
            "Predicing on: \n",
            " [47626.50390625 47265.00390625 47882.171875   51134.34375\n",
            " 55489.82421875 50258.734375   53402.42578125] --> Prediction: 47799.6171875\n",
            "\n",
            "Predicing on: \n",
            " [47265.00390625 47882.171875   51134.34375    55489.82421875\n",
            " 50258.734375   53402.42578125 47799.6171875 ] --> Prediction: 47141.984375\n",
            "\n",
            "Predicing on: \n",
            " [47882.171875   51134.34375    55489.82421875 50258.734375\n",
            " 53402.42578125 47799.6171875  47141.984375  ] --> Prediction: 48070.79296875\n",
            "\n",
            "Predicing on: \n",
            " [51134.34375    55489.82421875 50258.734375   53402.42578125\n",
            " 47799.6171875  47141.984375   48070.79296875] --> Prediction: 51662.4765625\n",
            "\n",
            "Predicing on: \n",
            " [55489.82421875 50258.734375   53402.42578125 47799.6171875\n",
            " 47141.984375   48070.79296875 51662.4765625 ] --> Prediction: 54958.90625\n",
            "\n",
            "Predicing on: \n",
            " [50258.734375   53402.42578125 47799.6171875  47141.984375\n",
            " 48070.79296875 51662.4765625  54958.90625   ] --> Prediction: 49971.3671875\n",
            "\n",
            "Predicing on: \n",
            " [53402.42578125 47799.6171875  47141.984375   48070.79296875\n",
            " 51662.4765625  54958.90625    49971.3671875 ] --> Prediction: 53603.49609375\n",
            "\n",
            "Predicing on: \n",
            " [47799.6171875  47141.984375   48070.79296875 51662.4765625\n",
            " 54958.90625    49971.3671875  53603.49609375] --> Prediction: 47093.3203125\n",
            "\n",
            "Predicing on: \n",
            " [47141.984375   48070.79296875 51662.4765625  54958.90625\n",
            " 49971.3671875  53603.49609375 47093.3203125 ] --> Prediction: 48407.44140625\n",
            "\n",
            "Predicing on: \n",
            " [48070.79296875 51662.4765625  54958.90625    49971.3671875\n",
            " 53603.49609375 47093.3203125  48407.44140625] --> Prediction: 48051.0078125\n",
            "\n",
            "Predicing on: \n",
            " [51662.4765625  54958.90625    49971.3671875  53603.49609375\n",
            " 47093.3203125  48407.44140625 48051.0078125 ] --> Prediction: 52466.60546875\n",
            "\n",
            "Predicing on: \n",
            " [54958.90625    49971.3671875  53603.49609375 47093.3203125\n",
            " 48407.44140625 48051.0078125  52466.60546875] --> Prediction: 55576.88671875\n",
            "\n",
            "Predicing on: \n",
            " [49971.3671875  53603.49609375 47093.3203125  48407.44140625\n",
            " 48051.0078125  52466.60546875 55576.88671875] --> Prediction: 50247.05078125\n",
            "\n",
            "Predicing on: \n",
            " [53603.49609375 47093.3203125  48407.44140625 48051.0078125\n",
            " 52466.60546875 55576.88671875 50247.05078125] --> Prediction: 53185.8671875\n",
            "\n",
            "Predicing on: \n",
            " [47093.3203125  48407.44140625 48051.0078125  52466.60546875\n",
            " 55576.88671875 50247.05078125 53185.8671875 ] --> Prediction: 46653.16796875\n",
            "\n",
            "Predicing on: \n",
            " [48407.44140625 48051.0078125  52466.60546875 55576.88671875\n",
            " 50247.05078125 53185.8671875  46653.16796875] --> Prediction: 48407.3828125\n",
            "\n",
            "Predicing on: \n",
            " [48051.0078125  52466.60546875 55576.88671875 50247.05078125\n",
            " 53185.8671875  46653.16796875 48407.3828125 ] --> Prediction: 49062.27734375\n",
            "\n",
            "Predicing on: \n",
            " [52466.60546875 55576.88671875 50247.05078125 53185.8671875\n",
            " 46653.16796875 48407.3828125  49062.27734375] --> Prediction: 53741.625\n",
            "\n",
            "Predicing on: \n",
            " [55576.88671875 50247.05078125 53185.8671875  46653.16796875\n",
            " 48407.3828125  49062.27734375 53741.625     ] --> Prediction: 55274.87890625\n",
            "\n",
            "Predicing on: \n",
            " [50247.05078125 53185.8671875  46653.16796875 48407.3828125\n",
            " 49062.27734375 53741.625      55274.87890625] --> Prediction: 50849.98828125\n",
            "\n",
            "Predicing on: \n",
            " [53185.8671875  46653.16796875 48407.3828125  49062.27734375\n",
            " 53741.625      55274.87890625 50849.98828125] --> Prediction: 52203.8046875\n",
            "\n",
            "Predicing on: \n",
            " [46653.16796875 48407.3828125  49062.27734375 53741.625\n",
            " 55274.87890625 50849.98828125 52203.8046875 ] --> Prediction: 46656.47265625\n",
            "\n",
            "Predicing on: \n",
            " [48407.3828125  49062.27734375 53741.625      55274.87890625\n",
            " 50849.98828125 52203.8046875  46656.47265625] --> Prediction: 48625.703125\n",
            "\n",
            "Predicing on: \n",
            " [49062.27734375 53741.625      55274.87890625 50849.98828125\n",
            " 52203.8046875  46656.47265625 48625.703125  ] --> Prediction: 49130.3125\n",
            "\n",
            "Predicing on: \n",
            " [53741.625      55274.87890625 50849.98828125 52203.8046875\n",
            " 46656.47265625 48625.703125   49130.3125    ] --> Prediction: 53913.48828125\n",
            "\n",
            "Predicing on: \n",
            " [55274.87890625 50849.98828125 52203.8046875  46656.47265625\n",
            " 48625.703125   49130.3125     53913.48828125] --> Prediction: 54508.34375\n",
            "\n",
            "Predicing on: \n",
            " [50849.98828125 52203.8046875  46656.47265625 48625.703125\n",
            " 49130.3125     53913.48828125 54508.34375   ] --> Prediction: 50607.65625\n",
            "\n",
            "Predicing on: \n",
            " [52203.8046875  46656.47265625 48625.703125   49130.3125\n",
            " 53913.48828125 54508.34375    50607.65625   ] --> Prediction: 52205.0546875\n",
            "\n",
            "Predicing on: \n",
            " [46656.47265625 48625.703125   49130.3125     53913.48828125\n",
            " 54508.34375    50607.65625    52205.0546875 ] --> Prediction: 46129.9375\n",
            "\n",
            "Predicing on: \n",
            " [48625.703125   49130.3125     53913.48828125 54508.34375\n",
            " 50607.65625    52205.0546875  46129.9375    ] --> Prediction: 48707.76953125\n",
            "\n",
            "Predicing on: \n",
            " [49130.3125     53913.48828125 54508.34375    50607.65625\n",
            " 52205.0546875  46129.9375     48707.76953125] --> Prediction: 49324.6328125\n",
            "\n",
            "Predicing on: \n",
            " [53913.48828125 54508.34375    50607.65625    52205.0546875\n",
            " 46129.9375     48707.76953125 49324.6328125 ] --> Prediction: 54502.48828125\n",
            "\n",
            "Predicing on: \n",
            " [54508.34375    50607.65625    52205.0546875  46129.9375\n",
            " 48707.76953125 49324.6328125  54502.48828125] --> Prediction: 54453.18359375\n",
            "\n",
            "Predicing on: \n",
            " [50607.65625    52205.0546875  46129.9375     48707.76953125\n",
            " 49324.6328125  54502.48828125 54453.18359375] --> Prediction: 50651.08203125\n",
            "\n",
            "Predicing on: \n",
            " [52205.0546875  46129.9375     48707.76953125 49324.6328125\n",
            " 54502.48828125 54453.18359375 50651.08203125] --> Prediction: 52004.90234375\n",
            "\n",
            "Predicing on: \n",
            " [46129.9375     48707.76953125 49324.6328125  54502.48828125\n",
            " 54453.18359375 50651.08203125 52004.90234375] --> Prediction: 45931.578125\n",
            "\n",
            "Predicing on: \n",
            " [48707.76953125 49324.6328125  54502.48828125 54453.18359375\n",
            " 50651.08203125 52004.90234375 45931.578125  ] --> Prediction: 48968.87890625\n",
            "\n",
            "Predicing on: \n",
            " [49324.6328125  54502.48828125 54453.18359375 50651.08203125\n",
            " 52004.90234375 45931.578125   48968.87890625] --> Prediction: 50194.0234375\n",
            "\n",
            "Predicing on: \n",
            " [54502.48828125 54453.18359375 50651.08203125 52004.90234375\n",
            " 45931.578125   48968.87890625 50194.0234375 ] --> Prediction: 54017.23046875\n",
            "\n",
            "Predicing on: \n",
            " [54453.18359375 50651.08203125 52004.90234375 45931.578125\n",
            " 48968.87890625 50194.0234375  54017.23046875] --> Prediction: 54266.9765625\n",
            "\n",
            "Predicing on: \n",
            " [50651.08203125 52004.90234375 45931.578125   48968.87890625\n",
            " 50194.0234375  54017.23046875 54266.9765625 ] --> Prediction: 51368.5\n",
            "\n",
            "Predicing on: \n",
            " [52004.90234375 45931.578125   48968.87890625 50194.0234375\n",
            " 54017.23046875 54266.9765625  51368.5       ] --> Prediction: 51484.52734375\n",
            "\n",
            "Predicing on: \n",
            " [45931.578125   48968.87890625 50194.0234375  54017.23046875\n",
            " 54266.9765625  51368.5        51484.52734375] --> Prediction: 46043.4609375\n",
            "\n",
            "Predicing on: \n",
            " [48968.87890625 50194.0234375  54017.23046875 54266.9765625\n",
            " 51368.5        51484.52734375 46043.4609375 ] --> Prediction: 48972.59375\n",
            "\n",
            "Predicing on: \n",
            " [50194.0234375  54017.23046875 54266.9765625  51368.5\n",
            " 51484.52734375 46043.4609375  48972.59375   ] --> Prediction: 50801.640625\n",
            "\n",
            "Predicing on: \n",
            " [54017.23046875 54266.9765625  51368.5        51484.52734375\n",
            " 46043.4609375  48972.59375    50801.640625  ] --> Prediction: 54423.29296875\n",
            "\n",
            "Predicing on: \n",
            " [54266.9765625  51368.5        51484.52734375 46043.4609375\n",
            " 48972.59375    50801.640625   54423.29296875] --> Prediction: 54033.42578125\n",
            "\n",
            "Predicing on: \n",
            " [51368.5        51484.52734375 46043.4609375  48972.59375\n",
            " 50801.640625   54423.29296875 54033.42578125] --> Prediction: 52423.921875\n",
            "\n",
            "Predicing on: \n",
            " [51484.52734375 46043.4609375  48972.59375    50801.640625\n",
            " 54423.29296875 54033.42578125 52423.921875  ] --> Prediction: 51333.125\n",
            "\n",
            "Predicing on: \n",
            " [46043.4609375  48972.59375    50801.640625   54423.29296875\n",
            " 54033.42578125 52423.921875   51333.125     ] --> Prediction: 45889.984375\n",
            "\n",
            "Predicing on: \n",
            " [48972.59375    50801.640625   54423.29296875 54033.42578125\n",
            " 52423.921875   51333.125      45889.984375  ] --> Prediction: 48505.0234375\n",
            "\n",
            "Predicing on: \n",
            " [50801.640625   54423.29296875 54033.42578125 52423.921875\n",
            " 51333.125      45889.984375   48505.0234375 ] --> Prediction: 51135.28515625\n",
            "\n",
            "Predicing on: \n",
            " [54423.29296875 54033.42578125 52423.921875   51333.125\n",
            " 45889.984375   48505.0234375  51135.28515625] --> Prediction: 54711.671875\n",
            "\n",
            "Predicing on: \n",
            " [54033.42578125 52423.921875   51333.125      45889.984375\n",
            " 48505.0234375  51135.28515625 54711.671875  ] --> Prediction: 54742.96484375\n",
            "\n",
            "Predicing on: \n",
            " [52423.921875   51333.125      45889.984375   48505.0234375\n",
            " 51135.28515625 54711.671875   54742.96484375] --> Prediction: 50383.828125\n",
            "\n",
            "Predicing on: \n",
            " [51333.125      45889.984375   48505.0234375  51135.28515625\n",
            " 54711.671875   54742.96484375 50383.828125  ] --> Prediction: 50519.74609375\n",
            "\n",
            "Predicing on: \n",
            " [45889.984375   48505.0234375  51135.28515625 54711.671875\n",
            " 54742.96484375 50383.828125   50519.74609375] --> Prediction: 45217.6953125\n",
            "\n",
            "Predicing on: \n",
            " [48505.0234375  51135.28515625 54711.671875   54742.96484375\n",
            " 50383.828125   50519.74609375 45217.6953125 ] --> Prediction: 48800.1796875\n",
            "\n",
            "Predicing on: \n",
            " [51135.28515625 54711.671875   54742.96484375 50383.828125\n",
            " 50519.74609375 45217.6953125  48800.1796875 ] --> Prediction: 51607.08203125\n",
            "\n",
            "Predicing on: \n",
            " [54711.671875   54742.96484375 50383.828125   50519.74609375\n",
            " 45217.6953125  48800.1796875  51607.08203125] --> Prediction: 54833.09375\n",
            "\n",
            "Predicing on: \n",
            " [54742.96484375 50383.828125   50519.74609375 45217.6953125\n",
            " 48800.1796875  51607.08203125 54833.09375   ] --> Prediction: 54201.65234375\n",
            "\n",
            "Predicing on: \n",
            " [50383.828125   50519.74609375 45217.6953125  48800.1796875\n",
            " 51607.08203125 54833.09375    54201.65234375] --> Prediction: 50573.0546875\n",
            "\n",
            "Predicing on: \n",
            " [50519.74609375 45217.6953125  48800.1796875  51607.08203125\n",
            " 54833.09375    54201.65234375 50573.0546875 ] --> Prediction: 50576.109375\n",
            "\n",
            "Predicing on: \n",
            " [45217.6953125  48800.1796875  51607.08203125 54833.09375\n",
            " 54201.65234375 50573.0546875  50576.109375  ] --> Prediction: 45160.0390625\n",
            "\n",
            "Predicing on: \n",
            " [48800.1796875  51607.08203125 54833.09375    54201.65234375\n",
            " 50573.0546875  50576.109375   45160.0390625 ] --> Prediction: 49180.23828125\n",
            "\n",
            "Predicing on: \n",
            " [51607.08203125 54833.09375    54201.65234375 50573.0546875\n",
            " 50576.109375   45160.0390625  49180.23828125] --> Prediction: 52045.1875\n",
            "\n",
            "Predicing on: \n",
            " [54833.09375    54201.65234375 50573.0546875  50576.109375\n",
            " 45160.0390625  49180.23828125 52045.1875    ] --> Prediction: 55728.95703125\n",
            "\n",
            "Predicing on: \n",
            " [54201.65234375 50573.0546875  50576.109375   45160.0390625\n",
            " 49180.23828125 52045.1875     55728.95703125] --> Prediction: 53550.1640625\n",
            "\n",
            "Predicing on: \n",
            " [50573.0546875  50576.109375   45160.0390625  49180.23828125\n",
            " 52045.1875     55728.95703125 53550.1640625 ] --> Prediction: 50144.08203125\n",
            "\n",
            "Predicing on: \n",
            " [50576.109375   45160.0390625  49180.23828125 52045.1875\n",
            " 55728.95703125 53550.1640625  50144.08203125] --> Prediction: 50267.47265625\n",
            "\n",
            "Predicing on: \n",
            " [45160.0390625  49180.23828125 52045.1875     55728.95703125\n",
            " 53550.1640625  50144.08203125 50267.47265625] --> Prediction: 45117.44921875\n",
            "\n",
            "Predicing on: \n",
            " [49180.23828125 52045.1875     55728.95703125 53550.1640625\n",
            " 50144.08203125 50267.47265625 45117.44921875] --> Prediction: 49219.44921875\n",
            "\n",
            "Predicing on: \n",
            " [52045.1875     55728.95703125 53550.1640625  50144.08203125\n",
            " 50267.47265625 45117.44921875 49219.44921875] --> Prediction: 52134.97265625\n",
            "\n",
            "Predicing on: \n",
            " [55728.95703125 53550.1640625  50144.08203125 50267.47265625\n",
            " 45117.44921875 49219.44921875 52134.97265625] --> Prediction: 55366.64453125\n",
            "\n",
            "Predicing on: \n",
            " [53550.1640625  50144.08203125 50267.47265625 45117.44921875\n",
            " 49219.44921875 52134.97265625 55366.64453125] --> Prediction: 53330.66796875\n",
            "\n",
            "Predicing on: \n",
            " [50144.08203125 50267.47265625 45117.44921875 49219.44921875\n",
            " 52134.97265625 55366.64453125 53330.66796875] --> Prediction: 49754.984375\n",
            "\n",
            "Predicing on: \n",
            " [50267.47265625 45117.44921875 49219.44921875 52134.97265625\n",
            " 55366.64453125 53330.66796875 49754.984375  ] --> Prediction: 49544.234375\n",
            "\n",
            "Predicing on: \n",
            " [45117.44921875 49219.44921875 52134.97265625 55366.64453125\n",
            " 53330.66796875 49754.984375   49544.234375  ] --> Prediction: 45877.921875\n",
            "\n",
            "Predicing on: \n",
            " [49219.44921875 52134.97265625 55366.64453125 53330.66796875\n",
            " 49754.984375   49544.234375   45877.921875  ] --> Prediction: 49551.75390625\n",
            "\n",
            "Predicing on: \n",
            " [52134.97265625 55366.64453125 53330.66796875 49754.984375\n",
            " 49544.234375   45877.921875   49551.75390625] --> Prediction: 53084.51953125\n",
            "\n",
            "Predicing on: \n",
            " [55366.64453125 53330.66796875 49754.984375   49544.234375\n",
            " 45877.921875   49551.75390625 53084.51953125] --> Prediction: 54842.33203125\n",
            "\n",
            "Predicing on: \n",
            " [53330.66796875 49754.984375   49544.234375   45877.921875\n",
            " 49551.75390625 53084.51953125 54842.33203125] --> Prediction: 52789.01171875\n",
            "\n",
            "Predicing on: \n",
            " [49754.984375   49544.234375   45877.921875   49551.75390625\n",
            " 53084.51953125 54842.33203125 52789.01171875] --> Prediction: 49819.29296875\n",
            "\n",
            "Predicing on: \n",
            " [49544.234375   45877.921875   49551.75390625 53084.51953125\n",
            " 54842.33203125 52789.01171875 49819.29296875] --> Prediction: 48427.24609375\n",
            "\n",
            "Predicing on: \n",
            " [45877.921875   49551.75390625 53084.51953125 54842.33203125\n",
            " 52789.01171875 49819.29296875 48427.24609375] --> Prediction: 45665.46875\n",
            "\n",
            "Predicing on: \n",
            " [49551.75390625 53084.51953125 54842.33203125 52789.01171875\n",
            " 49819.29296875 48427.24609375 45665.46875   ] --> Prediction: 50183.7109375\n",
            "\n",
            "Predicing on: \n",
            " [53084.51953125 54842.33203125 52789.01171875 49819.29296875\n",
            " 48427.24609375 45665.46875    50183.7109375 ] --> Prediction: 53549.1875\n",
            "\n",
            "Predicing on: \n",
            " [54842.33203125 52789.01171875 49819.29296875 48427.24609375\n",
            " 45665.46875    50183.7109375  53549.1875    ] --> Prediction: 54649.640625\n",
            "\n",
            "Predicing on: \n",
            " [52789.01171875 49819.29296875 48427.24609375 45665.46875\n",
            " 50183.7109375  53549.1875     54649.640625  ] --> Prediction: 52220.64453125\n",
            "\n",
            "Predicing on: \n",
            " [49819.29296875 48427.24609375 45665.46875    50183.7109375\n",
            " 53549.1875     54649.640625   52220.64453125] --> Prediction: 49930.90234375\n",
            "\n",
            "Predicing on: \n",
            " [48427.24609375 45665.46875    50183.7109375  53549.1875\n",
            " 54649.640625   52220.64453125 49930.90234375] --> Prediction: 48375.02734375\n",
            "\n",
            "Predicing on: \n",
            " [45665.46875    50183.7109375  53549.1875     54649.640625\n",
            " 52220.64453125 49930.90234375 48375.02734375] --> Prediction: 45780.45703125\n",
            "\n",
            "Predicing on: \n",
            " [50183.7109375  53549.1875     54649.640625   52220.64453125\n",
            " 49930.90234375 48375.02734375 45780.45703125] --> Prediction: 51002.65625\n",
            "\n",
            "Predicing on: \n",
            " [53549.1875     54649.640625   52220.64453125 49930.90234375\n",
            " 48375.02734375 45780.45703125 51002.65625   ] --> Prediction: 54152.63671875\n",
            "\n",
            "Predicing on: \n",
            " [54649.640625   52220.64453125 49930.90234375 48375.02734375\n",
            " 45780.45703125 51002.65625    54152.63671875] --> Prediction: 54413.51171875\n",
            "\n",
            "Predicing on: \n",
            " [52220.64453125 49930.90234375 48375.02734375 45780.45703125\n",
            " 51002.65625    54152.63671875 54413.51171875] --> Prediction: 51626.88671875\n",
            "\n",
            "Predicing on: \n",
            " [49930.90234375 48375.02734375 45780.45703125 51002.65625\n",
            " 54152.63671875 54413.51171875 51626.88671875] --> Prediction: 50262.35546875\n",
            "\n",
            "Predicing on: \n",
            " [48375.02734375 45780.45703125 51002.65625    54152.63671875\n",
            " 54413.51171875 51626.88671875 50262.35546875] --> Prediction: 47817.50390625\n",
            "\n",
            "Predicing on: \n",
            " [45780.45703125 51002.65625    54152.63671875 54413.51171875\n",
            " 51626.88671875 50262.35546875 47817.50390625] --> Prediction: 46183.35546875\n",
            "\n",
            "Predicing on: \n",
            " [51002.65625    54152.63671875 54413.51171875 51626.88671875\n",
            " 50262.35546875 47817.50390625 46183.35546875] --> Prediction: 51425.921875\n",
            "\n",
            "Predicing on: \n",
            " [54152.63671875 54413.51171875 51626.88671875 50262.35546875\n",
            " 47817.50390625 46183.35546875 51425.921875  ] --> Prediction: 54283.9375\n",
            "\n",
            "Predicing on: \n",
            " [54413.51171875 51626.88671875 50262.35546875 47817.50390625\n",
            " 46183.35546875 51425.921875   54283.9375    ] --> Prediction: 54359.62890625\n",
            "\n",
            "Predicing on: \n",
            " [51626.88671875 50262.35546875 47817.50390625 46183.35546875\n",
            " 51425.921875   54283.9375     54359.62890625] --> Prediction: 51722.46484375\n",
            "\n",
            "Predicing on: \n",
            " [50262.35546875 47817.50390625 46183.35546875 51425.921875\n",
            " 54283.9375     54359.62890625 51722.46484375] --> Prediction: 49539.34765625\n",
            "\n",
            "Predicing on: \n",
            " [47817.50390625 46183.35546875 51425.921875   54283.9375\n",
            " 54359.62890625 51722.46484375 49539.34765625] --> Prediction: 46776.23828125\n",
            "\n",
            "Predicing on: \n",
            " [46183.35546875 51425.921875   54283.9375     54359.62890625\n",
            " 51722.46484375 49539.34765625 46776.23828125] --> Prediction: 46323.20703125\n",
            "\n",
            "Predicing on: \n",
            " [51425.921875   54283.9375     54359.62890625 51722.46484375\n",
            " 49539.34765625 46776.23828125 46323.20703125] --> Prediction: 52438.22265625\n",
            "\n",
            "Predicing on: \n",
            " [54283.9375     54359.62890625 51722.46484375 49539.34765625\n",
            " 46776.23828125 46323.20703125 52438.22265625] --> Prediction: 55444.10546875\n",
            "\n",
            "Predicing on: \n",
            " [54359.62890625 51722.46484375 49539.34765625 46776.23828125\n",
            " 46323.20703125 52438.22265625 55444.10546875] --> Prediction: 54187.140625\n",
            "\n",
            "Predicing on: \n",
            " [51722.46484375 49539.34765625 46776.23828125 46323.20703125\n",
            " 52438.22265625 55444.10546875 54187.140625  ] --> Prediction: 52692.609375\n",
            "\n",
            "Predicing on: \n",
            " [49539.34765625 46776.23828125 46323.20703125 52438.22265625\n",
            " 55444.10546875 54187.140625   52692.609375  ] --> Prediction: 48357.6796875\n",
            "\n",
            "Predicing on: \n",
            " [46776.23828125 46323.20703125 52438.22265625 55444.10546875\n",
            " 54187.140625   52692.609375   48357.6796875 ] --> Prediction: 47090.61328125\n",
            "\n",
            "Predicing on: \n",
            " [46323.20703125 52438.22265625 55444.10546875 54187.140625\n",
            " 52692.609375   48357.6796875  47090.61328125] --> Prediction: 47005.15625\n",
            "\n",
            "Predicing on: \n",
            " [52438.22265625 55444.10546875 54187.140625   52692.609375\n",
            " 48357.6796875  47090.61328125 47005.15625   ] --> Prediction: 52628.4921875\n",
            "\n",
            "Predicing on: \n",
            " [55444.10546875 54187.140625   52692.609375   48357.6796875\n",
            " 47090.61328125 47005.15625    52628.4921875 ] --> Prediction: 55512.16015625\n",
            "\n",
            "Predicing on: \n",
            " [54187.140625   52692.609375   48357.6796875  47090.61328125\n",
            " 47005.15625    52628.4921875  55512.16015625] --> Prediction: 54038.3046875\n",
            "\n",
            "Predicing on: \n",
            " [52692.609375   48357.6796875  47090.61328125 47005.15625\n",
            " 52628.4921875  55512.16015625 54038.3046875 ] --> Prediction: 52270.2578125\n",
            "\n",
            "Predicing on: \n",
            " [48357.6796875  47090.61328125 47005.15625    52628.4921875\n",
            " 55512.16015625 54038.3046875  52270.2578125 ] --> Prediction: 48551.62109375\n",
            "\n",
            "Predicing on: \n",
            " [47090.61328125 47005.15625    52628.4921875  55512.16015625\n",
            " 54038.3046875  52270.2578125  48551.62109375] --> Prediction: 47021.625\n",
            "\n",
            "Predicing on: \n",
            " [47005.15625    52628.4921875  55512.16015625 54038.3046875\n",
            " 52270.2578125  48551.62109375 47021.625     ] --> Prediction: 47698.49609375\n",
            "\n",
            "Predicing on: \n",
            " [52628.4921875  55512.16015625 54038.3046875  52270.2578125\n",
            " 48551.62109375 47021.625      47698.49609375] --> Prediction: 53158.64453125\n",
            "\n",
            "Predicing on: \n",
            " [55512.16015625 54038.3046875  52270.2578125  48551.62109375\n",
            " 47021.625      47698.49609375 53158.64453125] --> Prediction: 55422.66796875\n",
            "\n",
            "Predicing on: \n",
            " [54038.3046875  52270.2578125  48551.62109375 47021.625\n",
            " 47698.49609375 53158.64453125 55422.66796875] --> Prediction: 54808.1796875\n",
            "\n",
            "Predicing on: \n",
            " [52270.2578125  48551.62109375 47021.625      47698.49609375\n",
            " 53158.64453125 55422.66796875 54808.1796875 ] --> Prediction: 52152.0859375\n",
            "\n",
            "Predicing on: \n",
            " [48551.62109375 47021.625      47698.49609375 53158.64453125\n",
            " 55422.66796875 54808.1796875  52152.0859375 ] --> Prediction: 48153.890625\n",
            "\n",
            "Predicing on: \n",
            " [47021.625      47698.49609375 53158.64453125 55422.66796875\n",
            " 54808.1796875  52152.0859375  48153.890625  ] --> Prediction: 45694.015625\n",
            "\n",
            "Predicing on: \n",
            " [47698.49609375 53158.64453125 55422.66796875 54808.1796875\n",
            " 52152.0859375  48153.890625   45694.015625  ] --> Prediction: 48302.44921875\n",
            "\n",
            "Predicing on: \n",
            " [53158.64453125 55422.66796875 54808.1796875  52152.0859375\n",
            " 48153.890625   45694.015625   48302.44921875] --> Prediction: 53443.41015625\n",
            "\n",
            "Predicing on: \n",
            " [55422.66796875 54808.1796875  52152.0859375  48153.890625\n",
            " 45694.015625   48302.44921875 53443.41015625] --> Prediction: 55709.0390625\n",
            "\n",
            "Predicing on: \n",
            " [54808.1796875  52152.0859375  48153.890625   45694.015625\n",
            " 48302.44921875 53443.41015625 55709.0390625 ] --> Prediction: 52654.765625\n",
            "\n",
            "Predicing on: \n",
            " [52152.0859375  48153.890625   45694.015625   48302.44921875\n",
            " 53443.41015625 55709.0390625  52654.765625  ] --> Prediction: 52028.828125\n",
            "\n",
            "Predicing on: \n",
            " [48153.890625   45694.015625   48302.44921875 53443.41015625\n",
            " 55709.0390625  52654.765625   52028.828125  ] --> Prediction: 47696.17578125\n",
            "\n",
            "Predicing on: \n",
            " [45694.015625   48302.44921875 53443.41015625 55709.0390625\n",
            " 52654.765625   52028.828125   47696.17578125] --> Prediction: 45880.19140625\n",
            "\n",
            "Predicing on: \n",
            " [48302.44921875 53443.41015625 55709.0390625  52654.765625\n",
            " 52028.828125   47696.17578125 45880.19140625] --> Prediction: 49062.21875\n",
            "\n",
            "Predicing on: \n",
            " [53443.41015625 55709.0390625  52654.765625   52028.828125\n",
            " 47696.17578125 45880.19140625 49062.21875   ] --> Prediction: 53864.1953125\n",
            "\n",
            "Predicing on: \n",
            " [55709.0390625  52654.765625   52028.828125   47696.17578125\n",
            " 45880.19140625 49062.21875    53864.1953125 ] --> Prediction: 55402.875\n",
            "\n",
            "Predicing on: \n",
            " [52654.765625   52028.828125   47696.17578125 45880.19140625\n",
            " 49062.21875    53864.1953125  55402.875     ] --> Prediction: 52906.26171875\n",
            "\n",
            "Predicing on: \n",
            " [52028.828125   47696.17578125 45880.19140625 49062.21875\n",
            " 53864.1953125  55402.875      52906.26171875] --> Prediction: 52877.39453125\n",
            "\n",
            "Predicing on: \n",
            " [47696.17578125 45880.19140625 49062.21875    53864.1953125\n",
            " 55402.875      52906.26171875 52877.39453125] --> Prediction: 47631.85546875\n",
            "\n",
            "Predicing on: \n",
            " [45880.19140625 49062.21875    53864.1953125  55402.875\n",
            " 52906.26171875 52877.39453125 47631.85546875] --> Prediction: 45904.80859375\n",
            "\n",
            "Predicing on: \n",
            " [49062.21875    53864.1953125  55402.875      52906.26171875\n",
            " 52877.39453125 47631.85546875 45904.80859375] --> Prediction: 49055.8671875\n",
            "\n",
            "Predicing on: \n",
            " [53864.1953125  55402.875      52906.26171875 52877.39453125\n",
            " 47631.85546875 45904.80859375 49055.8671875 ] --> Prediction: 54621.5234375\n",
            "\n",
            "Predicing on: \n",
            " [55402.875      52906.26171875 52877.39453125 47631.85546875\n",
            " 45904.80859375 49055.8671875  54621.5234375 ] --> Prediction: 54930.890625\n",
            "\n",
            "Predicing on: \n",
            " [52906.26171875 52877.39453125 47631.85546875 45904.80859375\n",
            " 49055.8671875  54621.5234375  54930.890625  ] --> Prediction: 53036.98046875\n",
            "\n",
            "Predicing on: \n",
            " [52877.39453125 47631.85546875 45904.80859375 49055.8671875\n",
            " 54621.5234375  54930.890625   53036.98046875] --> Prediction: 52209.171875\n",
            "\n",
            "Predicing on: \n",
            " [47631.85546875 45904.80859375 49055.8671875  54621.5234375\n",
            " 54930.890625   53036.98046875 52209.171875  ] --> Prediction: 46899.8046875\n",
            "\n",
            "Predicing on: \n",
            " [45904.80859375 49055.8671875  54621.5234375  54930.890625\n",
            " 53036.98046875 52209.171875   46899.8046875 ] --> Prediction: 45331.84765625\n",
            "\n",
            "Predicing on: \n",
            " [49055.8671875  54621.5234375  54930.890625   53036.98046875\n",
            " 52209.171875   46899.8046875  45331.84765625] --> Prediction: 49367.86328125\n",
            "\n",
            "Predicing on: \n",
            " [54621.5234375  54930.890625   53036.98046875 52209.171875\n",
            " 46899.8046875  45331.84765625 49367.86328125] --> Prediction: 54708.1953125\n",
            "\n",
            "Predicing on: \n",
            " [54930.890625   53036.98046875 52209.171875   46899.8046875\n",
            " 45331.84765625 49367.86328125 54708.1953125 ] --> Prediction: 54565.890625\n",
            "\n",
            "Predicing on: \n",
            " [53036.98046875 52209.171875   46899.8046875  45331.84765625\n",
            " 49367.86328125 54708.1953125  54565.890625  ] --> Prediction: 52223.57421875\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZvOcaWdyPg3"
      },
      "source": [
        "### 7. For future predictions, try to make a prediction, retrain a model on the predictions, make a prediction, retrain a model, make a prediction, retrain a model, make a prediction (retrain a model each time a new prediction is made). Plot the results, how do they look compared to the future predictions where a model wasnâ€™t retrained for every forecast (model_9)?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD2tfR7Y-BWG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkfktUGa-CRw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYvX6FuH-Cci"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzHOR23b-CkE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uedqTuLr-Cs1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Udvq9MA-C3S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eo6JOrd-Dme"
      },
      "source": [
        "### 8. Throughout this notebook, weâ€™ve only tried algorithms weâ€™ve handcrafted ourselves. But itâ€™s worth seeing how a purpose built forecasting algorithm goes.\n",
        "\n",
        "* Try out one of the extra algorithms listed in the modelling experiments part such as:\n",
        "\t*  [Facebookâ€™s Kats library](https://github.com/facebookresearch/Kats)  - there are many models in here, remember the machine learning practionerâ€™s motto: experiment, experiment, experiment.\n",
        "\t*  [LinkedInâ€™s Greykite library](https://github.com/linkedin/greykite) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rngm_dIP-Exz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}