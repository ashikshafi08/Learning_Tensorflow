{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow_Basics_from_docs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0UO32Yi5gHfn2p/ApGFZx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning_Tensorflow/blob/main/TensorFlow_Basics_from_docs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_1v5NrpcGhF"
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.keras import layers "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "393I2NpqcR06"
      },
      "source": [
        "Will be coding through every tutorials and gudies from the TensorFlow Documentation. The goal is to cement the basics for the upcoming developer exam and also knowing the basics very well might help in customizing tensorflow further. \n",
        "\n",
        "\n",
        "# TensorFlow Basics \n",
        "Things I will be going through: \n",
        "- Tensor \n",
        "- Variable \n",
        "- Automatic Differentiation \n",
        "- Intro to graphs and function\n",
        "- Intro to modules, layers and models \n",
        "- Training loop \n",
        "- Advanced auto diff\n",
        "- Ragged tensors \n",
        "- Sparse tensors \n",
        "- Numpy api \n",
        "- Tensor Slicing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8BbeTsudGRS"
      },
      "source": [
        "## Introduction to Tensors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1eMnJh0dcBV",
        "outputId": "074917b0-4291-4817-e7f0-28cacd5c5eb6"
      },
      "source": [
        "# Creating a scalr or called an rank-0 tensors \n",
        "rank_0_tensors = tf.constant(4)\n",
        "rank_0_tensors.ndim"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUjSmP6oeH_U",
        "outputId": "4cf481bc-86ce-40bc-9f58-ca7aa5db1373"
      },
      "source": [
        "# Creating a rank-1 tensors or otherwise called an vector \n",
        "rank_1_tensor = tf.constant([1,2,3,4])\n",
        "rank_1_tensor.ndim , rank_1_tensor"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,\n",
              " <tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pF7Cyu0eYff",
        "outputId": "ea4035be-e983-4eba-8fdc-a9b980e1b6c6"
      },
      "source": [
        "# Lets create a matrrix otherwise called as a rank 2 tensor \n",
        "rank_2_tensor = tf.constant([[1,2,3] , \n",
        "                             [4,5,6]])\n",
        "\n",
        "rank_2_tensor.shape , rank_2_tensor.ndim"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([2, 3]), 2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30snmkp5e6N1",
        "outputId": "75e72c47-262f-458c-862b-4c633ddfe03b"
      },
      "source": [
        "# Whats the default dtype of the tensors? \n",
        "rank_2_tensor.dtype , rank_2_tensor"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tf.int32, <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              " array([[1, 2, 3],\n",
              "        [4, 5, 6]], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ2nBm6jenBs",
        "outputId": "12ff5835-e852-4717-92fb-ddfcd511cfd9"
      },
      "source": [
        "# Setting the dtype while creating the tensor at first place. \n",
        "dtype_tensor = tf.constant([[1 , 2 ,3], \n",
        "                            [4, 5, 6]] , dtype = tf.float32)\n",
        "\n",
        "dtype_tensor.dtype , dtype_tensor"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tf.float32, <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              " array([[1., 2., 3.],\n",
              "        [4., 5., 6.]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK8RGkSvfBUu"
      },
      "source": [
        "Also tensors can be of more than 3 dimension, also dimensions or axes the same shit. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dcjq4f-FfY9L",
        "outputId": "4c6e7f87-c8e5-4c1e-ac5a-1569a4097cea"
      },
      "source": [
        "# Constructing a rank 3 tensor \n",
        "rank_3_tensor = tf.constant([\n",
        "      [[0 , 1, 2, 3, 4 ] , \n",
        "       [5, 6, 7, 8 , 9]] , \n",
        "\n",
        "       [[10 , 11, 12, 13, 14] , \n",
        "        [15, 16 , 17 , 18 , 19]], \n",
        "\n",
        "        [[20 , 21 ,22 ,23 ,24], \n",
        "         [25, 26 , 27 , 28 ,29]] ])\n",
        "\n",
        "print(rank_3_tensor) , rank_3_tensor.ndim \n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-h_aZx5f8wi",
        "outputId": "816ec1c1-e118-40a1-b679-e058a71863b4"
      },
      "source": [
        "# Getting the shape of above matrix \n",
        "rank_3_tensor.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([3, 2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KihMNS4gEFu"
      },
      "source": [
        "`TensorShape([3, 2, 5])` it can be decoded into: \n",
        "- 3 set of rows \n",
        "- 2 rows in each (in one row) \n",
        "- 5 elements in each \n",
        "\n",
        "![3-axis_front.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA0250AJgaLN",
        "outputId": "fd100a34-71d2-4515-ee82-454521f87027"
      },
      "source": [
        "# Converting the tensors inot numpy array \n",
        "import numpy as np \n",
        "\n",
        "# First way by wrapping in np.array()\n",
        "print(f'Using np.array method {np.array(rank_3_tensor)}\\n')\n",
        "\n",
        "\n",
        "# We can explicitly use tensor.numpy() to get the numpy version of it.\n",
        "print(f'Using .numpy method {rank_3_tensor.numpy()}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using np.array method [[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]]\n",
            "\n",
            "Using .numpy method [[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWFQflyzg3-e"
      },
      "source": [
        "Tensors not only comes with float, ints but also other types including: \n",
        "- complex numbers (i,j) \n",
        "- strings\n",
        "\n",
        "\n",
        "The base `tf.Tensor` class requirs the tensors to be 'rectangular' --> that is, along each axis, every elemnt is the same size. \n",
        "\n",
        "But with the below tensors class we can handle different shapes, \n",
        "- Ragged tensors \n",
        "- Sparse tensors \n",
        "\n",
        "\n",
        "We can't do operations across tensors with different shapes. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xReZt70vhUGR",
        "outputId": "3610ed52-c17f-4443-ae94-f4fbbd3851ac"
      },
      "source": [
        "# Tensors in other kinds of operations than simple arithmetic \n",
        "\n",
        "c = tf.constant([\n",
        "  [4.0 ,5.0] , [10.0 , 1.0] ])\n",
        "\n",
        "\n",
        "# Find the largest value \n",
        "print(tf.reduce_max(c))\n",
        "\n",
        "# Find the index of the largest value \n",
        "print(tf.argmax(c))\n",
        "\n",
        "# Compute the softmax \n",
        "print(tf.nn.softmax(c))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(10.0, shape=(), dtype=float32)\n",
            "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[2.6894143e-01 7.3105854e-01]\n",
            " [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u4-yEhQiV3R"
      },
      "source": [
        "### About shapes \n",
        "\n",
        "This is very crucial when we are dealing with tensors. In machine learning most of the error arises due to shape mismatch. Knowing your input and output shapes is vital. \n",
        "\n",
        "Lets look into some tensor vocabulary: \n",
        "\n",
        "- **Shape** --> The length (number of elemnts) of each of the axes of a tensor. \n",
        "- **Rank** --> Number of tensor axes. A scalar has a rank 0, a vector has rank 1 and matrix is rank 2. \n",
        "- **Axis** or **Dimensions**: A particular dimension of a tensor. \n",
        "- **Size** : The total number of items in the tensor, the product shape vector. \n",
        "\n",
        "\n",
        "Lets create a huge shaped tensor and access every parts of it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGa6UThOjozn",
        "outputId": "3a5f5511-21c5-4d79-ff4b-0b4ad2666f8a"
      },
      "source": [
        "# Creating rank 4 tensor \n",
        "rank_4_tensor = tf.zeros(shape = [3,2,4,5])\n",
        "rank_4_tensor , rank_4_tensor.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 2, 4, 5), dtype=float32, numpy=\n",
              " array([[[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "        [[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "        [[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]]], dtype=float32)>, TensorShape([3, 2, 4, 5]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dffh4RxClK0P"
      },
      "source": [
        "![shape.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJqpuDL_lX6m",
        "outputId": "bb05d772-02c1-478c-eb14-e1ae0e3a7743"
      },
      "source": [
        "# Printing out the every details of our tensor \n",
        "\n",
        "print(f'Type of every element in the tensor: {rank_4_tensor.dtype}\\n')\n",
        "print(f'Number of axes: {rank_4_tensor.ndim}\\n')\n",
        "print(f'Shape of a tensor: {rank_4_tensor.shape}\\n')\n",
        "print(f'Element along axis 0 of a tensor: {rank_4_tensor.shape[0]}\\n')\n",
        "print(f'Element along the last axis of tensor: {rank_4_tensor.shape[-1]}\\n')\n",
        "print(f'Total number of elements (3*2*4*5): {tf.size(rank_4_tensor).numpy()}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of every element in the tensor: <dtype: 'float32'>\n",
            "\n",
            "Number of axes: 4\n",
            "\n",
            "Shape of a tensor: (3, 2, 4, 5)\n",
            "\n",
            "Element along axis 0 of a tensor: 3\n",
            "\n",
            "Element along the last axis of tensor: 5\n",
            "\n",
            "Total number of elements (3*2*4*5): 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6qT5px_mLU9"
      },
      "source": [
        "Often the axes will be of following order from global to local: \n",
        "- Batch axis (None for the most of the time) \n",
        "- Spatial dimensions [height, width] for image (224 , 224). \n",
        "- Features, the number of outputs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhktHEqopZ-7"
      },
      "source": [
        "### Indexing \n",
        "\n",
        "#### **Single-axis Indexing**\n",
        "TensorFlow follows the standard Python indexing rules, \n",
        "- Index starts at 0. \n",
        "- Negative indices count backwards from the end. \n",
        "- colons (:) are used for slices. `start:stop:step`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ikcCPOtpwoX",
        "outputId": "b927e0bd-a9a4-4646-a735-bc6561422574"
      },
      "source": [
        "rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n",
        "print(rank_1_tensor.numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  2  3  5  8 13 21 34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKER9msmpzcl",
        "outputId": "e969900c-64bc-4437-b8a8-dd94def41bf5"
      },
      "source": [
        "rank_1_tensor[0].numpy() , rank_1_tensor[-1].numpy() , rank_1_tensor[1].numpy()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 34, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WiR2gOHqF0z",
        "outputId": "294e0fb7-b02f-4be6-d6de-16976db6a2bd"
      },
      "source": [
        "# Indexing with a slice operator : \n",
        "\n",
        "print(f'Getting everything: {rank_1_tensor[:].numpy()}')\n",
        "print(f'Before 4th indices: {rank_1_tensor[:4].numpy()}')\n",
        "print(f'From 4 to the end: {rank_1_tensor[4:].numpy()}')\n",
        "print(f'From 2, before 7: {rank_1_tensor[2:7].numpy()}')\n",
        "print(f'Every other item: {rank_1_tensor[::2].numpy()}') # start stop step(2)\n",
        "print(f'Reversed tensor: {rank_1_tensor[::-1].numpy()}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting everything: [ 0  1  1  2  3  5  8 13 21 34]\n",
            "Before 4th indices: [0 1 1 2]\n",
            "From 4 to the end: [ 3  5  8 13 21 34]\n",
            "From 2, before 7: [1 2 3 5 8]\n",
            "Every other item: [ 0  1  3  8 21]\n",
            "Reversed tensor: [34 21 13  8  5  3  2  1  1  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3vv3q7arP3G"
      },
      "source": [
        "#### **Multi-axis indexing** \n",
        "\n",
        "High rank tensors (3+) are indexed by passing multiple indices. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBOIekYCrlgV",
        "outputId": "52d6ceeb-c1f2-4299-aeed-c7eff7166e89"
      },
      "source": [
        "print(rank_2_tensor.numpy())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Kb5ha1frnnE",
        "outputId": "66f8352b-07b0-418f-8686-06ec1da3e4cf"
      },
      "source": [
        "# Passing an integer for each index, the result is a scalar (one value)\n",
        "\n",
        "rank_2_tensor[1 , 1].numpy()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXWiqFVTs7md"
      },
      "source": [
        "Indexing using many combinations of integers and slices.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySb7SHc0s90E",
        "outputId": "f60e80d8-e0f1-4e92-ea5d-1ddc55597743"
      },
      "source": [
        "# Get row and column of tensors \n",
        "\n",
        "print(f'Second row: {rank_2_tensor[1 , :].numpy()}')\n",
        "print(f'Second column: {rank_2_tensor[: , 1].numpy()}')\n",
        "print(f'Last row : {rank_2_tensor[-1 , :].numpy()}')\n",
        "print(f'First item in last column: {rank_2_tensor[0 , -1].numpy()}\\n')\n",
        "print(f'Skip the first row: {rank_2_tensor[1: , :].numpy()}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Second row: [4 5 6]\n",
            "Second column: [2 5]\n",
            "Last row : [4 5 6]\n",
            "First item in last column: 3\n",
            "\n",
            "Skip the first row: [[4 5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQvwRZH7ug9C",
        "outputId": "dfc07ded-f147-4c42-9f0d-3f2afea862fc"
      },
      "source": [
        "rank_3_tensor , rank_3_tensor.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 2, 5), dtype=int32, numpy=\n",
              " array([[[ 0,  1,  2,  3,  4],\n",
              "         [ 5,  6,  7,  8,  9]],\n",
              " \n",
              "        [[10, 11, 12, 13, 14],\n",
              "         [15, 16, 17, 18, 19]],\n",
              " \n",
              "        [[20, 21, 22, 23, 24],\n",
              "         [25, 26, 27, 28, 29]]], dtype=int32)>, TensorShape([3, 2, 5]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_QpXCouupHp"
      },
      "source": [
        "Selecting the last feature across all locations in example in the batch. \n",
        "\n",
        "https://tensorflow.org/guide/tensor_slicing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gcp71CXfuR3Y",
        "outputId": "295d2285-1353-4d94-d340-851b1aa670d5"
      },
      "source": [
        "# For the 3 axis tensor \n",
        "rank_3_tensor[: , : , -1] # here we get both the rows and cols, at the end indexing into the 4th index"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[ 4,  9],\n",
              "       [14, 19],\n",
              "       [24, 29]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWQWj7tjujZB"
      },
      "source": [
        "### Manipulating Shapes \n",
        "\n",
        "When we call shape, it returns a `TensorShape` object that shows the size along each axis. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFrro8uavysK",
        "outputId": "b7151ce7-101d-40eb-c9b6-27512cf03bc2"
      },
      "source": [
        "rank_2_tensor.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoEDium6v9CQ",
        "outputId": "3c50b137-8abd-476f-ee40-2fcff8be09c2"
      },
      "source": [
        "# Getting the Tensorshape as a python list \n",
        "rank_3_tensor.shape.as_list()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 2, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXFZjPn5wEPa"
      },
      "source": [
        "Like wise we can reshape a tensor into a new shape, by calling `tf.reshape` where the underlying data wont be duplicated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmxRUhC1wTLJ",
        "outputId": "0cc04e68-dff8-4dbf-e9e2-36066efe6fe5"
      },
      "source": [
        "# Shape takes a list as an argument \n",
        "print(f'Actual shape: {rank_1_tensor.shape}')\n",
        "reshaped_tensor = tf.reshape(rank_1_tensor , shape = [1, 10] ) # adding an extra dim\n",
        "print(f'\\nAfter reshaping: {reshaped_tensor}')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual shape: (10,)\n",
            "\n",
            "After reshaping: [[ 0  1  1  2  3  5  8 13 21 34]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIIk56Fewnv5",
        "outputId": "706c1c56-580e-44ac-ea9c-e3457b829587"
      },
      "source": [
        "rank_2_tensor.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kapIXNvnwzka",
        "outputId": "5da909da-7c84-4e0f-f8e0-fb219df8efdc"
      },
      "source": [
        "tf.reshape(rank_2_tensor , shape = [1, 3, 2]) # possibilities are [2,3,1] , [1 ,2 ,3] "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3, 2), dtype=int32, numpy=\n",
              "array([[[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w92q8tDyEbs",
        "outputId": "1a32e7fd-b183-4515-9bd0-a52ce075d453"
      },
      "source": [
        "tf.size(rank_2_tensor).numpy()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bp9-MsOxSd8"
      },
      "source": [
        "The important to remember is we can play with shapes till it is inbound to the actual values, in our case it is `6`. \n",
        "\n",
        "And if we try to exceed the size for instance adding an extra dim that will collapse the entire actual tensor. As long it is equal to 30, things will be fine. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ax3ZJP6xpQy"
      },
      "source": [
        "# Tryna exceed the size 6 \n",
        "# tf.reshape(rank_2_tensor , shape = [2 , 2 , 2])\n",
        "\n",
        "\n",
        "# Uncomment to re-produce the error "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tKFB6Vpxt5V"
      },
      "source": [
        "Perfect! Like I said before, the tensor values exceeded above 6 and we got the error. \n",
        "\n",
        "```\n",
        "InvalidArgumentError: Input to reshape is a tensor with 6 values, but the requested shape has 8 [Op:Reshape]\n",
        "```\n",
        "\n",
        "The data maintains its layout in memory and a new tensor is created, with the requested shape, pointing to the same data. TensorFlow uses C-style \"row-major\" memory ordering, where incrementing the rightmost index corresponds to a single step in memory.\n",
        "\n",
        "\n",
        "Also if we are not sure about the reshaping size, then we can use the [-1] which will reshape the actual tensor to whatever it fits. \n",
        "\n",
        "Basically it will flatten out the tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRx-QZn1ywvI",
        "outputId": "534aa6a9-6bd7-44a7-ce58-ec6c8530ca1e"
      },
      "source": [
        "# Using -1 (Basically it will flatten out the tensor)\n",
        "tf.reshape(rank_3_tensor , shape = [-1])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30,), dtype=int32, numpy=\n",
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRypGGcfzdm0",
        "outputId": "6c21080a-b923-465f-f7e5-f5fc4d6d4308"
      },
      "source": [
        "# Mixing the inner shapes to reproduce a new one \n",
        "print(tf.reshape(rank_3_tensor , [3*2 , 5]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4]\n",
            " [ 5  6  7  8  9]\n",
            " [10 11 12 13 14]\n",
            " [15 16 17 18 19]\n",
            " [20 21 22 23 24]\n",
            " [25 26 27 28 29]], shape=(6, 5), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sqQ_Ept03JY"
      },
      "source": [
        "Reshaping will work for any new shape with the same total number of elements, but it will not do anything useful if you dont respect the order of the axes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbp0T6FT9wEo",
        "outputId": "3f322c4b-6869-4d10-ea18-4aa8004c2ac3"
      },
      "source": [
        "# Below are the bad examples \n",
        "\n",
        "# Can't reorder axes with reshape \n",
        "print(tf.reshape(rank_3_tensor , shape = [2 , 3 ,5])) # Not a good practice \n",
        "\n",
        "# This is a mess lol \n",
        "print(tf.reshape(rank_3_tensor , shape = [5, 6]))\n",
        "\n",
        "\n",
        "# This doesnt work as we exceeded the amount of values in a tensor \n",
        "try: \n",
        "  tf.reshape(rank_3_tensor , shape = [7 , -1])\n",
        "except Exception as e:\n",
        "  print(f'{type(e).__name__}: {e}')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]\n",
            "  [10 11 12 13 14]]\n",
            "\n",
            " [[15 16 17 18 19]\n",
            "  [20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]\n",
            " [24 25 26 27 28 29]], shape=(5, 6), dtype=int32)\n",
            "InvalidArgumentError: Input to reshape is a tensor with 30 values, but the requested shape requires a multiple of 7 [Op:Reshape]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7OkyhYW-ai2"
      },
      "source": [
        "### Broadcasting \n",
        "\n",
        "Under certain conditions, smaller tensors are stretched automatically to fit larger tensors when running combined operations on them. \n",
        "\n",
        "This will come in handy when **we attempt to multiply or add a tensor to a scalar**. \n",
        "\n",
        "In that case, the scalar is broadcast to be the same shape as the other argument. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqgCVxtt_00l",
        "outputId": "9ff34870-8f88-47de-9bec-fa4e0319f796"
      },
      "source": [
        "x = tf.constant([[ 1, 2, 3]])\n",
        "y = tf.constant(2)\n",
        "z = tf.constant([2,2,2])\n",
        "\n",
        "# Broadcasting on the fly \n",
        "print(tf.multiply(x ,2))\n",
        "print(x * y)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[2 4 6]], shape=(1, 3), dtype=int32)\n",
            "tf.Tensor([[2 4 6]], shape=(1, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl5TRbplBB0f"
      },
      "source": [
        "Likewise, axes with the length 1 (ndim) can be stretched out to match the other arguments. Both arguments can be stretched into the same computation. \n",
        "\n",
        "In that case a 3x1 matrix is element-wise multiplied by a **1x4 matrix to produce a 3x4 matrix**. \n",
        "\n",
        "`3x1 | 1x4` we get 3x4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qLqicjEB6n0",
        "outputId": "2a5f13c1-ed91-48ac-bf33-f3c906822264"
      },
      "source": [
        "x = tf.reshape(x , [3,1]) \n",
        "print(x.shape)\n",
        "y = tf.range(1,5)\n",
        "\n",
        "print(tf.multiply(x , y))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 1)\n",
            "tf.Tensor(\n",
            "[[ 1  2  3  4]\n",
            " [ 2  4  6  8]\n",
            " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6vhf5bIC_yy",
        "outputId": "dfbb753a-298e-4f4e-d449-83594b5225c3"
      },
      "source": [
        "# Doing the same operation without broadcasting \n",
        "x_stretch = tf.constant([[1, 1, 1, 1],\n",
        "                         [2, 2, 2, 2],\n",
        "                         [3, 3, 3, 3]])\n",
        "\n",
        "y_stretch = tf.constant([[1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4]])\n",
        "\n",
        "print(x_stretch * y_stretch)  # Again, operator overloading"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 1  2  3  4]\n",
            " [ 2  4  6  8]\n",
            " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPgprN3bDtbd",
        "outputId": "ad98e734-9d52-48dd-94f0-c938f94fea67"
      },
      "source": [
        "print(tf.broadcast_to(x , y))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[1 1 1 1]\n",
            "   [2 2 2 2]\n",
            "   [3 3 3 3]]\n",
            "\n",
            "  [[1 1 1 1]\n",
            "   [2 2 2 2]\n",
            "   [3 3 3 3]]]], shape=(1, 2, 3, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-Cx9keKEcSj"
      },
      "source": [
        "[To know more about broadcasting](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkXXYeG6Etv9"
      },
      "source": [
        "### `tf.convert_to_tensor()`\n",
        "\n",
        "We use the `convert_to_tensor` on non-tensor arguments. There is registery of conversions, and most object classes like Numpys `ndarray`, `TensorShape`, Python lists and `tf.Variable` will all convert automatically. \n",
        "\n",
        "Also we can use `tf.register_tensor_conversion_function` if we have our own type of dtype to convert into a tensor. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo-L--YPE-aS"
      },
      "source": [
        "### Ragged Tensors \n",
        "\n",
        "A tensor with variable numbers of elements along some axis is called **ragged**. In that case `tf.ragged.RaggedTensor` for ragged data. \n",
        "\n",
        "\n",
        "Below isnt a ragged tensor, \n",
        "`[4 , None]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFZ-6WspHF2m"
      },
      "source": [
        "ragged_list = [\n",
        "  [0 ,1 , 2 ,3], \n",
        "  [4,5] ,\n",
        "  [6,7,8], \n",
        "  [9]\n",
        "]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFeoaBT-IGoe",
        "outputId": "7cc6b42d-5623-4c7c-9fe0-e997782ab813"
      },
      "source": [
        "try:\n",
        "  tensor = tf.constant(ragged_list)\n",
        "except Exception as e:\n",
        "  print(f'{type(e).__name__}: {e}')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ValueError: Can't convert non-rectangular Python sequence to Tensor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5yNg9L2IVxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "713945b3-7e69-40ed-e3bd-f87073bc1e36"
      },
      "source": [
        "# Creating a ragged tensor using the tf.ragged \n",
        "\n",
        "ragged_tensor = tf.ragged.constant(ragged_list)\n",
        "ragged_tensor.shape , ragged_tensor"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([4, None]),\n",
              " <tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZYjHjympj_s"
      },
      "source": [
        "Also we can see after finding the first element shape, the rest seems like None. Well this is because, these are the axes with unknown lengths. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRkrmpNZp0bu"
      },
      "source": [
        "### String Tensors  \n",
        "\n",
        "\n",
        "`tf.string` is a dtype, which is to say we can represent data as strings in tensors. \n",
        "\n",
        "The strings are atomic and cant be indexed the way Python strings are. But by using `tf.string` we can manipulate them. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MlRjGVprmLR",
        "outputId": "dc27dcfd-29bc-4b46-aaa2-a72665c9b5dd"
      },
      "source": [
        "# Tensor string \n",
        "scalar_string_tensor = tf.constant('Gray wolf')\n",
        "print(scalar_string_tensor)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Gray wolf', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsVBtypxrt8C",
        "outputId": "d1103348-2181-4ac3-aebe-f6e1368ffa43"
      },
      "source": [
        "# Creating a vector of strings \n",
        "tensor_of_strings = tf.constant([\n",
        "            'Gray wolf', \n",
        "            'Lazy dogg', \n",
        "            'Dumb cats' ])\n",
        "\n",
        "tensor_of_strings"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Gray wolf', b'Lazy dogg', b'Dumb cats'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5GcSjHpr-fq"
      },
      "source": [
        "The **b** prefix indicates that `tf.string` dtype is not a unicode string, but a byte-string.\n",
        "\n",
        "To know more about Unicode text https://www.tensorflow.org/tutorials/load_data/unicode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE8o5OoMsT5t",
        "outputId": "d4a9db0a-79b3-47ba-967e-7d11a9ca4901"
      },
      "source": [
        "# Basic function : Split \n",
        "tf.strings.split(scalar_string_tensor , sep= ' ')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'Gray', b'wolf'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDFMq6EFsfot",
        "outputId": "d8e587c1-d322-4776-fff2-0b9fb5bfc309"
      },
      "source": [
        "# Splitting a ununiform strings, then they will turn into a RaggedTensor \n",
        "\n",
        "tf.strings.split(tensor_of_strings)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'Gray', b'wolf'], [b'Lazy', b'dogg'], [b'Dumb', b'cats']]>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dNjHVujszzL",
        "outputId": "3ebb412c-611f-4574-f231-7be01989ca53"
      },
      "source": [
        "# We can also convert \"strings of number\" into number \n",
        "text = tf.constant('1 10 100')\n",
        "tf.strings.to_number(tf.strings.split(text , ' '))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([  1.,  10., 100.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsBBaq5zul1z",
        "outputId": "79526c87-268c-47cd-9086-58c8097c325b"
      },
      "source": [
        "# Or we can split it up as unicode and then decode it \n",
        "unicode_bytes = tf.constant('アヒル 🦆')\n",
        "\n",
        "# Splitting into chars \n",
        "unicode_char_bytes = tf.strings.unicode_split(unicode_bytes , 'UTF-8')\n",
        "\n",
        "# Decoding the unicode chars \n",
        "unicode_values = tf.strings.unicode_decode(unicode_bytes , 'UTF-8')\n",
        "\n",
        "print(unicode_char_bytes)\n",
        "print(unicode_values)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'\\xe3\\x82\\xa2' b'\\xe3\\x83\\x92' b'\\xe3\\x83\\xab' b' ' b'\\xf0\\x9f\\xa6\\x86'], shape=(5,), dtype=string)\n",
            "tf.Tensor([ 12450  12498  12523     32 129414], shape=(5,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR_fjIlcvFkw"
      },
      "source": [
        "### Sparse Tensors \n",
        "\n",
        "\n",
        "Sometimes our data is sparse, like a very wide embedding space. TensorFlow supports sparse tensor `tf.sparse.SparseTensor`. \n",
        "\n",
        "Sparse tensor store values by index in a memory-efficient manner. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IL_HppGwfYJ",
        "outputId": "8a933618-3d3d-46e0-d0bd-5b973004101f"
      },
      "source": [
        "sparse_tensor = tf.sparse.SparseTensor(indices=[[0,0] , [1,2]] , \n",
        "                                       values = [1 ,2], dense_shape = [3,4])\n",
        "print(sparse_tensor)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SparseTensor(indices=tf.Tensor(\n",
            "[[0 0]\n",
            " [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r93vPHiMxxvd"
      },
      "source": [
        "## Introduction to Variables \n",
        "\n",
        "TensorFlow variable is the recommended way to represent shared, persistent state of our program manipulates. \n",
        "\n",
        "The variables created are tracled via the `tf.Variable` class. A `tf.Variable` represents a tensor whose values can be changed by running operations on it. \n",
        "\n",
        "High level libraries like `tf.keras` use `tf.Variable` to store model parameters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IScz5ZAypv9"
      },
      "source": [
        "### Create a variable\n",
        "\n",
        "The `tf.Variable` will have the same dtype as the initialization value. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzUNH4UXzXTO",
        "outputId": "7f4a4bf3-4cf0-4d00-b3d1-6eb7418c90f5"
      },
      "source": [
        "# Converting a constant tensor into a variable \n",
        "my_tensor = tf.constant([[1.0 , 2.0] , [3.0 , 4.0]])\n",
        "my_variable = tf.Variable(my_tensor)\n",
        "\n",
        "# Variables can be all kinds of types, just like tensors \n",
        "bool_variable = tf.Variable([False , False,  False , True])\n",
        "complex_variable = tf.Variable([5+4] , 6 + 1j)\n",
        "\n",
        "complex_variable"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(1,) dtype=int32, numpy=array([9], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4TcaAi90Jft",
        "outputId": "fb0cfd13-ace4-4423-8d84-20cbc7bd994e"
      },
      "source": [
        "# We can also access the dtype \n",
        "my_variable.dtype"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.float32"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iEMrmM_0TOK",
        "outputId": "396a1d43-4776-4a3d-cbc1-2f10bd38dab4"
      },
      "source": [
        "# Also using some useful operations \n",
        "print(tf.convert_to_tensor(my_variable))\n",
        "print(tf.argmax(my_variable))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 2.]\n",
            " [3. 4.]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor([1 1], shape=(2,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coRrZA730zkC"
      },
      "source": [
        "Since the variable is backed by the tensor class, by using the `tf.Variable.assign` doesn't usually allocate a tensor, instead the existing tensors memory is re-used. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcrtqEm-1Kvm",
        "outputId": "b1b1ff19-d8dd-4002-8303-6f71f3742bcb"
      },
      "source": [
        "a = tf.Variable([2.0 , 4.0]) # dtyype of float \n",
        "print(f'Before the assign method: {a.dtype}\\n')\n",
        "print(f'We can use assign for the same allocated memory tensor: {a.assign([1,2])}\\n\\n')\n",
        "\n",
        "# What if we try to exceed the existing variable size/memory? \n",
        "try:\n",
        "  a.assign([1.0 , 2.0 ,3.0])\n",
        "except Exception as e:\n",
        "  print(f'{type(e).__name__}: {e}')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before the assign method: <dtype: 'float32'>\n",
            "\n",
            "We can use assign for the same allocated memory tensor: <tf.Variable 'UnreadVariable' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)>\n",
            "\n",
            "\n",
            "ValueError: Cannot assign to variable Variable:0 due to variable shape (2,) and value shape (3,) are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rZBqYCR1aRw"
      },
      "source": [
        "If we use a variable like a tensor in operations, we will usually operate on the backing tensor. \n",
        "\n",
        "Creating new variables from existing variables duplicated the backing tensors. \n",
        "\n",
        "**Two variables will not share the same memory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmCPUcFaCCc-",
        "outputId": "30a31a88-6637-4b81-fd87-1e24ddbb71be"
      },
      "source": [
        "# Creating a new variable from the existing tensor\n",
        "\n",
        "a = tf.Variable([2.0 , 3.0])\n",
        "\n",
        "# Create b based on the value of a \n",
        "b = tf.Variable(a)\n",
        "\n",
        "# Assign changes the values\n",
        "print(a.assign([5, 6]))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'UnreadVariable' shape=(2,) dtype=float32, numpy=array([5., 6.], dtype=float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRuADk6BCWss",
        "outputId": "1db3e8af-9c00-4c84-ff61-bee1348f80df"
      },
      "source": [
        "# We can see that a and b are different\n",
        "print(a.numpy())\n",
        "print(b.numpy())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5. 6.]\n",
            "[2. 3.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiVnauJUCzrM",
        "outputId": "32495a53-fc9d-414a-dbbd-c49bdab0d67b"
      },
      "source": [
        "# Other versions of assign \n",
        "print(a.assign_add([2,3]).numpy()) # Adds up the existing value [5 ,6] + [2,3]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7. 9.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y9BZaWCDHuX"
      },
      "source": [
        "### Lifecycles, naming and watching \n",
        "\n",
        "Lifecycle methods associated with an object allow you to control what happens when an object is created or destroyed. \n",
        "\n",
        "Variables can also be named which can help us to track and debug them. Also we can give two variables the same nane. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOTsMtvSD1v5",
        "outputId": "86d7bd84-6a18-4f1b-f424-77c04a1d5e21"
      },
      "source": [
        "# Create a and b (they will have the same name)\n",
        "# But different tensors \n",
        "\n",
        "a = tf.Variable(my_tensor , name = 'Yoooo!')\n",
        "b = tf.Variable(my_tensor + 8 , name = 'Yoooo!')\n",
        "\n",
        "# These are un-equal element wise, despite having the same name \n",
        "print(a == b)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[False False]\n",
            " [False False]], shape=(2, 2), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmchSUvoEJIk"
      },
      "source": [
        "**Things to know:**\n",
        "- Variable names are perserved when saving and loading the models. \n",
        "- By default, models will accquire **unique variable names automatically**. \n",
        "- Variables comes in handy at times when we are doing differentiation, some variables need not to be differentiated. \n",
        "- We can **turn off the gradients for a variable by setting `trainable = False` at creatoon**\n",
        "- A variable wouldnt need gradient during the training step counter. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_XSoXIqFACC",
        "outputId": "a724df9f-7179-4177-8e0e-24a0cd3aafe5"
      },
      "source": [
        "# No grads! \n",
        "step_counter = tf.Variable(1 , trainable = False)\n",
        "step_counter"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=1>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaBuBY0NFFqE"
      },
      "source": [
        "### Placing variables and tensors \n",
        "\n",
        "In short, most of the variables will run on GPU instance. \n",
        "\n",
        "Also we can explicitly run a variable on the CPU, even if there is GPU availale. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA8ZJWe5JSSe",
        "outputId": "bf51879e-e98b-4cfb-8f3a-5a7dd1353513"
      },
      "source": [
        "# Placing the tensors on different instances \n",
        "print(tf.config.list_physical_devices()) # we are running on CPU \n",
        "\n",
        "with tf.device('CPU:0'):\n",
        "\n",
        "  # Create some tensors on the placement instanc \n",
        "  a = tf.Variable([[1.0 , 2.0 ,3.0] , \n",
        "                   [4.0 ,5.0 ,6.0]])\n",
        "  \n",
        "  b = tf.Variable([[1.0 ,2.0] , \n",
        "                   [9.0 ,8.1 ], \n",
        "                   [5.0 ,6.0]])\n",
        "\n",
        "  # Matrix multi! \n",
        "  c = tf.matmul(a ,b)\n",
        "\n",
        "# This got calculated on the cpu instance\n",
        "print(c)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "tf.Tensor(\n",
            "[[34.  36.2]\n",
            " [79.  84.5]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwXSN5sPJbgN"
      },
      "source": [
        "Also its possible to run the operations on different instances, both the GPU and CPU. \n",
        "\n",
        "But this will introduce delay, as data needs to be copied between the devices. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w5QGii7JiBH",
        "outputId": "04c84ac3-bae7-4ca4-b66a-1d2fcadeb6f9"
      },
      "source": [
        "%%time\n",
        "# Running the operations on different instance. \n",
        "\n",
        "# First creating the tensors on CPU \n",
        "with tf.device('CPU:0'):\n",
        "\n",
        "  a = tf.Variable([[1.0 , 2.0 ,3.0] , \n",
        "                   [4.0 ,5.0 ,6.0]])\n",
        "  \n",
        "  b = tf.Variable([[1.0 ,2.0] , \n",
        "                   [9.0 ,8.1 ], \n",
        "                   [5.0 ,6.0]])\n",
        "  \n",
        "# Making the matrxi multi on GPU \n",
        "with tf.device('GPU:0'):\n",
        "  k = tf.matmul(a , b)\n",
        "\n",
        "print(k)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[34.  36.2]\n",
            " [79.  84.5]], shape=(2, 2), dtype=float32)\n",
            "CPU times: user 4.35 ms, sys: 1.08 ms, total: 5.43 ms\n",
            "Wall time: 5.91 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21kzh42HLm5m",
        "outputId": "858a8166-6532-4db7-b8d4-1812ecec6c32"
      },
      "source": [
        "%%time\n",
        "# Running on the default instance\n",
        "a = tf.Variable([[1.0 , 2.0 ,3.0] , \n",
        "                   [4.0 ,5.0 ,6.0]])\n",
        "  \n",
        "b = tf.Variable([[1.0 ,2.0] , \n",
        "                   [9.0 ,8.1 ], \n",
        "                   [5.0 ,6.0]])\n",
        "\n",
        "k = tf.matmul(a ,b)\n",
        "print(k)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[34.  36.2]\n",
            " [79.  84.5]], shape=(2, 2), dtype=float32)\n",
            "CPU times: user 3.92 ms, sys: 150 µs, total: 4.07 ms\n",
            "Wall time: 6.21 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9kkjZopL-8R"
      },
      "source": [
        "## Introductions to gradients and automatic differentiation (my fav part) \n",
        "\n",
        "Calculus with tensorflow!! \n",
        "\n",
        "\n",
        "Well in short, we need calculus to train our model weights and biases. But how? \n",
        "\n",
        "Our goal is to get the loss function low as possible and in order to do that we need to find the gradients (tweak values) that will help us to find the right numbers for the weights and biases which will decrease the loss function. \n",
        "\n",
        "Computing gradients on the eager execution, not the graph! \n",
        "\n",
        "\n",
        "[Great resource on eager execution](https://stackoverflow.com/questions/53953099/what-is-the-purpose-of-the-tensorflow-gradient-tape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRTd1YB3M1SO"
      },
      "source": [
        "### Computing gradients \n",
        "\n",
        "To differentiate automatically, TensorFlow needs to remember what **operations happen in what order during the forward pass**.\n",
        "\n",
        "Then in the backward pass, TensorFlow traverses this list of operations in reverse order to compute gradients. \n",
        "\n",
        "```\n",
        "differentiation on a equation  (forward pass) --> calling backward pass on that equation --> gets all the gradients tracked.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA5YbVVzOLQk"
      },
      "source": [
        "### Gradient tapes \n",
        "\n",
        "We can use the `tf.GradientTape` for automatic differentiation, that is, computing the gradient of a computation (loss function) with respect to some inputs, usually it will be of `tf.Variable` dtype. \n",
        "\n",
        "```\n",
        "loss function (with weights and biases) ---> automatic differentiation ---> back propagation ---> get the gradients\n",
        "```\n",
        "\n",
        "Relevant operations executed inside the `tf.GradientTape` records onto a **tape**. \n",
        "\n",
        "Then TensorFlow uses that recorded tape with operations in it to compute the gradients using the reverse mode differentiation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8gK6W9tUcpU",
        "outputId": "c1fa13f6-5382-485f-eeb2-b09210f40f90"
      },
      "source": [
        "x = tf.Variable(3.0)\n",
        "\n",
        "with tf.GradientTape() as tape: # operations get stored in tape\n",
        "  y = x ** 2 \n",
        "\n",
        "print(y)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(9.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc-nFMyMVG_G"
      },
      "source": [
        "Awesome we have recorded some operations with our friend `tape`, now we can use the `GradientTape.gradient(target, sources)` to calculate the gradient of some taget (loss function here) relative to some source (models inputs). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qwr1YKF2Vkft",
        "outputId": "e0bea08b-41e0-483e-8a4e-7fb9cf4c7a05"
      },
      "source": [
        "# Applying the diff for y will give us dy = 2x * dx \n",
        "\n",
        "# Calculating the above (dy wrt to dx)\n",
        "dy_dx = tape.gradient(y , x) # calculating the gradients for the loss eq for our given values\n",
        "dy_dx.numpy()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.0"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WHFMDTUWAtY"
      },
      "source": [
        "We can change the values of x, so the diff also changes. But we have to set the tape `persistent = True ` so it will perform del tape after every execution. \n",
        "\n",
        "> A persistent gradient can be created with with tf.GradientTape(persistent=True) as tape and can/should be manually deleted with del tape (credits for this @zwep, @Crispy13)\n",
        "\n",
        "\n",
        "https://stackoverflow.com/questions/56072634/tf-2-0-runtimeerror-gradienttape-gradient-can-only-be-called-once-on-non-pers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YBqFZnfWJyK",
        "outputId": "eb5909d7-324a-46b7-93b3-9c7116687699"
      },
      "source": [
        "# Setting persistent to True (so we can use this again and again without any BS errors) \n",
        "x = tf.Variable(4.58855)\n",
        "\n",
        "with tf.GradientTape(persistent= True) as tape: # operations get stored in tape\n",
        "  y = x ** 2 \n",
        "\n",
        "# Calculating the grad \n",
        "dy_dx_1 = tape.gradient(y , x)\n",
        "print(dy_dx_1) \n",
        "\n",
        "# Now with the same eq but different value \n",
        "x = tf.Variable(5.00)\n",
        "with tf.GradientTape() as tape: \n",
        "  y = x ** 4\n",
        "\n",
        "dy_dx_2 = tape.gradient(y , x)\n",
        "print(dy_dx_2)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(9.1771, shape=(), dtype=float32)\n",
            "tf.Tensor(500.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xxh6Q81WOmk"
      },
      "source": [
        "Automatic differenitation oon vectors, except scalars now. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJVFMcKnahQ9",
        "outputId": "3daacf9e-051b-4fc8-e9a0-2dd39b145c1e"
      },
      "source": [
        "# Lets create dummy weights and biases + inputs \n",
        "w = tf.Variable(tf.random.normal((3 ,2)) , name ='weights' )\n",
        "b = tf.Variable(tf.zeros(2 , dtype= tf.float32) , name ='biases' )\n",
        "x = [[1. , 2. ,3.]]\n",
        "\n",
        "print(w.numpy())\n",
        "print(f'\\n{b.numpy()}\\n')\n",
        "print(x)\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.09147087 -0.6690964 ]\n",
            " [ 2.6865048  -0.3745898 ]\n",
            " [ 0.64072037  0.1354184 ]]\n",
            "\n",
            "[0. 0.]\n",
            "\n",
            "[[1.0, 2.0, 3.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0aLy8OTbCJC",
        "outputId": "8558d2fc-0420-424e-d953-b503c4bf8050"
      },
      "source": [
        "# Using tensors of diff shapes \n",
        "with tf.GradientTape(persistent = True) as tape:\n",
        "  y = x @ w+ b\n",
        "  loss = tf.reduce_mean(y**2)\n",
        "\n",
        "print(y)\n",
        "print(loss)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[ 7.3866415 -1.0120208]], shape=(1, 2), dtype=float32)\n",
            "tf.Tensor(27.793327, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAifN9MDconT",
        "outputId": "b2a034db-42d9-46be-a91a-30563be37966"
      },
      "source": [
        "x @ w + b"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 7.3866415, -1.0120208]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OwMQumfc_7y"
      },
      "source": [
        "Now to get the gradient `loss` w.r.t both the variables, we can pass both the weights and biases as sources to the gradient method. \n",
        "\n",
        "The `tape`  is flexible about how sources are passed and **will accept any nested combinations of lists or dictionaries and return the gradient structured the same way**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIcK3v9Di55w",
        "outputId": "1a5bfdd6-1fcf-4341-dca7-ec45a84efaff"
      },
      "source": [
        "# Getting thr gradients wrt to 2 variables \n",
        "[d1_dw , d1_db] = tape.gradient(loss , sources = [w ,b])\n",
        "print(d1_dw)\n",
        "print('\\n')\n",
        "print(d1_db)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 7.3866415 -1.0120208]\n",
            " [14.773283  -2.0240417]\n",
            " [22.159924  -3.0360625]], shape=(3, 2), dtype=float32)\n",
            "\n",
            "\n",
            "tf.Tensor([ 7.3866415 -1.0120208], shape=(2,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thtfrTK9jTYX"
      },
      "source": [
        "The gradient w.r.t each source has the shape of the sources. That is the gradients will hae the same shape as the weight and biases it got computed. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRvxHTo8kKVa",
        "outputId": "066f02f9-b379-4b2e-940c-6291baf2b58a"
      },
      "source": [
        "print(f'Actual weight shape: {w.shape}\\n')\n",
        "print(f'Gradients shape computed on the weights: {d1_dw.shape}')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual weight shape: (3, 2)\n",
            "\n",
            "Gradients shape computed on the weights: (3, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fc4xKD4kVnJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}