{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow_Basics_from_docs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNmGDDHqd0/1rfKr3j34FCW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning_Tensorflow/blob/main/TensorFlow_Basics_from_docs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_1v5NrpcGhF"
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.keras import layers "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "393I2NpqcR06"
      },
      "source": [
        "Will be coding through every tutorials and gudies from the TensorFlow Documentation. The goal is to cement the basics for the upcoming developer exam and also knowing the basics very well might help in customizing tensorflow further. \n",
        "\n",
        "\n",
        "# TensorFlow Basics \n",
        "Things I will be going through: \n",
        "- Tensor \n",
        "- Variable \n",
        "- Automatic Differentiation \n",
        "- Intro to graphs and function\n",
        "- Intro to modules, layers and models \n",
        "- Training loop \n",
        "- Advanced auto diff\n",
        "- Ragged tensors \n",
        "- Sparse tensors \n",
        "- Numpy api \n",
        "- Tensor Slicing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8BbeTsudGRS"
      },
      "source": [
        "## Introduction to Tensors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1eMnJh0dcBV",
        "outputId": "7f324db2-ccf1-483a-d39b-68e3cba32dd2"
      },
      "source": [
        "# Creating a scalr or called an rank-0 tensors \n",
        "rank_0_tensors = tf.constant(4)\n",
        "rank_0_tensors.ndim"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUjSmP6oeH_U",
        "outputId": "b5a77939-8ab7-453f-ae88-004490d304a6"
      },
      "source": [
        "# Creating a rank-1 tensors or otherwise called an vector \n",
        "rank_1_tensor = tf.constant([1,2,3,4])\n",
        "rank_1_tensor.ndim , rank_1_tensor"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,\n",
              " <tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pF7Cyu0eYff",
        "outputId": "a3aa9ceb-b95b-4851-fead-046c4d179dda"
      },
      "source": [
        "# Lets create a matrrix otherwise called as a rank 2 tensor \n",
        "rank_2_tensor = tf.constant([[1,2,3] , \n",
        "                             [4,5,6]])\n",
        "\n",
        "rank_2_tensor.shape , rank_2_tensor.ndim"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([2, 3]), 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30snmkp5e6N1",
        "outputId": "34375677-c022-4b59-dd37-89cf5b99e433"
      },
      "source": [
        "# Whats the default dtype of the tensors? \n",
        "rank_2_tensor.dtype , rank_2_tensor"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tf.int32, <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              " array([[1, 2, 3],\n",
              "        [4, 5, 6]], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ2nBm6jenBs",
        "outputId": "a89f16df-8afc-4312-b455-b4f02db58d05"
      },
      "source": [
        "# Setting the dtype while creating the tensor at first place. \n",
        "dtype_tensor = tf.constant([[1 , 2 ,3], \n",
        "                            [4, 5, 6]] , dtype = tf.float32)\n",
        "\n",
        "dtype_tensor.dtype , dtype_tensor"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tf.float32, <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              " array([[1., 2., 3.],\n",
              "        [4., 5., 6.]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK8RGkSvfBUu"
      },
      "source": [
        "Also tensors can be of more than 3 dimension, also dimensions or axes the same shit. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dcjq4f-FfY9L",
        "outputId": "792c0c69-9805-47d9-8731-c228ba743e71"
      },
      "source": [
        "# Constructing a rank 3 tensor \n",
        "rank_3_tensor = tf.constant([\n",
        "      [[0 , 1, 2, 3, 4 ] , \n",
        "       [5, 6, 7, 8 , 9]] , \n",
        "\n",
        "       [[10 , 11, 12, 13, 14] , \n",
        "        [15, 16 , 17 , 18 , 19]], \n",
        "\n",
        "        [[20 , 21 ,22 ,23 ,24], \n",
        "         [25, 26 , 27 , 28 ,29]] ])\n",
        "\n",
        "print(rank_3_tensor) , rank_3_tensor.ndim \n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-h_aZx5f8wi",
        "outputId": "555140f0-124a-47ac-e538-38ae00d324ed"
      },
      "source": [
        "# Getting the shape of above matrix \n",
        "rank_3_tensor.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([3, 2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KihMNS4gEFu"
      },
      "source": [
        "`TensorShape([3, 2, 5])` it can be decoded into: \n",
        "- 3 set of rows \n",
        "- 2 rows in each (in one row) \n",
        "- 5 elements in each \n",
        "\n",
        "![3-axis_front.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA0250AJgaLN",
        "outputId": "269796d7-80a4-4b2d-cec0-c84c157e64ef"
      },
      "source": [
        "# Converting the tensors inot numpy array \n",
        "import numpy as np \n",
        "\n",
        "# First way by wrapping in np.array()\n",
        "print(f'Using np.array method {np.array(rank_3_tensor)}\\n')\n",
        "\n",
        "\n",
        "# We can explicitly use tensor.numpy() to get the numpy version of it.\n",
        "print(f'Using .numpy method {rank_3_tensor.numpy()}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using np.array method [[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]]\n",
            "\n",
            "Using .numpy method [[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWFQflyzg3-e"
      },
      "source": [
        "Tensors not only comes with float, ints but also other types including: \n",
        "- complex numbers (i,j) \n",
        "- strings\n",
        "\n",
        "\n",
        "The base `tf.Tensor` class requirs the tensors to be 'rectangular' --> that is, along each axis, every elemnt is the same size. \n",
        "\n",
        "But with the below tensors class we can handle different shapes, \n",
        "- Ragged tensors \n",
        "- Sparse tensors \n",
        "\n",
        "\n",
        "We can't do operations across tensors with different shapes. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xReZt70vhUGR",
        "outputId": "49787c62-f358-4f7a-a3b7-3c20e583aa96"
      },
      "source": [
        "# Tensors in other kinds of operations than simple arithmetic \n",
        "\n",
        "c = tf.constant([\n",
        "  [4.0 ,5.0] , [10.0 , 1.0] ])\n",
        "\n",
        "\n",
        "# Find the largest value \n",
        "print(tf.reduce_max(c))\n",
        "\n",
        "# Find the index of the largest value \n",
        "print(tf.argmax(c))\n",
        "\n",
        "# Compute the softmax \n",
        "print(tf.nn.softmax(c))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(10.0, shape=(), dtype=float32)\n",
            "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[2.6894143e-01 7.3105860e-01]\n",
            " [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u4-yEhQiV3R"
      },
      "source": [
        "### About shapes \n",
        "\n",
        "This is very crucial when we are dealing with tensors. In machine learning most of the error arises due to shape mismatch. Knowing your input and output shapes is vital. \n",
        "\n",
        "Lets look into some tensor vocabulary: \n",
        "\n",
        "- **Shape** --> The length (number of elemnts) of each of the axes of a tensor. \n",
        "- **Rank** --> Number of tensor axes. A scalar has a rank 0, a vector has rank 1 and matrix is rank 2. \n",
        "- **Axis** or **Dimensions**: A particular dimension of a tensor. \n",
        "- **Size** : The total number of items in the tensor, the product shape vector. \n",
        "\n",
        "\n",
        "Lets create a huge shaped tensor and access every parts of it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGa6UThOjozn",
        "outputId": "39b85814-11e8-4775-bb37-eb98c6a65d61"
      },
      "source": [
        "# Creating rank 4 tensor \n",
        "rank_4_tensor = tf.zeros(shape = [3,2,4,5])\n",
        "rank_4_tensor , rank_4_tensor.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 2, 4, 5), dtype=float32, numpy=\n",
              " array([[[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "        [[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "        [[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]]], dtype=float32)>, TensorShape([3, 2, 4, 5]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dffh4RxClK0P"
      },
      "source": [
        "![shape.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJqpuDL_lX6m",
        "outputId": "2d0d22d6-da97-4ff5-d080-cc23fbf8a3b8"
      },
      "source": [
        "# Printing out the every details of our tensor \n",
        "\n",
        "print(f'Type of every element in the tensor: {rank_4_tensor.dtype}\\n')\n",
        "print(f'Number of axes: {rank_4_tensor.ndim}\\n')\n",
        "print(f'Shape of a tensor: {rank_4_tensor.shape}\\n')\n",
        "print(f'Element along axis 0 of a tensor: {rank_4_tensor.shape[0]}\\n')\n",
        "print(f'Element along the last axis of tensor: {rank_4_tensor.shape[-1]}\\n')\n",
        "print(f'Total number of elements (3*2*4*5): {tf.size(rank_4_tensor).numpy()}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of every element in the tensor: <dtype: 'float32'>\n",
            "\n",
            "Number of axes: 4\n",
            "\n",
            "Shape of a tensor: (3, 2, 4, 5)\n",
            "\n",
            "Element along axis 0 of a tensor: 3\n",
            "\n",
            "Element along the last axis of tensor: 5\n",
            "\n",
            "Total number of elements (3*2*4*5): 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6qT5px_mLU9"
      },
      "source": [
        "Often the axes will be of following order from global to local: \n",
        "- Batch axis (None for the most of the time) \n",
        "- Spatial dimensions [height, width] for image (224 , 224). \n",
        "- Features, the number of outputs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhktHEqopZ-7"
      },
      "source": [
        "### Indexing \n",
        "\n",
        "#### **Single-axis Indexing**\n",
        "TensorFlow follows the standard Python indexing rules, \n",
        "- Index starts at 0. \n",
        "- Negative indices count backwards from the end. \n",
        "- colons (:) are used for slices. `start:stop:step`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ikcCPOtpwoX",
        "outputId": "8c9fdc23-c73c-4c77-9934-aeb24894cdee"
      },
      "source": [
        "rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n",
        "print(rank_1_tensor.numpy())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  2  3  5  8 13 21 34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKER9msmpzcl",
        "outputId": "74f8becb-3c5f-462b-a2e3-225981297917"
      },
      "source": [
        "rank_1_tensor[0].numpy() , rank_1_tensor[-1].numpy() , rank_1_tensor[1].numpy()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 34, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WiR2gOHqF0z",
        "outputId": "9888e7cb-e051-4582-ac35-1e613a4eb3a5"
      },
      "source": [
        "# Indexing with a slice operator : \n",
        "\n",
        "print(f'Getting everything: {rank_1_tensor[:].numpy()}')\n",
        "print(f'Before 4th indices: {rank_1_tensor[:4].numpy()}')\n",
        "print(f'From 4 to the end: {rank_1_tensor[4:].numpy()}')\n",
        "print(f'From 2, before 7: {rank_1_tensor[2:7].numpy()}')\n",
        "print(f'Every other item: {rank_1_tensor[::2].numpy()}') # start stop step(2)\n",
        "print(f'Reversed tensor: {rank_1_tensor[::-1].numpy()}')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting everything: [ 0  1  1  2  3  5  8 13 21 34]\n",
            "Before 4th indices: [0 1 1 2]\n",
            "From 4 to the end: [ 3  5  8 13 21 34]\n",
            "From 2, before 7: [1 2 3 5 8]\n",
            "Every other item: [ 0  1  3  8 21]\n",
            "Reversed tensor: [34 21 13  8  5  3  2  1  1  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3vv3q7arP3G"
      },
      "source": [
        "#### **Multi-axis indexing** \n",
        "\n",
        "High rank tensors (3+) are indexed by passing multiple indices. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBOIekYCrlgV",
        "outputId": "03bf1c2a-952b-4ae3-83ba-123446329584"
      },
      "source": [
        "print(rank_2_tensor.numpy())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Kb5ha1frnnE",
        "outputId": "9f76712a-528f-4abe-bd66-85d82bda0cdc"
      },
      "source": [
        "# Passing an integer for each index, the result is a scalar (one value)\n",
        "\n",
        "rank_2_tensor[1 , 1].numpy()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXWiqFVTs7md"
      },
      "source": [
        "Indexing using many combinations of integers and slices.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySb7SHc0s90E",
        "outputId": "2c9cea32-3b22-4320-8d80-f06f9814b55f"
      },
      "source": [
        "# Get row and column of tensors \n",
        "\n",
        "print(f'Second row: {rank_2_tensor[1 , :].numpy()}')\n",
        "print(f'Second column: {rank_2_tensor[: , 1].numpy()}')\n",
        "print(f'Last row : {rank_2_tensor[-1 , :].numpy()}')\n",
        "print(f'First item in last column: {rank_2_tensor[0 , -1].numpy()}\\n')\n",
        "print(f'Skip the first row: {rank_2_tensor[1: , :].numpy()}')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Second row: [4 5 6]\n",
            "Second column: [2 5]\n",
            "Last row : [4 5 6]\n",
            "First item in last column: 3\n",
            "\n",
            "Skip the first row: [[4 5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQvwRZH7ug9C",
        "outputId": "aafb6834-5a45-4574-d2be-adbe05805713"
      },
      "source": [
        "rank_3_tensor , rank_3_tensor.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 2, 5), dtype=int32, numpy=\n",
              " array([[[ 0,  1,  2,  3,  4],\n",
              "         [ 5,  6,  7,  8,  9]],\n",
              " \n",
              "        [[10, 11, 12, 13, 14],\n",
              "         [15, 16, 17, 18, 19]],\n",
              " \n",
              "        [[20, 21, 22, 23, 24],\n",
              "         [25, 26, 27, 28, 29]]], dtype=int32)>, TensorShape([3, 2, 5]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_QpXCouupHp"
      },
      "source": [
        "Selecting the last feature across all locations in example in the batch. \n",
        "\n",
        "https://tensorflow.org/guide/tensor_slicing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gcp71CXfuR3Y",
        "outputId": "94e51094-eb04-4577-bbce-5e128fb50f1d"
      },
      "source": [
        "# For the 3 axis tensor \n",
        "rank_3_tensor[: , : , -1] # here we get both the rows and cols, at the end indexing into the 4th index"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[ 4,  9],\n",
              "       [14, 19],\n",
              "       [24, 29]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWQWj7tjujZB"
      },
      "source": [
        "### Manipulating Shapes \n",
        "\n",
        "When we call shape, it returns a `TensorShape` object that shows the size along each axis. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFrro8uavysK",
        "outputId": "02838690-12b4-4848-c87d-4d80d7a6661a"
      },
      "source": [
        "rank_2_tensor.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoEDium6v9CQ",
        "outputId": "b8b35fba-28fe-4c99-e8ea-57f5e1289f2e"
      },
      "source": [
        "# Getting the Tensorshape as a python list \n",
        "rank_3_tensor.shape.as_list()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 2, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXFZjPn5wEPa"
      },
      "source": [
        "Like wise we can reshape a tensor into a new shape, by calling `tf.reshape` where the underlying data wont be duplicated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmxRUhC1wTLJ",
        "outputId": "2f969a74-5d58-4f8a-bda8-fe5fc4a0c7d7"
      },
      "source": [
        "# Shape takes a list as an argument \n",
        "print(f'Actual shape: {rank_1_tensor.shape}')\n",
        "reshaped_tensor = tf.reshape(rank_1_tensor , shape = [1, 10] ) # adding an extra dim\n",
        "print(f'\\nAfter reshaping: {reshaped_tensor}')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual shape: (10,)\n",
            "\n",
            "After reshaping: [[ 0  1  1  2  3  5  8 13 21 34]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIIk56Fewnv5",
        "outputId": "36ff167f-c10b-4eb0-c75c-ed8d40952495"
      },
      "source": [
        "rank_2_tensor.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kapIXNvnwzka",
        "outputId": "e079e4c3-8b7e-40d9-eee3-ae3edc8ffea9"
      },
      "source": [
        "tf.reshape(rank_2_tensor , shape = [1, 3, 2]) # possibilities are [2,3,1] , [1 ,2 ,3] "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3, 2), dtype=int32, numpy=\n",
              "array([[[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w92q8tDyEbs",
        "outputId": "83023adb-9f87-4181-a567-51207899380f"
      },
      "source": [
        "tf.size(rank_2_tensor).numpy()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bp9-MsOxSd8"
      },
      "source": [
        "The important to remember is we can play with shapes till it is inbound to the actual values, in our case it is `6`. \n",
        "\n",
        "And if we try to exceed the size for instance adding an extra dim that will collapse the entire actual tensor. As long it is equal to 30, things will be fine. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "-ax3ZJP6xpQy",
        "outputId": "91c51bed-8b0d-498d-8aa5-3a13fac0502b"
      },
      "source": [
        "# Tryna exceed the size 6 \n",
        "# tf.reshape(rank_2_tensor , shape = [2 , 2 , 2])\n",
        "\n",
        "\n",
        "# Uncomment to re-produce the error "
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-a1c1bd3c4390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Tryna exceed the size 6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_2_tensor\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   \"\"\"\n\u001b[0;32m--> 196\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8397\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8398\u001b[0m       return reshape_eager_fallback(\n\u001b[0;32m-> 8399\u001b[0;31m           tensor, shape, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   8400\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8401\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape_eager_fallback\u001b[0;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[1;32m   8422\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tshape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8423\u001b[0m   _result = _execute.execute(b\"Reshape\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 8424\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   8425\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8426\u001b[0m     _execute.record_gradient(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 6 values, but the requested shape has 8 [Op:Reshape]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tKFB6Vpxt5V"
      },
      "source": [
        "Perfect! Like I said before, the tensor values exceeded above 6 and we got the error. \n",
        "\n",
        "```\n",
        "InvalidArgumentError: Input to reshape is a tensor with 6 values, but the requested shape has 8 [Op:Reshape]\n",
        "```\n",
        "\n",
        "The data maintains its layout in memory and a new tensor is created, with the requested shape, pointing to the same data. TensorFlow uses C-style \"row-major\" memory ordering, where incrementing the rightmost index corresponds to a single step in memory.\n",
        "\n",
        "\n",
        "Also if we are not sure about the reshaping size, then we can use the [-1] which will reshape the actual tensor to whatever it fits. \n",
        "\n",
        "Basically it will flatten out the tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRx-QZn1ywvI",
        "outputId": "67252776-d783-4f52-b02b-9493b4609363"
      },
      "source": [
        "# Using -1 (Basically it will flatten out the tensor)\n",
        "tf.reshape(rank_3_tensor , shape = [-1])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30,), dtype=int32, numpy=\n",
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRypGGcfzdm0",
        "outputId": "e4461455-fb78-430e-ac14-8076ee9dd280"
      },
      "source": [
        "# Mixing the inner shapes to reproduce a new one \n",
        "print(tf.reshape(rank_3_tensor , [3*2 , 5]))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4]\n",
            " [ 5  6  7  8  9]\n",
            " [10 11 12 13 14]\n",
            " [15 16 17 18 19]\n",
            " [20 21 22 23 24]\n",
            " [25 26 27 28 29]], shape=(6, 5), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sqQ_Ept03JY"
      },
      "source": [
        "Reshaping will work for any new shape with the same total number of elements, but it will not do anything useful if you dont respect the order of the axes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbp0T6FT9wEo",
        "outputId": "ff21c06c-0a88-4aef-e2e9-4587573fe0ad"
      },
      "source": [
        "# Below are the bad examples \n",
        "\n",
        "# Can't reorder axes with reshape \n",
        "print(tf.reshape(rank_3_tensor , shape = [2 , 3 ,5])) # Not a good practice \n",
        "\n",
        "# This is a mess lol \n",
        "print(tf.reshape(rank_3_tensor , shape = [5, 6]))\n",
        "\n",
        "\n",
        "# This doesnt work as we exceeded the amount of values in a tensor \n",
        "try: \n",
        "  tf.reshape(rank_3_tensor , shape = [7 , -1])\n",
        "except Exception as e:\n",
        "  print(f'{type(e).__name__}: {e}')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]\n",
            "  [10 11 12 13 14]]\n",
            "\n",
            " [[15 16 17 18 19]\n",
            "  [20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]\n",
            " [24 25 26 27 28 29]], shape=(5, 6), dtype=int32)\n",
            "InvalidArgumentError: Input to reshape is a tensor with 30 values, but the requested shape requires a multiple of 7 [Op:Reshape]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7OkyhYW-ai2"
      },
      "source": [
        "### Broadcasting \n",
        "\n",
        "Under certain conditions, smaller tensors are stretched automatically to fit larger tensors when running combined operations on them. \n",
        "\n",
        "This will come in handy when **we attempt to multiply or add a tensor to a scalar**. \n",
        "\n",
        "In that case, the scalar is broadcast to be the same shape as the other argument. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqgCVxtt_00l",
        "outputId": "201e099b-4333-41af-e318-e951bf5f87b7"
      },
      "source": [
        "x = tf.constant([[ 1, 2, 3]])\n",
        "y = tf.constant(2)\n",
        "z = tf.constant([2,2,2])\n",
        "\n",
        "# Broadcasting on the fly \n",
        "print(tf.multiply(x ,2))\n",
        "print(x * y)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[2 4 6]], shape=(1, 3), dtype=int32)\n",
            "tf.Tensor([[2 4 6]], shape=(1, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl5TRbplBB0f"
      },
      "source": [
        "Likewise, axes with the length 1 (ndim) can be stretched out to match the other arguments. Both arguments can be stretched into the same computation. \n",
        "\n",
        "In that case a 3x1 matrix is element-wise multiplied by a **1x4 matrix to produce a 3x4 matrix**. \n",
        "\n",
        "`3x1 | 1x4` we get 3x4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qLqicjEB6n0",
        "outputId": "f41ff27c-2faa-43ca-b92d-dfbf0be21662"
      },
      "source": [
        "x = tf.reshape(x , [3,1]) \n",
        "print(x.shape)\n",
        "y = tf.range(1,5)\n",
        "\n",
        "print(tf.multiply(x , y))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 1)\n",
            "tf.Tensor(\n",
            "[[ 1  2  3  4]\n",
            " [ 2  4  6  8]\n",
            " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6vhf5bIC_yy",
        "outputId": "39e75951-2068-4342-9b4c-3081c8e820c2"
      },
      "source": [
        "# Doing the same operation without broadcasting \n",
        "x_stretch = tf.constant([[1, 1, 1, 1],\n",
        "                         [2, 2, 2, 2],\n",
        "                         [3, 3, 3, 3]])\n",
        "\n",
        "y_stretch = tf.constant([[1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4]])\n",
        "\n",
        "print(x_stretch * y_stretch)  # Again, operator overloading"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 1  2  3  4]\n",
            " [ 2  4  6  8]\n",
            " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPgprN3bDtbd",
        "outputId": "0a56378d-6eda-4db6-d839-2496b7c05e85"
      },
      "source": [
        "print(tf.broadcast_to(x , y))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[1 1 1 1]\n",
            "   [2 2 2 2]\n",
            "   [3 3 3 3]]\n",
            "\n",
            "  [[1 1 1 1]\n",
            "   [2 2 2 2]\n",
            "   [3 3 3 3]]]], shape=(1, 2, 3, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-Cx9keKEcSj"
      },
      "source": [
        "[To know more about broadcasting](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkXXYeG6Etv9"
      },
      "source": [
        "### `tf.convert_to_tensor()`\n",
        "\n",
        "We use the `convert_to_tensor` on non-tensor arguments. There is registery of conversions, and most object classes like Numpys `ndarray`, `TensorShape`, Python lists and `tf.Variable` will all convert automatically. \n",
        "\n",
        "Also we can use `tf.register_tensor_conversion_function` if we have our own type of dtype to convert into a tensor. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo-L--YPE-aS"
      },
      "source": [
        "### Ragged Tensors \n",
        "\n",
        "A tensor with variable numbers of elements along some axis is called **ragged**. In that case `tf.ragged.RaggedTensor` for ragged data. \n",
        "\n",
        "\n",
        "Below isnt a ragged tensor, \n",
        "`[4 , None]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFZ-6WspHF2m"
      },
      "source": [
        "ragged_list = [\n",
        "  [0 ,1 , 2 ,3], \n",
        "  [4,5] ,\n",
        "  [6,7,8], \n",
        "  [9]\n",
        "]"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFeoaBT-IGoe",
        "outputId": "32962cea-c8dd-47d4-abdc-a3e7338964e1"
      },
      "source": [
        "try:\n",
        "  tensor = tf.constant(ragged_list)\n",
        "except Exception as e:\n",
        "  print(f'{type(e).__name__}: {e}')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ValueError: Can't convert non-rectangular Python sequence to Tensor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5yNg9L2IVxG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}