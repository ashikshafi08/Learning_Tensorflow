{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Crowd_Research_paper_classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNzPjtjYEv65Wf2HG9sGaEi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning_Tensorflow/blob/main/TensorFlow/AI_Crowd_Research_paper_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENEkFHAC96qf",
        "outputId": "04bb2851-292b-408f-d98c-68a0e599d700"
      },
      "source": [
        "!pip install aicrowd-cli\n",
        "API_KEY = '' \n",
        "!aicrowd login --api-key $API_KEY\n",
        "\n",
        "# Downloading the Dataset\n",
        "# Downloading the Dataset ( removing data and assets folder if existing already and then creating the folder )\n",
        "!rm -rf data\n",
        "!mkdir data\n",
        "!rm -rf assets\n",
        "!mkdir assets\n",
        "\n",
        "!aicrowd dataset download --challenge research-paper-classification -j 3 -o data # Downloading the dataset and saving it in data folder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting aicrowd-cli\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/57/59b5a00c6e90c9cc028b3da9dff90e242ad2847e735b1a0e81a21c616e27/aicrowd_cli-0.1.7-py3-none-any.whl (49kB)\n",
            "\r\u001b[K     |██████▋                         | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 20kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 30kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 40kB 26.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml<1,>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (0.10.2)\n",
            "Requirement already satisfied: click<8,>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (7.1.2)\n",
            "Collecting requests<3,>=2.25.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.6MB/s \n",
            "\u001b[?25hCollecting tqdm<5,>=4.56.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/d7/f357d98e9b50346bcb6095fe3ad205d8db3174eb5edb03edfe7c4099576d/tqdm-4.61.0-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.9MB/s \n",
            "\u001b[?25hCollecting gitpython<4,>=3.1.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/da/6f6224fdfc47dab57881fe20c0d1bc3122be290198ba0bf26a953a045d92/GitPython-3.1.17-py3-none-any.whl (166kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 36.3MB/s \n",
            "\u001b[?25hCollecting requests-toolbelt<1,>=0.9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.3MB/s \n",
            "\u001b[?25hCollecting rich<11,>=10.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/32/eb8aadb1ed791081e5c773bd1dfa15f1a71788fbeda37b12f837f2b1999b/rich-10.3.0-py3-none-any.whl (205kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 36.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (2020.12.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (1.24.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from gitpython<4,>=3.1.12->aicrowd-cli) (3.7.4.3)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich<11,>=10.0.0->aicrowd-cli) (2.6.1)\n",
            "Collecting colorama<0.5.0,>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/92/dfd892312d822f36c55366118b95d914e5f16de11044a27cf10a7d71bbbf/commonmark-0.9.1-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.9MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: requests, tqdm, smmap, gitdb, gitpython, requests-toolbelt, colorama, commonmark, rich, aicrowd-cli\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed aicrowd-cli-0.1.7 colorama-0.4.4 commonmark-0.9.1 gitdb-4.0.7 gitpython-3.1.17 requests-2.25.1 requests-toolbelt-0.9.1 rich-10.3.0 smmap-4.0.0 tqdm-4.61.0\n",
            "\u001b[32mAPI Key valid\u001b[0m\n",
            "\u001b[32mSaved API Key successfully!\u001b[0m\n",
            "\n",
            "test.csv:   0% 0.00/3.01M [00:00<?, ?B/s]\n",
            "val.csv: 100% 883k/883k [00:00<00:00, 2.18MB/s]\n",
            "\n",
            "test.csv: 100% 3.01M/3.01M [00:00<00:00, 5.38MB/s]\n",
            "\n",
            "train.csv: 100% 8.77M/8.77M [00:00<00:00, 9.69MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF30ATBWmDG6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhCnFZ-_-WO1"
      },
      "source": [
        "# Importing all the packages we need \n",
        "import tensorflow as tf \n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIS32YRG_HkD",
        "outputId": "fbf413a8-738e-4b62-8188-6b6d3a0f5829"
      },
      "source": [
        "# Importing the data \n",
        "\n",
        "train_data = pd.read_csv('data/train.csv')\n",
        "val_data = pd.read_csv('data/val.csv')\n",
        "test_data = pd.read_csv('data/test.csv')\n",
        "\n",
        "# Printing out all shapes of our data \n",
        "print(f'Shape of the train data: {train_data.shape}')\n",
        "print(f'Shape of the validation data: {val_data.shape}')\n",
        "print(f'Shape of the test data: {test_data.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the train data: (31500, 3)\n",
            "Shape of the validation data: (2700, 3)\n",
            "Shape of the test data: (10800, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fQHKZBgd_I55",
        "outputId": "c366bce7-f9bc-432c-fa9a-846d30122754"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>we propose deep network models and learning al...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>multi-distance information computed by the MDL...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>traditional solutions consider dense pedestria...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>in this paper, is used the lagrangian classica...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>the aim of this work is to determine how vulne...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               text  label\n",
              "0   0  we propose deep network models and learning al...      3\n",
              "1   1  multi-distance information computed by the MDL...      3\n",
              "2   2  traditional solutions consider dense pedestria...      2\n",
              "3   3  in this paper, is used the lagrangian classica...      2\n",
              "4   4  the aim of this work is to determine how vulne...      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvVYmrtL_KqJ",
        "outputId": "eb0e2e2e-fddc-4b97-def3-c478963d5e8f"
      },
      "source": [
        "# How many labels are there? \n",
        "train_data['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    19676\n",
              "0     4352\n",
              "1     4078\n",
              "2     3394\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "j6UTGMzp_R1R",
        "outputId": "8c6b91bd-6539-41f2-89e6-da59d8a3bc8f"
      },
      "source": [
        "# Plotting the above same stuff \n",
        "train_data['label'].value_counts().plot(kind = 'barh')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f135e940ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxeQuA0cHn5s",
        "outputId": "00e1d0a2-612a-4fe2-9b50-126318cb5b9d"
      },
      "source": [
        "# Shuffling our train data \n",
        "train_data_shuffled = train_data.sample(frac = 1 , random_state = 42)\n",
        "train_data_shuffled.head() , train_data_shuffled.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(          id                                               text  label\n",
              " 14664  14664  DefGrid is a learnable neural network module t...      3\n",
              " 1981    1981  combining Haar-Hilbert and Log-Gabor improves ...      3\n",
              " 18349  18349  the simulator, based on ROS (Robot Operating S...      2\n",
              " 20489  20489  we propose a method to synthesize policies tha...      0\n",
              " 18121  18121  previous flow completion methods are often una...      3,\n",
              " (31500, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKJzpvFeFjym",
        "outputId": "a1fd8c0f-55ed-435f-f732-a7886928455d"
      },
      "source": [
        "# Splitting sentences and labels\n",
        "train_sentences = train_data_shuffled['text'].to_numpy()\n",
        "train_labels = train_data_shuffled['label'].to_numpy()\n",
        "\n",
        "val_sentences = val_data['text'].to_numpy()\n",
        "val_labels = val_data['label'].to_numpy()\n",
        "\n",
        "test_sentences = test_data['text'].to_numpy()\n",
        "test_labels = test_data['label'].to_numpy()\n",
        "\n",
        "\n",
        "# Checking the shapes \n",
        "print(f'Shape of the train sentences: {train_sentences.shape}')\n",
        "print(f'Shape of the validation sentences: {val_sentences.shape}')\n",
        "print(f'Shape of the train labels: {train_labels.shape}')\n",
        "print(f'Shape of the validation labels: {val_labels.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the train sentences: (31500,)\n",
            "Shape of the validation sentences: (2700,)\n",
            "Shape of the train labels: (31500,)\n",
            "Shape of the validation labels: (2700,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bh0jVlDHV4i"
      },
      "source": [
        "# Converting into dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences , train_labels))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences , val_labels))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Awy5Jss9KVXp",
        "outputId": "48b14d15-b257-4186-f715-6362f17f8101"
      },
      "source": [
        "train_dataset.element_spec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMkfiFYdL4Nm"
      },
      "source": [
        "# Enabling prefetch and turning our data into batches.\n",
        "\n",
        "train_dataset = train_dataset.shuffle(buffer_size= 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(batch_size = 32).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikf8ZirfMv7w",
        "outputId": "dcf216b6-e8bb-4b1e-a468-4d8ba4b63ab0"
      },
      "source": [
        "train_dataset , val_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PrefetchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int64)>,\n",
              " <PrefetchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int64)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yAqG_kNOJ6L",
        "outputId": "809f2f13-d8fc-414a-f370-01bdeacd3db3"
      },
      "source": [
        "for text , label in train_dataset.take(1):\n",
        "  print(f'Label: {label[0]}')\n",
        "  print(f'\\nText:\\n {text[0]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 2\n",
            "\n",
            "Text:\n",
            " b'the method paves the way for deducting high-level reactive behaviors from low-level perceptive information by autonomous robots . the aforementioned process lets us actualize different generations of Braitenberg vehicles .'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyUqT2xFOPIS"
      },
      "source": [
        "# Setting up our text vectorization variable \n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "max_vocab_length = 15000 \n",
        "max_length = 18\n",
        "\n",
        "# Creating a instance \n",
        "text_vectorizer = TextVectorization(max_tokens = max_vocab_length ,\n",
        "                                    output_mode = 'int' , \n",
        "                                    output_sequence_length = max_length)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw7aWQmCQjRi"
      },
      "source": [
        "# Fit the text vectorizer to the training sentence\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REIW-Oh7Qq3y",
        "outputId": "7b0cafbd-dda5-445a-d143-26973810f58c"
      },
      "source": [
        "# Creating a embedding layer \n",
        "from tensorflow.keras import layers \n",
        "\n",
        "embedding = layers.Embedding(input_dim = max_vocab_length , \n",
        "                             output_dim = 128 , \n",
        "                             input_length = max_length)\n",
        "\n",
        "embedding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f1356a2acd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksn09CT1V5Oy",
        "outputId": "4450120b-9ef8-4fc5-d043-74d7f33c126a"
      },
      "source": [
        "train_dataset.element_spec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(None,), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ymqtu5Z2Tu4o",
        "outputId": "64c47650-57ea-4e8f-b655-914459b923dd"
      },
      "source": [
        "# Building an LSTM Model \n",
        "from tensorflow.keras import layers \n",
        "\n",
        "# Setting up the inputs \n",
        "inputs = layers.Input(shape = (1,), dtype = tf.string)\n",
        "\n",
        "# Converting text into numbers and creating a embedding \n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "\n",
        "# The LSTM model \n",
        "#x = layers.Bidirectional(layers.LSTM(64 , return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "#x = layers.LSTM(32 , return_sequences= True)(x)\n",
        "#x = layers.LSTM(8)(x)\n",
        "x = layers.Dense(10 , activation = 'relu')(x)\n",
        "\n",
        "# Intializing our outputs \n",
        "outputs = layers.Dense(4 , activation= 'softmax')(x)\n",
        "\n",
        "# Packing into a model \n",
        "lstm_model = tf.keras.Model(inputs , outputs , name = 'LSTM_model')\n",
        "\n",
        "# Summary of the model \n",
        "lstm_model.summary()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"LSTM_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 18)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 18, 128)           1920000   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 4)                 44        \n",
            "=================================================================\n",
            "Total params: 2,020,150\n",
            "Trainable params: 2,020,150\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rbGOS7SWusu"
      },
      "source": [
        "# Compiling the model \n",
        "lstm_model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy() , \n",
        "                   optimizer = tf.keras.optimizers.Adam() , \n",
        "                   metrics = ['accuracy'])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YyrjAxCXGpE",
        "outputId": "9d979e91-0220-4029-ba77-e49bc63cbc3d"
      },
      "source": [
        "# Fitting the model \n",
        "lstm_history = lstm_model.fit(train_dataset , \n",
        "                              validation_data = val_dataset , \n",
        "                              epochs = 5)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "985/985 [==============================] - 44s 42ms/step - loss: 0.1457 - accuracy: 0.9501 - val_loss: 1.2463 - val_accuracy: 0.7356\n",
            "Epoch 2/5\n",
            "985/985 [==============================] - 40s 41ms/step - loss: 0.0437 - accuracy: 0.9857 - val_loss: 1.5440 - val_accuracy: 0.7430\n",
            "Epoch 3/5\n",
            "985/985 [==============================] - 40s 41ms/step - loss: 0.0323 - accuracy: 0.9888 - val_loss: 1.6713 - val_accuracy: 0.7126\n",
            "Epoch 4/5\n",
            "985/985 [==============================] - 40s 41ms/step - loss: 0.0294 - accuracy: 0.9896 - val_loss: 1.5848 - val_accuracy: 0.7211\n",
            "Epoch 5/5\n",
            "985/985 [==============================] - 40s 41ms/step - loss: 0.0222 - accuracy: 0.9920 - val_loss: 1.8471 - val_accuracy: 0.7304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZGS4jqKcciL",
        "outputId": "7d816933-85e1-4244-922c-4c4a84ff4612"
      },
      "source": [
        "lstm_pred_probs = lstm_model.predict(test_sentences)\n",
        "lstm_preds = np.argmax(lstm_pred_probs , axis =1)\n",
        "lstm_preds[:10]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 3, 3, 1, 1, 1, 3, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "yw6GCb0jcgFs",
        "outputId": "875b2a02-d607-4ead-9742-7ddf0889fc08"
      },
      "source": [
        "# Dropping the label column\n",
        "test_data.drop('label' , inplace = True , axis = 1)\n",
        "\n",
        "# Assigning the predictions\n",
        "test_data['label'] = lstm_preds\n",
        "test_data.head()\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>we propose a lightweight framework to detect i...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>the proposed method presents an alternate solu...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>proposed ear identification method fusing SIFT...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>a method to reconstruct the three-dimensional ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>strong local consistencies can improve their p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               text  label\n",
              "0   0  we propose a lightweight framework to detect i...      3\n",
              "1   1  the proposed method presents an alternate solu...      2\n",
              "2   2  proposed ear identification method fusing SIFT...      3\n",
              "3   3  a method to reconstruct the three-dimensional ...      3\n",
              "4   4  strong local consistencies can improve their p...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoKGJCNsdxIQ"
      },
      "source": [
        "### Using Transfer Learning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxXN_ODXel0w"
      },
      "source": [
        "# Creating a Keras layer \n",
        "import tensorflow_hub as hub\n",
        "sentence_encoder_layer = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4' , \n",
        "                                        input_shape = [] , # Defining a input shape so our layer will take anything sequence as a input (any variable length)\n",
        "                                        dtype = tf.string , \n",
        "                                        trainable = False , \n",
        "                                        name = 'USE_layer')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjR69er1eonD",
        "outputId": "6639200b-06fa-4bea-91d4-aff3d98314a2"
      },
      "source": [
        "# Building a model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "use_model = tf.keras.Sequential([\n",
        "  sentence_encoder_layer,\n",
        "  layers.Dense(64 , activation = 'relu'),\n",
        "  layers.Dense(4 , activation = 'softmax')\n",
        "\n",
        "] , name = 'USE_model')\n",
        "\n",
        "# Summary of the mdoel \n",
        "use_model.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"USE_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE_layer (KerasLayer)       (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 256,830,916\n",
            "Trainable params: 33,092\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbALv__RfCZY",
        "outputId": "ae034a84-6de1-4065-ca7d-116f9d32d634"
      },
      "source": [
        "# Compiling the model \n",
        "use_model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy() , \n",
        "                  optimizer = tf.keras.optimizers.Adam() , \n",
        "                  metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the model \n",
        "use_history = use_model.fit(train_dataset , \n",
        "                            validation_data = val_dataset , \n",
        "                            epochs = 5)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "985/985 [==============================] - 15s 14ms/step - loss: 0.5945 - accuracy: 0.7766 - val_loss: 0.5126 - val_accuracy: 0.8174\n",
            "Epoch 2/5\n",
            "985/985 [==============================] - 13s 13ms/step - loss: 0.5099 - accuracy: 0.8079 - val_loss: 0.5053 - val_accuracy: 0.8141\n",
            "Epoch 3/5\n",
            "985/985 [==============================] - 13s 13ms/step - loss: 0.4971 - accuracy: 0.8112 - val_loss: 0.4985 - val_accuracy: 0.8196\n",
            "Epoch 4/5\n",
            "985/985 [==============================] - 13s 13ms/step - loss: 0.4864 - accuracy: 0.8151 - val_loss: 0.4892 - val_accuracy: 0.8263\n",
            "Epoch 5/5\n",
            "985/985 [==============================] - 13s 13ms/step - loss: 0.4756 - accuracy: 0.8201 - val_loss: 0.4839 - val_accuracy: 0.8248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aec83_g_fXPr",
        "outputId": "c740d8e5-43e9-4030-fa3c-153cd8b138c7"
      },
      "source": [
        "use_pred_probs = use_model.predict(test_sentences)\n",
        "use_preds = np.argmax(use_pred_probs , axis =1)\n",
        "use_preds[:10]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 3, 0, 1, 3, 0, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "lDkte3ugfll6",
        "outputId": "048142bd-e048-4c4b-eeb9-6bad992bda58"
      },
      "source": [
        "# Dropping the label column\n",
        "test_data.drop('label' , inplace = True , axis = 1)\n",
        "\n",
        "# Assigning the predictions\n",
        "test_data['label'] = use_preds\n",
        "test_data.head()\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>we propose a lightweight framework to detect i...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>the proposed method presents an alternate solu...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>proposed ear identification method fusing SIFT...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>a method to reconstruct the three-dimensional ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>strong local consistencies can improve their p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               text  label\n",
              "0   0  we propose a lightweight framework to detect i...      3\n",
              "1   1  the proposed method presents an alternate solu...      3\n",
              "2   2  proposed ear identification method fusing SIFT...      3\n",
              "3   3  a method to reconstruct the three-dimensional ...      3\n",
              "4   4  strong local consistencies can improve their p...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPGVPDpffzlM"
      },
      "source": [
        "import os\n",
        "#!mkdir assets\n",
        "test_data.to_csv(os.path.join(\"assets\", \"submission.csv\"), index=False)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3YabuYUgGZt",
        "outputId": "911d723f-4a2b-4f8a-854f-82adda742a79"
      },
      "source": [
        "!aicrowd notebook submit -c research-paper-classification -a assets --no-verify"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using notebook: /content/drive/MyDrive/Colab Notebooks/AI_Crowd_Research_paper_classification.ipynb for submission...\n",
            "Removing existing files from submission directory...\n",
            "Scrubbing API keys from the notebook...\n",
            "Collecting notebook...\n",
            "\u001b[2K\u001b[1;34msubmission.zip\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m • \u001b[32m1.1/1.1 MB\u001b[0m • \u001b[31m1.7 MB/s\u001b[0m • \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h                                                        ╭─────────────────────────╮                                                        \n",
            "                                                        │ \u001b[1mSuccessfully submitted!\u001b[0m │                                                        \n",
            "                                                        ╰─────────────────────────╯                                                        \n",
            "\u001b[3m                                                              Important links                                                              \u001b[0m\n",
            "┌──────────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
            "│  This submission │ https://www.aicrowd.com/challenges/ai-blitz-9/problems/research-paper-classification/submissions/145873              │\n",
            "│                  │                                                                                                                      │\n",
            "│  All submissions │ https://www.aicrowd.com/challenges/ai-blitz-9/problems/research-paper-classification/submissions?my_submissions=true │\n",
            "│                  │                                                                                                                      │\n",
            "│      Leaderboard │ https://www.aicrowd.com/challenges/ai-blitz-9/problems/research-paper-classification/leaderboards                    │\n",
            "│                  │                                                                                                                      │\n",
            "│ Discussion forum │ https://discourse.aicrowd.com/c/ai-blitz-9                                                                           │\n",
            "│                  │                                                                                                                      │\n",
            "│   Challenge page │ https://www.aicrowd.com/challenges/ai-blitz-9/problems/research-paper-classification                                 │\n",
            "└──────────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW-EfL4SgQCI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}