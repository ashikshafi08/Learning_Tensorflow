{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of AI_Crowd_Research_paper_classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMd7ED0ocxbhfVrOIipkMOD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning_Tensorflow/blob/main/Experiments/Copy_of_AI_Crowd_Research_paper_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENEkFHAC96qf",
        "outputId": "b4f8d0e6-eb57-4b10-c404-81b5c489bf06"
      },
      "source": [
        "!pip install aicrowd-cli\n",
        "API_KEY = '' \n",
        "!aicrowd login --api-key $API_KEY\n",
        "\n",
        "# Downloading the Dataset\n",
        "# Downloading the Dataset ( removing data and assets folder if existing already and then creating the folder )\n",
        "!rm -rf data\n",
        "!mkdir data\n",
        "!rm -rf assets\n",
        "!mkdir assets\n",
        "\n",
        "!aicrowd dataset download --challenge research-paper-classification -j 3 -o data # Downloading the dataset and saving it in data folder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting aicrowd-cli\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/57/59b5a00c6e90c9cc028b3da9dff90e242ad2847e735b1a0e81a21c616e27/aicrowd_cli-0.1.7-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[?25hCollecting gitpython<4,>=3.1.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/da/6f6224fdfc47dab57881fe20c0d1bc3122be290198ba0bf26a953a045d92/GitPython-3.1.17-py3-none-any.whl (166kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 21.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml<1,>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (0.10.2)\n",
            "Collecting tqdm<5,>=4.56.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/20/9f1e974bb4761128fc0d0a32813eaa92827309b1756c4b892d28adfb4415/tqdm-4.61.1-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 4.8MB/s \n",
            "\u001b[?25hCollecting requests<3,>=2.25.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.1MB/s \n",
            "\u001b[?25hCollecting rich<11,>=10.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/32/eb8aadb1ed791081e5c773bd1dfa15f1a71788fbeda37b12f837f2b1999b/rich-10.3.0-py3-none-any.whl (205kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 33.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<8,>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (7.1.2)\n",
            "Collecting requests-toolbelt<1,>=0.9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from gitpython<4,>=3.1.12->aicrowd-cli) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (1.24.3)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/92/dfd892312d822f36c55366118b95d914e5f16de11044a27cf10a7d71bbbf/commonmark-0.9.1-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.6MB/s \n",
            "\u001b[?25hCollecting colorama<0.5.0,>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich<11,>=10.0.0->aicrowd-cli) (2.6.1)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: smmap, gitdb, gitpython, tqdm, requests, commonmark, colorama, rich, requests-toolbelt, aicrowd-cli\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed aicrowd-cli-0.1.7 colorama-0.4.4 commonmark-0.9.1 gitdb-4.0.7 gitpython-3.1.17 requests-2.25.1 requests-toolbelt-0.9.1 rich-10.3.0 smmap-4.0.0 tqdm-4.61.1\n",
            "\u001b[32mAPI Key valid\u001b[0m\n",
            "\u001b[32mSaved API Key successfully!\u001b[0m\n",
            "train.csv:   0% 0.00/8.77M [00:00<?, ?B/s]\n",
            "test.csv:   0% 0.00/3.01M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "val.csv:   0% 0.00/883k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "val.csv: 100% 883k/883k [00:00<00:00, 2.69MB/s]\n",
            "\n",
            "test.csv: 100% 3.01M/3.01M [00:00<00:00, 6.16MB/s]\n",
            "train.csv: 100% 8.77M/8.77M [00:00<00:00, 13.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF30ATBWmDG6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhCnFZ-_-WO1"
      },
      "source": [
        "# Importing all the packages we need \n",
        "import tensorflow as tf \n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIS32YRG_HkD",
        "outputId": "75590eb0-f6e1-48aa-99af-3c235c2f490f"
      },
      "source": [
        "# Importing the data \n",
        "\n",
        "train_data = pd.read_csv('data/train.csv')\n",
        "val_data = pd.read_csv('data/val.csv')\n",
        "test_data = pd.read_csv('data/test.csv')\n",
        "\n",
        "# Printing out all shapes of our data \n",
        "print(f'Shape of the train data: {train_data.shape}')\n",
        "print(f'Shape of the validation data: {val_data.shape}')\n",
        "print(f'Shape of the test data: {test_data.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the train data: (31500, 3)\n",
            "Shape of the validation data: (2700, 3)\n",
            "Shape of the test data: (10800, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fQHKZBgd_I55",
        "outputId": "c59b217c-5536-48d6-c436-7b7081a0cf0e"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>we propose deep network models and learning al...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>multi-distance information computed by the MDL...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>traditional solutions consider dense pedestria...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>in this paper, is used the lagrangian classica...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>the aim of this work is to determine how vulne...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               text  label\n",
              "0   0  we propose deep network models and learning al...      3\n",
              "1   1  multi-distance information computed by the MDL...      3\n",
              "2   2  traditional solutions consider dense pedestria...      2\n",
              "3   3  in this paper, is used the lagrangian classica...      2\n",
              "4   4  the aim of this work is to determine how vulne...      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvVYmrtL_KqJ",
        "outputId": "a68f2f5f-b576-407d-f10f-e5ca3e17ab99"
      },
      "source": [
        "# How many labels are there? \n",
        "train_data['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    19676\n",
              "0     4352\n",
              "1     4078\n",
              "2     3394\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "j6UTGMzp_R1R",
        "outputId": "a039b57f-e11e-41f3-c444-1cf0e807a6a9"
      },
      "source": [
        "# Plotting the above same stuff \n",
        "train_data['label'].value_counts().plot(kind = 'barh')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8d6435fc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxeQuA0cHn5s",
        "outputId": "b413f7c0-e1bf-4a32-a747-e96779e19169"
      },
      "source": [
        "# Shuffling our train data \n",
        "train_data_shuffled = train_data.sample(frac = 1 , random_state = 42)\n",
        "train_data_shuffled.head() , train_data_shuffled.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(          id                                               text  label\n",
              " 14664  14664  DefGrid is a learnable neural network module t...      3\n",
              " 1981    1981  combining Haar-Hilbert and Log-Gabor improves ...      3\n",
              " 18349  18349  the simulator, based on ROS (Robot Operating S...      2\n",
              " 20489  20489  we propose a method to synthesize policies tha...      0\n",
              " 18121  18121  previous flow completion methods are often una...      3,\n",
              " (31500, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKJzpvFeFjym",
        "outputId": "4a0e993f-3637-4901-82aa-0585fa975088"
      },
      "source": [
        "# Splitting sentences and labels\n",
        "train_sentences = train_data_shuffled['text'].to_numpy()\n",
        "train_labels = train_data_shuffled['label'].to_numpy()\n",
        "\n",
        "val_sentences = val_data['text'].to_numpy()\n",
        "val_labels = val_data['label'].to_numpy()\n",
        "\n",
        "test_sentences = test_data['text'].to_numpy()\n",
        "test_labels = test_data['label'].to_numpy()\n",
        "\n",
        "\n",
        "# Checking the shapes \n",
        "print(f'Shape of the train sentences: {train_sentences.shape}')\n",
        "print(f'Shape of the validation sentences: {val_sentences.shape}')\n",
        "print(f'Shape of the train labels: {train_labels.shape}')\n",
        "print(f'Shape of the validation labels: {val_labels.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the train sentences: (31500,)\n",
            "Shape of the validation sentences: (2700,)\n",
            "Shape of the train labels: (31500,)\n",
            "Shape of the validation labels: (2700,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bh0jVlDHV4i"
      },
      "source": [
        "# Converting into dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences , train_labels))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences , val_labels))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Awy5Jss9KVXp",
        "outputId": "e38480fa-8cba-49de-a863-6f0a259dc5db"
      },
      "source": [
        "train_dataset.element_spec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMkfiFYdL4Nm"
      },
      "source": [
        "# Enabling prefetch and turning our data into batches.\n",
        "\n",
        "train_dataset = train_dataset.shuffle(buffer_size= 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(batch_size = 32).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikf8ZirfMv7w",
        "outputId": "9a9dceb1-3438-4932-ae00-2a4fbc2a107a"
      },
      "source": [
        "train_dataset , val_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PrefetchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int64)>,\n",
              " <PrefetchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int64)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6BzbjTZUce1",
        "outputId": "31d524da-89df-4b0e-c4e2-34d2dda7c803"
      },
      "source": [
        "import numpy as np \n",
        "zero , one , two , three = np.bincount(train_data['label'])\n",
        "total = zero + one + two + three\n",
        "print(f'Examples:\\n Total:{total}\\n\\n  Zero:{zero} ({100 * zero / total:.2f}% of total)\\n  One:{one}  ({100 * one / total:.2f}% of total)\\n  Two:{two}  ({100 * two / total:.2f}% of total)\\n  Three:{three} ({100 * three / total:.2f}% of total)\\n')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Examples:\n",
            " Total:31500\n",
            "\n",
            "  Zero:4352 (13.82% of total)\n",
            "  One:4078  (12.95% of total)\n",
            "  Two:3394  (10.77% of total)\n",
            "  Three:19676 (62.46% of total)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZi3aPoqUcjc"
      },
      "source": [
        "METRICS = [\n",
        "      tf.keras.metrics.TruePositives(name='tp'),\n",
        "      tf.keras.metrics.FalsePositives(name='fp'),\n",
        "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
        "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),\n",
        "      tf.keras.metrics.AUC(name='auc'),\n",
        "      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdfTjQ56Uco0",
        "outputId": "65df6624-b387-4288-81dc-7efa88c14d7e"
      },
      "source": [
        "# Calculating the class weights for each labels\n",
        "weight_for_0 = (1 / zero) * (total / 2.0)\n",
        "weight_for_1 = (1 / one) * (total / 2.0)\n",
        "weight_for_2 = (1 / two) * (total / 2.0)\n",
        "weight_for_3 = (1 / three) * (total / 2.0)\n",
        "\n",
        "# Creating a dictionary of class weights\n",
        "class_weight = {0: weight_for_0 , \n",
        "                1: weight_for_1 , \n",
        "                2: weight_for_2 , \n",
        "                3: weight_for_3}\n",
        "\n",
        "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
        "print('Weight for class 1: {:.2f}'.format(weight_for_1))\n",
        "print('Weight for class 2: {:.2f}'.format(weight_for_2))\n",
        "print('Weight for class 3: {:.2f}'.format(weight_for_3))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weight for class 0: 3.62\n",
            "Weight for class 1: 3.86\n",
            "Weight for class 2: 4.64\n",
            "Weight for class 3: 0.80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDtu7NpYUcsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda0e16f-e029-4237-eb86-491bc8f9b767"
      },
      "source": [
        "np.unique(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3v4MB8BUcyN"
      },
      "source": [
        "zero_train_labels = train_labels == 0\n",
        "one_train_labels = train_labels == 1\n",
        "two_train_labels = train_labels == 2\n",
        "three_train_labels = train_labels == 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVS3sPR3ClVO",
        "outputId": "453e327d-7bf9-4fb5-c677-06cf746fe31d"
      },
      "source": [
        "zero_label_features = train_sentences[zero_train_labels]\n",
        "one_label_features = train_sentences[one_train_labels]\n",
        "two_label_features = train_sentences[two_train_labels]\n",
        "three_label_features = train_sentences[three_train_labels]\n",
        "\n",
        "len(zero_label_features) , len(one_label_features) , len(two_label_features) , len(three_label_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4352, 4078, 3394, 19676)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaR8zXwoUc3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f51416-680e-4ecc-eb82-3ee9378f4da3"
      },
      "source": [
        "# Checking again\n",
        "print(f'Examples:\\n Total:{total}\\n\\n  Zero:{zero} ({100 * zero / total:.2f}% of total)\\n  One:{one}  ({100 * one / total:.2f}% of total)\\n  Two:{two}  ({100 * two / total:.2f}% of total)\\n  Three:{three} ({100 * three / total:.2f}% of total)\\n')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Examples:\n",
            " Total:31500\n",
            "\n",
            "  Zero:4352 (13.82% of total)\n",
            "  One:4078  (12.95% of total)\n",
            "  Two:3394  (10.77% of total)\n",
            "  Three:19676 (62.46% of total)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTiL0I5KUc-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f78916c-5b63-4087-aaff-73835d86c8e6"
      },
      "source": [
        "# Now doing the same for labels \n",
        "zero_labels = train_labels[zero_train_labels]\n",
        "one_labels = train_labels[one_train_labels]\n",
        "two_labels = train_labels[two_train_labels]\n",
        "three_labels = train_labels[three_train_labels]\n",
        "\n",
        "len(zero_labels) , len(one_labels) , len(two_labels) , len(three_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4352, 4078, 3394, 19676)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FwbfvoxUdBZ"
      },
      "source": [
        "Using `tf.data`\n",
        "\n",
        "Balancing the examples using the Dataset api "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srUhux2VUdEl"
      },
      "source": [
        "BUFFER_SIZE = 100000\n",
        "\n",
        "def make_ds(features , labels):\n",
        "  ds = tf.data.Dataset.from_tensor_slices((features , labels))\n",
        "  ds = ds.shuffle(BUFFER_SIZE).repeat()\n",
        "  return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFukSOXmUdHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6184cfa9-fb6d-473c-9a28-1f8af90c6440"
      },
      "source": [
        "zero_ds = make_ds(zero_label_features , zero_labels)\n",
        "one_ds = make_ds(one_label_features , one_labels)\n",
        "two_ds = make_ds(two_label_features , two_labels)\n",
        "three_ds = make_ds(three_label_features , three_labels)\n",
        "\n",
        "zero_ds , one_ds , two_ds , three_ds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<RepeatDataset shapes: ((), ()), types: (tf.string, tf.int64)>,\n",
              " <RepeatDataset shapes: ((), ()), types: (tf.string, tf.int64)>,\n",
              " <RepeatDataset shapes: ((), ()), types: (tf.string, tf.int64)>,\n",
              " <RepeatDataset shapes: ((), ()), types: (tf.string, tf.int64)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhdcmjQ7UdJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d83148ea-4e89-463e-8a80-f950145d8d08"
      },
      "source": [
        "# Merging all the datasets using (sample_from_datasets) \n",
        "BATCH_SIZE = 32\n",
        "resampled_train_ds = tf.data.experimental.sample_from_datasets([zero_ds , one_ds , two_ds , three_ds] , weights = [0.25 , 0.25 , 0.25 , 0.25])\n",
        "resampled_train_ds = resampled_train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "resampled_train_ds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdk5Cb8tFFNM",
        "outputId": "bc0a10c6-6b24-4a9a-ae9b-cc0e27474628"
      },
      "source": [
        "for features, label in resampled_train_ds.take(1):\n",
        "  print(label.numpy().mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syGCmpMDFFSL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFgsz_01FFXA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8NGIDnqFFbD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxOVBSu8FFfi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q4-Lkw4FFm2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yAqG_kNOJ6L",
        "outputId": "8289de0e-fbab-4623-e6ab-df86d3ca78ba"
      },
      "source": [
        "for text , label in train_dataset.take(1):\n",
        "  print(f'Label: {label[0]}')\n",
        "  print(f'\\nText:\\n {text[0]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 2\n",
            "\n",
            "Text:\n",
            " b'millimeter wave radar is becoming increasingly popular as a sensing modality for robotic mapping and state estimation . but there are very few publicly available datasets that include dense, high-resolution radar scans and none focused on 3D odometry and mapping .'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyUqT2xFOPIS"
      },
      "source": [
        "# Setting up our text vectorization variable \n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "max_vocab_length = 10000 \n",
        "max_length = 15\n",
        "\n",
        "# Creating a instance \n",
        "text_vectorizer = TextVectorization(max_tokens = max_vocab_length ,\n",
        "                                    output_mode = 'int' , \n",
        "                                    output_sequence_length = max_length)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw7aWQmCQjRi"
      },
      "source": [
        "# Fit the text vectorizer to the training sentence\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REIW-Oh7Qq3y",
        "outputId": "452cd232-6de4-4a1f-aa22-1cca7545c6ab"
      },
      "source": [
        "# Creating a embedding layer \n",
        "from tensorflow.keras import layers \n",
        "\n",
        "embedding = layers.Embedding(input_dim = max_vocab_length , \n",
        "                             output_dim = 128 , \n",
        "                             input_length = max_length)\n",
        "\n",
        "embedding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f8d5ace0e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksn09CT1V5Oy",
        "outputId": "fbd4a859-6d00-42a6-e603-c9cbeadda58c"
      },
      "source": [
        "steps_per_epoch = len(train_dataset) // BATCH_SIZE\n",
        "steps_per_epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzPm148O1VI_"
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 2:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.1)\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ymqtu5Z2Tu4o",
        "outputId": "565507c9-df46-4dda-abcd-cbab4b181c40"
      },
      "source": [
        "# Building an LSTM Model \n",
        "from tensorflow.keras import layers \n",
        "\n",
        "# Setting up the inputs \n",
        "inputs = layers.Input(shape = (1,), dtype = tf.string)\n",
        "\n",
        "# Converting text into numbers and creating a embedding \n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "\n",
        "# The LSTM model \n",
        "#x = layers.Bidirectional(layers.LSTM(64 , return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "#x = layers.LSTM(32 , return_sequences= True)(x)\n",
        "#x = layers.LSTM(8)(x)\n",
        "x = layers.Dense(32 , activation = 'relu')(x)\n",
        "#x = layers.Dropout(0.1)(x)\n",
        "# Intializing our outputs \n",
        "outputs = layers.Dense(4 , activation= 'softmax')(x)\n",
        "\n",
        "# Packing into a model \n",
        "lstm_model = tf.keras.Model(inputs , outputs , name = 'LSTM_model')\n",
        "\n",
        "# Summary of the model \n",
        "lstm_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"LSTM_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_2 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      multiple                  1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 4)                 132       \n",
            "=================================================================\n",
            "Total params: 1,383,076\n",
            "Trainable params: 1,383,076\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rbGOS7SWusu"
      },
      "source": [
        "# Compiling the model \n",
        "lstm_model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy() , \n",
        "                   optimizer = tf.keras.optimizers.Adam() , \n",
        "                   metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YyrjAxCXGpE",
        "outputId": "ef5c1e69-0182-427f-fd24-1a9c39d4753b"
      },
      "source": [
        "# Fitting the model \n",
        "lstm_history = lstm_model.fit(resampled_train_ds , \n",
        "                              steps_per_epoch = 350 ,\n",
        "                              validation_data = val_dataset , \n",
        "                              epochs = 6, \n",
        "                              class_weight = class_weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "350/350 [==============================] - 52s 44ms/step - loss: 0.7087 - accuracy: 0.8884 - val_loss: 1.2195 - val_accuracy: 0.6607\n",
            "Epoch 2/6\n",
            "350/350 [==============================] - 14s 41ms/step - loss: 0.2316 - accuracy: 0.9538 - val_loss: 1.4801 - val_accuracy: 0.6844\n",
            "Epoch 3/6\n",
            "350/350 [==============================] - 14s 41ms/step - loss: 0.1636 - accuracy: 0.9634 - val_loss: 1.5850 - val_accuracy: 0.6933\n",
            "Epoch 4/6\n",
            "350/350 [==============================] - 14s 41ms/step - loss: 0.1411 - accuracy: 0.9688 - val_loss: 1.4555 - val_accuracy: 0.7185\n",
            "Epoch 5/6\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.1432 - accuracy: 0.9682 - val_loss: 1.6042 - val_accuracy: 0.7211\n",
            "Epoch 6/6\n",
            "350/350 [==============================] - 14s 41ms/step - loss: 0.1135 - accuracy: 0.9735 - val_loss: 1.6443 - val_accuracy: 0.7156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZGS4jqKcciL",
        "outputId": "45551c36-4e7b-4d3a-9d0c-004fc7c4993b"
      },
      "source": [
        "lstm_pred_probs = lstm_model.predict(test_sentences)\n",
        "lstm_preds = np.argmax(lstm_pred_probs , axis =1)\n",
        "lstm_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 3, 3, 3, 1, 1, 1, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R7v4NPJ0QL6",
        "outputId": "79e553aa-5cfc-4e07-dbd0-c60f6cdeee00"
      },
      "source": [
        "lstm_pred_probs = lstm_model.predict(val_sentences)\n",
        "lstm_preds = np.argmax(lstm_pred_probs , axis =1)\n",
        "lstm_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 3, 3, 1, 3, 3, 3, 0, 3, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx03ys_Pzu_J"
      },
      "source": [
        "def classification_evaluation_metrics(y_true , \n",
        "                                      y_preds):\n",
        "  '''\n",
        "  Arguments: \n",
        "  y_true --> true labels of the data \n",
        "  y_preds --> predicted labels of the data \n",
        "\n",
        "  Returns: \n",
        "  A dictionary of evaluation metrics like precision , recall and f1_score\n",
        "  '''\n",
        "\n",
        "  # Let's first import the needed metrics \n",
        "  from sklearn.metrics import precision_score , f1_score , accuracy_score , recall_score\n",
        "\n",
        "  # Creting the metrics \n",
        "  accuracy = accuracy_score(y_true , y_preds)\n",
        "  f1_score = f1_score(y_true , y_preds , average = 'weighted')\n",
        "  precision = precision_score(y_true , y_preds , average = 'weighted')\n",
        "  recall = recall_score(y_true , y_preds , average = 'weighted')\n",
        "\n",
        "  # Now will create a dictionary of these metrics and pack them\n",
        "  evaluation_dict = {'Accuracy:': accuracy * 100 , \n",
        "                     'F1_Score: ': f1_score , \n",
        "                     'Precision: ': precision , \n",
        "                     'Recall: ': recall }\n",
        "\n",
        "  # Return our dictionary \n",
        "  return evaluation_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTANmt2Fz1CY",
        "outputId": "74fabed6-81f7-42e2-8bff-cd53e0db07bd"
      },
      "source": [
        "# Using the above function \n",
        "lstm_results = classification_evaluation_metrics(val_labels , \n",
        "                                                    lstm_preds)\n",
        "\n",
        "# Looking into the dictionary of evaluation metrics \n",
        "lstm_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 71.18518518518519,\n",
              " 'F1_Score: ': 0.7222431410310249,\n",
              " 'Precision: ': 0.7391961881455207,\n",
              " 'Recall: ': 0.7118518518518518}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "yw6GCb0jcgFs",
        "outputId": "6484f125-cc1b-46bb-ee38-2c11487bf92c"
      },
      "source": [
        "# Dropping the label column\n",
        "test_data.drop('label' , inplace = True , axis = 1)\n",
        "\n",
        "# Assigning the predictions\n",
        "test_data['label'] = lstm_preds\n",
        "test_data.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>we propose a lightweight framework to detect i...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>the proposed method presents an alternate solu...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>proposed ear identification method fusing SIFT...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>a method to reconstruct the three-dimensional ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>strong local consistencies can improve their p...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               text  label\n",
              "0   0  we propose a lightweight framework to detect i...      3\n",
              "1   1  the proposed method presents an alternate solu...      2\n",
              "2   2  proposed ear identification method fusing SIFT...      3\n",
              "3   3  a method to reconstruct the three-dimensional ...      3\n",
              "4   4  strong local consistencies can improve their p...      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oE1FuTXdNe2"
      },
      "source": [
        "test_data.to_csv('submission.csv' , index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoKGJCNsdxIQ"
      },
      "source": [
        "### Using Transfer Learning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxXN_ODXel0w"
      },
      "source": [
        "# Creating a Keras layer \n",
        "import tensorflow_hub as hub\n",
        "sentence_encoder_layer = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4' , \n",
        "                                        input_shape = [] , # Defining a input shape so our layer will take anything sequence as a input (any variable length)\n",
        "                                        dtype = tf.string , \n",
        "                                        trainable = False , \n",
        "                                        name = 'USE_layer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p61DzWLowGqV",
        "outputId": "bf2255ed-7f61-443b-8337-bdddafbaa3e8"
      },
      "source": [
        "len(train_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "985"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6IqTsa0vrBx"
      },
      "source": [
        "#!pip install tensorflow_addons\n",
        "import tensorflow_addons as tfa \n",
        "\n",
        "f1_score = tfa.metrics.F1Score( num_classes= 3, average = 'weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjR69er1eonD",
        "outputId": "3ef2d210-6a6f-4b99-9be3-547fef30194c"
      },
      "source": [
        "# Building a model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "use_model = tf.keras.Sequential([\n",
        "  sentence_encoder_layer,\n",
        "  layers.Dense(64 , activation = 'relu'),\n",
        "  #layers.Dense(64 , activation= 'relu'),\n",
        "  #layers.Dropout(0.1),\n",
        "  layers.Dense(4 , activation = 'softmax')\n",
        "\n",
        "] , name = 'USE_model')\n",
        "\n",
        "# Summary of the mdoel \n",
        "use_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"USE_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE_layer (KerasLayer)       (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 256,830,916\n",
            "Trainable params: 33,092\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbALv__RfCZY",
        "outputId": "b8d16eb2-11c5-4975-89eb-3acfe3ab1a62"
      },
      "source": [
        "# Compiling the model \n",
        "use_model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy() , \n",
        "                  optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0001) , \n",
        "                  metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the model \n",
        "use_history = use_model.fit(resampled_train_ds ,\n",
        "                            steps_per_epoch = 250 ,  \n",
        "                            validation_data = val_dataset , \n",
        "                            epochs = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 8s 24ms/step - loss: 1.3309 - accuracy: 0.5129 - val_loss: 1.2346 - val_accuracy: 0.6904\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 5s 20ms/step - loss: 1.1689 - accuracy: 0.6634 - val_loss: 1.0590 - val_accuracy: 0.7252\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 1.0155 - accuracy: 0.7007 - val_loss: 0.9609 - val_accuracy: 0.7059\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.9103 - accuracy: 0.7084 - val_loss: 0.8601 - val_accuracy: 0.7141\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 5s 20ms/step - loss: 0.8413 - accuracy: 0.7140 - val_loss: 0.7935 - val_accuracy: 0.7270\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.7971 - accuracy: 0.7172 - val_loss: 0.7590 - val_accuracy: 0.7278\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 5s 20ms/step - loss: 0.7669 - accuracy: 0.7197 - val_loss: 0.7239 - val_accuracy: 0.7370\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 5s 20ms/step - loss: 0.7470 - accuracy: 0.7222 - val_loss: 0.7007 - val_accuracy: 0.7407\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.7283 - accuracy: 0.7318 - val_loss: 0.6886 - val_accuracy: 0.7430\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.7179 - accuracy: 0.7285 - val_loss: 0.6900 - val_accuracy: 0.7381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aec83_g_fXPr",
        "outputId": "2a8a6416-631a-43dc-88de-becfe86c2759"
      },
      "source": [
        "use_pred_probs = use_model.predict(test_sentences)\n",
        "use_preds = np.argmax(use_pred_probs , axis =1)\n",
        "use_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 3, 3, 0, 1, 3, 1, 0, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbcKtnZcRejw"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\",\n",
        "                           input_shape=[], dtype=tf.string)\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(keras.layers.Dense(16, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "uClXdTCTSU2o",
        "outputId": "a60e8ca7-bc52-4fe0-aedb-6179083e1a62"
      },
      "source": [
        "# Creating a Keras Layer \n",
        "token_based_layer = hub.KerasLayer(\n",
        "    'https://tfhub.dev/google/nnlm-en-dim128/2' , \n",
        "    input_shape = [] , dtype = tf.string\n",
        ")\n",
        "\n",
        "# Building a model out of it \n",
        "token_based_model = tf.keras.Sequential([                                        \n",
        "  embedding ,                                          \n",
        "  token_based_layer ,  \n",
        "  #layers.Dense(64 , activation = 'tanh')\n",
        "  layers.Dense(64 , activation = 'relu'),\n",
        "  layers.Dropout(0.2), \n",
        "  layers.Dense(4 , activation = 'softmax')\n",
        "] , name = 'token_based_model_from_tfhub')\n",
        "\n",
        "#token_based_model.summary()\n",
        "\n",
        "# Compile the model \n",
        "token_based_model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy() , \n",
        "                          optimizer = tf.keras.optimizers.Adam() , \n",
        "                          metrics = ['accuracy'])\n",
        "\n",
        "# Fit the model \n",
        "token_based_model.fit(resampled_train_ds , \n",
        "                      steps_per_epoch = 350 , \n",
        "                      validation_data = val_dataset , \n",
        "                      epochs = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-140-f69de387ca05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m ] , name = 'token_based_model_from_tfhub')\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#token_based_model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 970\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1106\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1108\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow_hub/keras_layer.py:229 call  *\n        result = f()\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py:670 _call_attribute  **\n        return instance.__call__(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py:889 __call__\n        result = self._call(*args, **kwds)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py:954 _call\n        *args, **kwds)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py:2776 canonicalize_function_inputs\n        inputs, self._input_signature, self._flat_input_signature)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py:2878 _convert_inputs_to_signature\n        format_error_message(inputs, input_signature))\n\n    ValueError: Python inputs incompatible with input_signature:\n      inputs: (\n        Tensor(\"Placeholder:0\", shape=(None, 15, 128), dtype=float32))\n      input_signature: (\n        TensorSpec(shape=(None,), dtype=tf.string, name=None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWAcFndESU7L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZKDl34vSVAH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt1H3nh6SVHt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmWr1hrXSVMc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Zn2RsPSVR3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovOHC4UmSVW-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_wKw3xZSVZ5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klSCtvdWSVf2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "lDkte3ugfll6",
        "outputId": "f6624aab-e5ee-4bda-cdff-e371fac87a87"
      },
      "source": [
        "# Dropping the label column\n",
        "test_data.drop('label' , inplace = True , axis = 1)\n",
        "\n",
        "# Assigning the predictions\n",
        "test_data['label'] = use_preds\n",
        "test_data.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>we propose a lightweight framework to detect i...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>the proposed method presents an alternate solu...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>proposed ear identification method fusing SIFT...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>a method to reconstruct the three-dimensional ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>strong local consistencies can improve their p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               text  label\n",
              "0   0  we propose a lightweight framework to detect i...      3\n",
              "1   1  the proposed method presents an alternate solu...      2\n",
              "2   2  proposed ear identification method fusing SIFT...      3\n",
              "3   3  a method to reconstruct the three-dimensional ...      3\n",
              "4   4  strong local consistencies can improve their p...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPGVPDpffzlM"
      },
      "source": [
        "import os\n",
        "#!mkdir assets\n",
        "test_data.to_csv(os.path.join(\"assets\", \"submission.csv\"), index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3YabuYUgGZt",
        "outputId": "8c362a41-2382-48ba-b885-45e9e9f10216"
      },
      "source": [
        "!aicrowd notebook submit -c research-paper-classification -a assets --no-verify"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using notebook: /content/drive/MyDrive/Colab Notebooks/Copy of AI_Crowd_Research_paper_classification.ipynb for submission...\n",
            "Removing existing files from submission directory...\n",
            "Scrubbing API keys from the notebook...\n",
            "Collecting notebook...\n",
            "\u001b[2K\u001b[1;34msubmission.zip\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m • \u001b[32m1.1/1.1 MB\u001b[0m • \u001b[31m1.7 MB/s\u001b[0m • \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h                                                        ╭─────────────────────────╮                                                        \n",
            "                                                        │ \u001b[1mSuccessfully submitted!\u001b[0m │                                                        \n",
            "                                                        ╰─────────────────────────╯                                                        \n",
            "\u001b[3m                                                              Important links                                                              \u001b[0m\n",
            "┌──────────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
            "│  This submission │ https://www.aicrowd.com/challenges/ai-blitz-9/problems/research-paper-classification/submissions/146725              │\n",
            "│                  │                                                                                                                      │\n",
            "│  All submissions │ https://www.aicrowd.com/challenges/ai-blitz-9/problems/research-paper-classification/submissions?my_submissions=true │\n",
            "│                  │                                                                                                                      │\n",
            "│      Leaderboard │ https://www.aicrowd.com/challenges/ai-blitz-9/problems/research-paper-classification/leaderboards                    │\n",
            "│                  │                                                                                                                      │\n",
            "│ Discussion forum │ https://discourse.aicrowd.com/c/ai-blitz-9                                                                           │\n",
            "│                  │                                                                                                                      │\n",
            "│   Challenge page │ https://www.aicrowd.com/challenges/ai-blitz-9/problems/research-paper-classification                                 │\n",
            "└──────────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW-EfL4SgQCI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f8ce8b4-f93f-48f7-e11f-1b84cd8d38d2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmGaVMkmbuu4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}