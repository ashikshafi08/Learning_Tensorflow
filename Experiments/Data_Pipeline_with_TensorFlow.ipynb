{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Pipeline with TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOoKdqpBIM8sJYwj6KihM8i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning_Tensorflow/blob/main/Experiments/Data_Pipeline_with_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2BE-ltcHDV-",
        "outputId": "ef402f4e-6f23-4a0b-c0f1-776231f359ca"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjOdE6H9ocGJ"
      },
      "source": [
        "# Learning how to build data pipelines with `tf.data`\n",
        "\n",
        "The `tf.data` help us to build complex input pipelines from single, resuable pieces. \n",
        "\n",
        "For example the pipeline, \n",
        "- for an image model might aggregate data from files in a distributed file system and apply random perturbations to each image, and merge randomly selected images into a batch for training. \n",
        "- can be even used for text model might involve extracting symbolds from raw text data, converting them to embedding idenitifiers with a lookup table and batching together sequences of different lengths. \n",
        "\n",
        "The `tf.data` API makes it possible to handle large amounts of data, read from different data formats, and perform complex transformations.\n",
        "\n",
        "The `tf.data` API introduces a `tf.data.Dataset` abstraction that represents a sequence of elements, in which each element consists of one or more components. \n",
        "\n",
        "For example, in an image pipeline, an element might be a single training example, with a **pair of tensor components representing the image and it's label.**\n",
        "\n",
        "**The two distinct ways to create a dataset**: \n",
        "- A data **source** constructs a `Dataset` from data stored in memory or in one or more files. \n",
        "- A data **transformation** constructs a dataset from one or more `tf.data.Dataset`. \n",
        "\n",
        "\n",
        "## Basic Mechanics \n",
        "\n",
        "- To create an input pipeline, we must start with a data source. \n",
        "\n",
        "- (Other files) For example, to construct a `Dataset` from data in memory (folders etc..) we can use `tf.data.ataset.from_tensors()` or `tf.data.Dataset.from_tensor_slices()`. \n",
        "- (TFRecord file) If the input data is stored in a TFRecord format, we can then use `tf.data.TFRecordDataset()`\n",
        "\n",
        "> The `Dataset` object is a Python iterable (we can loop through). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtpkBQq1zXEZ"
      },
      "source": [
        "# Importing the things we need \n",
        "import tensorflow as tf\n",
        "import pathlib \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1QuZxr4HB82",
        "outputId": "2b42b59f-edd4-421f-d45a-3f1979c5a2c0"
      },
      "source": [
        "# Creating a dummy data and using tf.data.Dataset.from_tensor_slices()\n",
        "\n",
        "dum_list = [8 , 3, 0 , 8 , 2 , 1]\n",
        "dataset = tf.data.Dataset.from_tensor_slices(dum_list)\n",
        "dataset"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpDDR26YHCnK",
        "outputId": "683b43c9-0718-416d-c591-0ffa546b1599"
      },
      "source": [
        "# Iterating a looking what's inside the dataset we created \n",
        "for elem in dataset:\n",
        "  print(elem.numpy())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "3\n",
            "0\n",
            "8\n",
            "2\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXq5YqHe2nql",
        "outputId": "b7bc76a6-3b3d-48bc-a081-10eeebd8fe30"
      },
      "source": [
        "# Trying out a synthetic data \n",
        "\n",
        "(train_data , train_labels) , (test_data , test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Printing out the shapes of our mnist dataset \n",
        "train_data.shape , train_labels.shape , test_data.shape , test_labels.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv1TgdW4_Ekf"
      },
      "source": [
        "Loading our data usig `tf.data` and create a TensorSliceDataset object for our train data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSOnOXsC_a4v",
        "outputId": "eb2cefde-119a-485c-fa7f-632c7406f8db"
      },
      "source": [
        "# Turning our train data into TensorSliceDataset object \n",
        "train_dataset_slices = tf.data.Dataset.from_tensor_slices((train_data , train_labels))\n",
        "\n",
        "train_dataset_slices"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((28, 28), ()), types: (tf.uint8, tf.uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxclChAn_w5u"
      },
      "source": [
        "Cool! Now we have packed our train images and labels into a one whole Dataset. \n",
        "\n",
        "To view the labels https://stackoverflow.com/questions/64132847/how-to-iterate-over-tensorslicedataset-object-in-tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anuCMUdaAola",
        "outputId": "9556a00d-2f10-4c20-edc8-e87b0863cbdf"
      },
      "source": [
        "train_dataset_slices.element_spec"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(28, 28), dtype=tf.uint8, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.uint8, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqhsATzVA9PR"
      },
      "source": [
        "Let's try the same for but this time with `tf.data.Dataset.from_tensors()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duMYzJLIEKvH",
        "outputId": "d7e92b72-f180-4a54-85dd-497d180d9367"
      },
      "source": [
        "# Using tf.data.Dataset_from_tensors() \n",
        "\n",
        "train_data_tensors = tf.data.Dataset.from_tensors((train_data , train_labels))\n",
        "\n",
        "train_data_tensors"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorDataset shapes: ((60000, 28, 28), (60000,)), types: (tf.uint8, tf.uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvLGWlSjGABp",
        "outputId": "9795435b-d864-49ff-cc1d-0b7248461962"
      },
      "source": [
        "# Looking into our dataset \n",
        "train_data_tensors.element_spec"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(60000, 28, 28), dtype=tf.uint8, name=None),\n",
              " TensorSpec(shape=(60000,), dtype=tf.uint8, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CTweON4GFPQ",
        "outputId": "e6d0a5a5-5a27-43e4-b93d-f81021ae9f86"
      },
      "source": [
        "train_data_tensors.list_files"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function tensorflow.python.data.ops.dataset_ops.DatasetV2.list_files>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WhNKeSGGydv"
      },
      "source": [
        "Using the `tf.data.Dataset.from_generator()` now, this well help us to create a Dataset object from a datagenerator object. \n",
        "\n",
        "Useful links\n",
        "- [Converting ImageDatasetGenerator into dataset object](https://stackoverflow.com/questions/54606302/tf-data-dataset-from-tf-keras-preprocessing-image-imagedatagenerator-flow-from-d)\n",
        "- [How to use during fit function](\n",
        " https://stackoverflow.com/questions/52636127/how-to-use-keras-generator-with-tf-data-api)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-H_qIc6M2nU"
      },
      "source": [
        "# Loading in the cats and dogs dataset \n",
        "\n",
        "# data's url \n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "# Extracting from the path\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip' , origin = _URL , extract = True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip) , 'cats_and_dogs_filtered')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2Zbt4GxOMUP",
        "outputId": "ebce3ede-3b46-4db4-fe24-30e6eb0a30fa"
      },
      "source": [
        "# What's inside PATH? \n",
        "\n",
        "os.listdir(PATH)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vectorize.py', 'validation', 'train']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfQWluEYORnV"
      },
      "source": [
        "# Now setting up our train and validation directory (for images)\n",
        "train_dir = os.path.join(PATH , 'train')\n",
        "valid_dir = os.path.join(PATH , 'validation')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrcmQvQtOpqx",
        "outputId": "ff2347bb-e72e-4c7f-a881-ca078da0f6d0"
      },
      "source": [
        "# What's inside our train_dir \n",
        "os.listdir(train_dir)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dogs', 'cats']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63LuE3HlPbDJ",
        "outputId": "14e44607-0cc8-454e-e837-5b13f79eaa39"
      },
      "source": [
        "# Looking intos cats folder \n",
        "os.listdir(f'{train_dir}/cats')[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cat.826.jpg',\n",
              " 'cat.422.jpg',\n",
              " 'cat.862.jpg',\n",
              " 'cat.517.jpg',\n",
              " 'cat.966.jpg',\n",
              " 'cat.134.jpg',\n",
              " 'cat.506.jpg',\n",
              " 'cat.282.jpg',\n",
              " 'cat.135.jpg',\n",
              " 'cat.161.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfh7QObGOtGU",
        "outputId": "2527dff7-b450-40d5-f020-fe31384bfa41"
      },
      "source": [
        "# Using ImageDataGenerator \n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.)\n",
        "\n",
        "# Getting the images from our directory\n",
        "train_gen = train_datagen.flow_from_directory(train_dir)\n",
        "\n",
        "# For Validation \n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.)\n",
        "valid_gen  = valid_datagen.flow_from_directory(valid_dir)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZgEWihyvIJ8",
        "outputId": "da9f1e0e-d007-4894-a0cd-68c4d40724f2"
      },
      "source": [
        "images, labels = next(train_gen)\n",
        "\n",
        "# Checking their shapes\n",
        "images.shape , labels.shape , images.dtype , labels.dtype"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 256, 256, 3), (32, 2), dtype('float32'), dtype('float32'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8zt9J-0hFHo",
        "outputId": "de2b154d-2b97-4eb0-a17a-ee6d9875af01"
      },
      "source": [
        "train_gen.labels"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xcTFflXPkuT",
        "outputId": "2f92f859-8b86-4b36-90d6-ddb0219abc20"
      },
      "source": [
        "# Gotta inspect our train_gen and collect some info that may help us in converting to Dataset object \n",
        "\n",
        "print(f'Target size of images: {train_gen.target_size}')\n",
        "print(f'Number of classes: {train_gen.num_classes}')\n",
        "print(f'Getting the class indices: {train_gen.class_indices}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target size of images: (256, 256)\n",
            "Number of classes: 2\n",
            "Getting the class indices: {'cats': 0, 'dogs': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJtHEnZVQB-u"
      },
      "source": [
        "Alright! Now is the big game of converting our generator to Dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG8kCl1fQIII",
        "outputId": "86f3a390-9db4-48a0-8b70-b650fe405b71"
      },
      "source": [
        "train_dataset_gen = tf.data.Dataset.from_generator(\n",
        "    lambda: train_datagen.flow_from_directory(train_dir) , \n",
        "    output_types = (tf.float32 , tf.float32), \n",
        "    output_shapes = ([None, 256, 256 ,3] , [None , 2])\n",
        ")\n",
        "\n",
        "valid_dataset_gen = tf.data.Dataset.from_generator(\n",
        "    lambda: valid_datagen.flow_from_directory(valid_dir), \n",
        "    output_types = (tf.float32 , tf.float32), \n",
        "    output_shapes = ([None , 256 , 256 , 3] , [None , 2])\n",
        "\n",
        ")\n",
        "\n",
        "train_dataset_gen  , valid_dataset_gen"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<FlatMapDataset shapes: ((None, 256, 256, 3), (None, 2)), types: (tf.float32, tf.float32)>,\n",
              " <FlatMapDataset shapes: ((None, 256, 256, 3), (None, 2)), types: (tf.float32, tf.float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh-F0b_XdP86"
      },
      "source": [
        "it = iter(train_dataset_gen)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_2xSseSQvzZ",
        "outputId": "623cbe1e-ad09-43a4-a54a-fd136beb9fa3"
      },
      "source": [
        "for elem in train_dataset_gen:\n",
        "  print"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WVqYwnZ0uFK"
      },
      "source": [
        "unbatch_data = train_dataset_gen.apply(tf.data.experimental.unbatch())"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOC5Oqgq3SEw",
        "outputId": "2a818359-bba9-4afb-c36b-a645b2df9ddd"
      },
      "source": [
        "images , labels = next(iter(train_dataset_gen))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0eY2j-l61zt",
        "outputId": "129498a3-a032-4535-ff00-ef4817475695"
      },
      "source": [
        "class GeneratorLen(object):\n",
        "    def __init__(self, gen, length):\n",
        "        self.gen = gen\n",
        "        self.length = length\n",
        "\n",
        "    def __len__(self): \n",
        "        return self.length\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self.gen\n",
        "\n",
        "g = train_dataset_gen\n",
        "h = GeneratorLen(g, 1)\n",
        "print(len(h))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "LhtheuWRgENK",
        "outputId": "8b1c9906-d241-4ce4-fef5-ef68f2c3953a"
      },
      "source": [
        "list(h)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-9304c0e2ab5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: iter() returned non-iterator of type 'FlatMapDataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrIiTp5f618a",
        "outputId": "86746397-f6e9-4bf9-b229-c01f97ac235d"
      },
      "source": [
        "dum_train = train_dataset_gen.shuffle(buffer_size= 1000).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "dum_train"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, 256, 256, 3), (None, 2)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "TlVzAD_f62Be",
        "outputId": "3a356882-0e13-4cb8-947f-960fb1995209"
      },
      "source": [
        "len(dum_train)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-e54b0a5d3e2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdum_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset length is infinite.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mUNKNOWN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset length is unknown.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: dataset length is unknown."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGwFP4L-1bf0",
        "outputId": "cc0c4ec8-f702-4bf0-9152-4fa67ce9da5f"
      },
      "source": [
        "unbatch_data = unbatch_data."
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_UnbatchDataset shapes: ((256, 256, 3), (2,)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd_yXs-c0uLH",
        "outputId": "0012db79-5a3c-4f72-e222-99b2a6eeaad1"
      },
      "source": [
        "unbatch_data.padded_batch(32)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PaddedBatchDataset shapes: ((None, 256, 256, 3), (None, 2)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2k2I9mZQ95k",
        "outputId": "48603712-edea-4cc3-840f-14405225cb50"
      },
      "source": [
        "train_dataset_gen.take(1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: ((None, 256, 256, 3), (None, 2)), types: (tf.float32, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "yT01sL9ZRAeQ",
        "outputId": "5e626089-ce9a-4233-f088-4dac9f7d94ef"
      },
      "source": [
        "len(train_dataset_gen)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-52c460fa743e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset length is infinite.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mUNKNOWN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset length is unknown.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: dataset length is unknown."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRP-ZCUlUX9O",
        "outputId": "aac6ca5d-53db-4980-9743-e189699fa285"
      },
      "source": [
        ""
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input layer (InputLayer)     [(None, 160, 160, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 160, 160, 3)       39        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 54, 54, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 54, 54, 3)         39        \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 54, 54, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 54, 54, 3)         1539      \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 54, 54, 128)       512       \n",
            "_________________________________________________________________\n",
            "Output_layer (Dense)         (None, 54, 54, 2)         258       \n",
            "=================================================================\n",
            "Total params: 2,899\n",
            "Trainable params: 2,899\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18s4lGLvWmMd"
      },
      "source": [
        "model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy() , \n",
        "              optimizer = tf.keras.optimizers.Adam(), \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "696lbjqCc0Gy"
      },
      "source": [
        "model.fit(train_dataset_gen , \n",
        "          epochs = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1NhFUj9XNJY",
        "outputId": "6f423dc8-15a0-4f34-abd8-ce84e5bfbc68"
      },
      "source": [
        "train_dataset_gen.element_spec"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(None, 2), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL_tZu3YXxZx"
      },
      "source": [
        "Extracting images and labels from our dataset object. \n",
        "\n",
        "Useful link: https://stackoverflow.com/questions/56226621/how-to-extract-data-labels-back-from-tensorflow-dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIUfaQU_Yz-t"
      },
      "source": [
        "# Extracting images and labels from our dataset object\n",
        "for images , labels in train_dataset_gen.take(1):\n",
        "   sample_images = images \n",
        "   sample_labels = labels\n",
        "\n",
        "\n"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Kkhp7FWZDL7",
        "outputId": "11505cf0-5744-4f32-d36d-e6adfe27bc3a"
      },
      "source": [
        "len(sample_images) , len(sample_labels)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eObiJiugaIBd",
        "outputId": "0b7f828f-2379-41df-e94a-38adb7675fed"
      },
      "source": [
        "# Checking the image \n",
        "sample_images[:1]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 256, 256, 3), dtype=float32, numpy=\n",
              "array([[[[0.12156864, 0.16862746, 0.21568629],\n",
              "         [0.12156864, 0.16862746, 0.21568629],\n",
              "         [0.12156864, 0.16862746, 0.21568629],\n",
              "         ...,\n",
              "         [0.5529412 , 0.5176471 , 0.45882356],\n",
              "         [0.5529412 , 0.5176471 , 0.45882356],\n",
              "         [0.5647059 , 0.5294118 , 0.47058827]],\n",
              "\n",
              "        [[0.1137255 , 0.16078432, 0.20784315],\n",
              "         [0.10980393, 0.15686275, 0.20392159],\n",
              "         [0.10980393, 0.15686275, 0.20392159],\n",
              "         ...,\n",
              "         [0.5529412 , 0.5176471 , 0.45882356],\n",
              "         [0.5529412 , 0.5176471 , 0.45882356],\n",
              "         [0.56078434, 0.5254902 , 0.4666667 ]],\n",
              "\n",
              "        [[0.1137255 , 0.16078432, 0.20784315],\n",
              "         [0.10980393, 0.15686275, 0.20392159],\n",
              "         [0.10980393, 0.15686275, 0.20392159],\n",
              "         ...,\n",
              "         [0.5529412 , 0.5176471 , 0.45882356],\n",
              "         [0.5529412 , 0.5176471 , 0.45882356],\n",
              "         [0.56078434, 0.5254902 , 0.4666667 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.8313726 , 0.7607844 , 0.74509805],\n",
              "         [0.8470589 , 0.77647066, 0.7607844 ],\n",
              "         [0.8470589 , 0.77647066, 0.7607844 ],\n",
              "         ...,\n",
              "         [0.6313726 , 0.5921569 , 0.5529412 ],\n",
              "         [0.6313726 , 0.5921569 , 0.5529412 ],\n",
              "         [0.61960787, 0.5803922 , 0.5411765 ]],\n",
              "\n",
              "        [[0.8313726 , 0.7607844 , 0.74509805],\n",
              "         [0.8470589 , 0.77647066, 0.7607844 ],\n",
              "         [0.8470589 , 0.77647066, 0.7607844 ],\n",
              "         ...,\n",
              "         [0.6313726 , 0.5921569 , 0.5529412 ],\n",
              "         [0.6313726 , 0.5921569 , 0.5529412 ],\n",
              "         [0.61960787, 0.5803922 , 0.5411765 ]],\n",
              "\n",
              "        [[0.8352942 , 0.7490196 , 0.7058824 ],\n",
              "         [0.8470589 , 0.7686275 , 0.7254902 ],\n",
              "         [0.8470589 , 0.7686275 , 0.7254902 ],\n",
              "         ...,\n",
              "         [0.5803922 , 0.5411765 , 0.5019608 ],\n",
              "         [0.5803922 , 0.5411765 , 0.5019608 ],\n",
              "         [0.57254905, 0.53333336, 0.49411768]]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vrc-HpYNaJx0",
        "outputId": "3b0697b5-59ed-4c22-ce66-81db96d0c4d1"
      },
      "source": [
        "# Checking our labels \n",
        "sample_labels[:10]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 2), dtype=int32, numpy=\n",
              "array([[0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIe3gm-Aaa3J"
      },
      "source": [
        "# Applying the same on the whole dataset \n",
        "#for images , labels in train_dataset_gen.take(-1):\n",
        "#  train_images = images\n",
        "#  train_labels = labels\n",
        "\n",
        "# train_images , train_labels = tuple(zip(*train_dataset_gen))\n",
        "\n",
        "# The for loop is taking *infinitely* long time "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhI_1XNga4DH"
      },
      "source": [
        "def preprocess_func(image , label):\n",
        "  image = tf.image.resize(image , [224 , 224])\n",
        "  return tf.cast(image , tf.float32) , label"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX8qh4R6b2D0"
      },
      "source": [
        "# Map preprocess function to train and valid \n",
        "train_dataset_gen = train_dataset_gen.map(map_func=preprocess_func , num_parallel_calls=tf.data.AUTOTUNE)\n",
        "#train_dataset_gen = train_dataset_gen.shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "\n",
        "valid_dataset_gen = valid_dataset_gen.map(map_func=preprocess_func , num_parallel_calls=tf.data.AUTOTUNE)\n",
        "#valid_dataset_gen = valid_dataset_gen.batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvSWaMHpb9iI",
        "outputId": "4dd737c4-3561-4013-ea4f-320406b8c109"
      },
      "source": [
        "train_dataset_gen , valid_dataset_gen"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<ParallelMapDataset shapes: ((None, 224, 224, 3), (None, 2)), types: (tf.float32, tf.float32)>,\n",
              " <ParallelMapDataset shapes: ((None, 224, 224, 3), (None, 2)), types: (tf.float32, tf.float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MB1ce2zzgOlW"
      },
      "source": [
        "model.fit(train_dataset_gen , \n",
        "          epochs = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "bb7Y_XHJi_Tp",
        "outputId": "3549806c-a701-4a92-f4dc-2c9ffaebe240"
      },
      "source": [
        "train_dataset_gen.class_names"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-1b2230350457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'PrefetchDataset' object has no attribute 'class_names'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnrNbRXVga7O",
        "outputId": "196af612-c27f-4d18-d93b-4d9851694655"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# Create base model\n",
        "input_shape = (256, 256, 3)\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable = False # freeze base model layers\n",
        "\n",
        "# Create Functional model \n",
        "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "# Note: EfficientNetBX models have rescaling built-in but if your model didn't you could have a layer like below\n",
        "# x = preprocessing.Rescaling(1./255)(x)\n",
        "x = base_model(inputs, training=False) # set base_model to inference mode only\n",
        "x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
        "#x = layers.Dense(2)(x) # want one output neuron per class \n",
        "# Separate activation of output layer so we can output float32 activations\n",
        "outputs = layers.Dense(2, activation=\"softmax\")(x) \n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", # Use sparse_categorical_crossentropy when labels are *not* one-hot\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0Z5AYekjZkF",
        "outputId": "e7dde518-4e55-45cd-cfaa-7bbc9b65a44f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (InputLayer)     [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "efficientnetb0 (Functional)  (None, None, None, 1280)  4049571   \n",
            "_________________________________________________________________\n",
            "pooling_layer (GlobalAverage (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 2562      \n",
            "=================================================================\n",
            "Total params: 4,052,133\n",
            "Trainable params: 2,562\n",
            "Non-trainable params: 4,049,571\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-OS8baSjcqO"
      },
      "source": [
        "# Compile the model \n",
        "model.compile(loss = tf.keras.losses.CategoricalCrossentropy() , \n",
        "              optimizer = tf.keras.optimizers.Adam() , \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0ZREfJWij-J",
        "outputId": "3bf3a59d-e87e-4fa4-aeea-dcd5581cc2a3"
      },
      "source": [
        "2000 / 32"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1JKEGdljm7v",
        "outputId": "f9dc93c0-30ff-4700-f858-2e2f62237147"
      },
      "source": [
        "model.fit(train_dataset_gen  , epochs = 3, \n",
        "                    steps_per_epoch = 62.5 , \n",
        "                    validation_data = valid_dataset_gen , \n",
        "                    validation_steps = 10)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "Found 2000 images belonging to 2 classes.\n",
            "63/62 [==============================] - ETA: -1s - loss: 0.6973 - accuracy: 0.4990Found 1000 images belonging to 2 classes.\n",
            "62/62 [==============================] - 189s 3s/step - loss: 0.6973 - accuracy: 0.4990 - val_loss: 0.6936 - val_accuracy: 0.5063\n",
            "Epoch 2/3\n",
            "63/62 [==============================] - ETA: -1s - loss: 0.6958 - accuracy: 0.4830Found 1000 images belonging to 2 classes.\n",
            "62/62 [==============================] - 188s 3s/step - loss: 0.6958 - accuracy: 0.4830 - val_loss: 0.6921 - val_accuracy: 0.5250\n",
            "Epoch 3/3\n",
            "63/62 [==============================] - ETA: -1s - loss: 0.6950 - accuracy: 0.5025Found 1000 images belonging to 2 classes.\n",
            "62/62 [==============================] - 188s 3s/step - loss: 0.6950 - accuracy: 0.5025 - val_loss: 0.6921 - val_accuracy: 0.5188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f427aacfdd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kZLW06oj8p5"
      },
      "source": [
        "c"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}