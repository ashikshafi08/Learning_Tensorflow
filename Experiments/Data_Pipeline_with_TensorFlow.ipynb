{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Pipeline with TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPml/MZ4/O3jU84Ll4PwAA1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning_Tensorflow/blob/main/Experiments/Data_Pipeline_with_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2BE-ltcHDV-",
        "outputId": "0b25d9e6-d408-46fc-d4a2-45f3651c9f51"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed May 19 21:05:04 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjOdE6H9ocGJ"
      },
      "source": [
        "# Learning how to build data pipelines with `tf.data`\n",
        "\n",
        "The `tf.data` help us to build complex input pipelines from single, resuable pieces. \n",
        "\n",
        "For example the pipeline, \n",
        "- for an image model might aggregate data from files in a distributed file system and apply random perturbations to each image, and merge randomly selected images into a batch for training. \n",
        "- can be even used for text model might involve extracting symbolds from raw text data, converting them to embedding idenitifiers with a lookup table and batching together sequences of different lengths. \n",
        "\n",
        "The `tf.data` API makes it possible to handle large amounts of data, read from different data formats, and perform complex transformations.\n",
        "\n",
        "The `tf.data` API introduces a `tf.data.Dataset` abstraction that represents a sequence of elements, in which each element consists of one or more components. \n",
        "\n",
        "For example, in an image pipeline, an element might be a single training example, with a **pair of tensor components representing the image and it's label.**\n",
        "\n",
        "**The two distinct ways to create a dataset**: \n",
        "- A data **source** constructs a `Dataset` from data stored in memory or in one or more files. \n",
        "- A data **transformation** constructs a dataset from one or more `tf.data.Dataset`. \n",
        "\n",
        "\n",
        "## Basic Mechanics \n",
        "\n",
        "- To create an input pipeline, we must start with a data source. \n",
        "\n",
        "- (Other files) For example, to construct a `Dataset` from data in memory (folders etc..) we can use `tf.data.ataset.from_tensors()` or `tf.data.Dataset.from_tensor_slices()`. \n",
        "- (TFRecord file) If the input data is stored in a TFRecord format, we can then use `tf.data.TFRecordDataset()`\n",
        "\n",
        "> The `Dataset` object is a Python iterable (we can loop through). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtpkBQq1zXEZ"
      },
      "source": [
        "# Importing the things we need \n",
        "import tensorflow as tf\n",
        "import pathlib \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1QuZxr4HB82",
        "outputId": "1a49374d-f179-4537-bf22-7c3df41bb9dc"
      },
      "source": [
        "# Creating a dummy data and using tf.data.Dataset.from_tensor_slices()\n",
        "\n",
        "dum_list = [8 , 3, 0 , 8 , 2 , 1]\n",
        "dataset = tf.data.Dataset.from_tensor_slices(dum_list)\n",
        "dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpDDR26YHCnK",
        "outputId": "19dcbd48-9e3c-4374-a070-cc055860b369"
      },
      "source": [
        "# Iterating a looking what's inside the dataset we created \n",
        "for elem in dataset:\n",
        "  print(elem.numpy())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "3\n",
            "0\n",
            "8\n",
            "2\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXq5YqHe2nql",
        "outputId": "bf36df64-c49c-491f-b6b0-645d8355f97c"
      },
      "source": [
        "# Trying out a synthetic data \n",
        "\n",
        "(train_data , train_labels) , (test_data , test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Printing out the shapes of our mnist dataset \n",
        "train_data.shape , train_labels.shape , test_data.shape , test_labels.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv1TgdW4_Ekf"
      },
      "source": [
        "Loading our data usig `tf.data` and create a TensorSliceDataset object for our train data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSOnOXsC_a4v",
        "outputId": "eb2cefde-119a-485c-fa7f-632c7406f8db"
      },
      "source": [
        "# Turning our train data into TensorSliceDataset object \n",
        "train_dataset_slices = tf.data.Dataset.from_tensor_slices((train_data , train_labels))\n",
        "\n",
        "train_dataset_slices"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((28, 28), ()), types: (tf.uint8, tf.uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxclChAn_w5u"
      },
      "source": [
        "Cool! Now we have packed our train images and labels into a one whole Dataset. \n",
        "\n",
        "To view the labels https://stackoverflow.com/questions/64132847/how-to-iterate-over-tensorslicedataset-object-in-tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anuCMUdaAola",
        "outputId": "9556a00d-2f10-4c20-edc8-e87b0863cbdf"
      },
      "source": [
        "train_dataset_slices.element_spec"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(28, 28), dtype=tf.uint8, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.uint8, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqhsATzVA9PR"
      },
      "source": [
        "Let's try the same for but this time with `tf.data.Dataset.from_tensors()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duMYzJLIEKvH",
        "outputId": "d7e92b72-f180-4a54-85dd-497d180d9367"
      },
      "source": [
        "# Using tf.data.Dataset_from_tensors() \n",
        "\n",
        "train_data_tensors = tf.data.Dataset.from_tensors((train_data , train_labels))\n",
        "\n",
        "train_data_tensors"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorDataset shapes: ((60000, 28, 28), (60000,)), types: (tf.uint8, tf.uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvLGWlSjGABp",
        "outputId": "9795435b-d864-49ff-cc1d-0b7248461962"
      },
      "source": [
        "# Looking into our dataset \n",
        "train_data_tensors.element_spec"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(60000, 28, 28), dtype=tf.uint8, name=None),\n",
              " TensorSpec(shape=(60000,), dtype=tf.uint8, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CTweON4GFPQ",
        "outputId": "e6d0a5a5-5a27-43e4-b93d-f81021ae9f86"
      },
      "source": [
        "train_data_tensors.list_files"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function tensorflow.python.data.ops.dataset_ops.DatasetV2.list_files>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WhNKeSGGydv"
      },
      "source": [
        "Using the `tf.data.Dataset.from_generator()` now, this well help us to create a Dataset object from a datagenerator object. \n",
        "\n",
        "Useful links\n",
        "- [Converting ImageDatasetGenerator into dataset object](https://stackoverflow.com/questions/54606302/tf-data-dataset-from-tf-keras-preprocessing-image-imagedatagenerator-flow-from-d)\n",
        "- [How to use during fit function](\n",
        " https://stackoverflow.com/questions/52636127/how-to-use-keras-generator-with-tf-data-api)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-H_qIc6M2nU"
      },
      "source": [
        "# Loading in the cats and dogs dataset \n",
        "\n",
        "# data's url \n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "# Extracting from the path\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip' , origin = _URL , extract = True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip) , 'cats_and_dogs_filtered')\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2Zbt4GxOMUP",
        "outputId": "f08b8d80-d2aa-4b53-835a-88e486858d3f"
      },
      "source": [
        "# What's inside PATH? \n",
        "\n",
        "os.listdir(PATH)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'vectorize.py', 'validation']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfQWluEYORnV"
      },
      "source": [
        "# Now setting up our train and validation directory (for images)\n",
        "train_dir = os.path.join(PATH , 'train')\n",
        "valid_dir = os.path.join(PATH , 'validation')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrcmQvQtOpqx",
        "outputId": "bbdc2721-459a-4f19-daed-d50c48228ab4"
      },
      "source": [
        "# What's inside our train_dir \n",
        "os.listdir(train_dir)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cats', 'dogs']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63LuE3HlPbDJ",
        "outputId": "211f8944-75be-4e25-e975-22c37086b0e2"
      },
      "source": [
        "# Looking intos cats folder \n",
        "os.listdir(f'{train_dir}/cats')[:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cat.710.jpg',\n",
              " 'cat.204.jpg',\n",
              " 'cat.879.jpg',\n",
              " 'cat.100.jpg',\n",
              " 'cat.802.jpg',\n",
              " 'cat.218.jpg',\n",
              " 'cat.455.jpg',\n",
              " 'cat.442.jpg',\n",
              " 'cat.916.jpg',\n",
              " 'cat.91.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfh7QObGOtGU",
        "outputId": "b39e770b-3a0b-4f5e-ba17-3e621f6ef420"
      },
      "source": [
        "# Using ImageDataGenerator \n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.)\n",
        "\n",
        "# Getting the images from our directory and resizing them\n",
        "train_gen = train_datagen.flow_from_directory(train_dir)\n",
        "\n",
        "# For Validation \n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.)\n",
        "valid_gen  = valid_datagen.flow_from_directory(valid_dir)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8zt9J-0hFHo",
        "outputId": "b0c7112c-78a3-4dd8-a8a8-e5dc322460cd"
      },
      "source": [
        "train_gen.labels"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xcTFflXPkuT",
        "outputId": "e783f784-4469-4d0c-9977-434bc763cddd"
      },
      "source": [
        "# Gotta inspect our train_gen and collect some info that may help us in converting to Dataset object \n",
        "\n",
        "print(f'Target size of images: {train_gen.target_size}')\n",
        "print(f'Number of classes: {train_gen.num_classes}')\n",
        "print(f'Getting the class indices: {train_gen.class_indices}')"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target size of images: (256, 256)\n",
            "Number of classes: 2\n",
            "Getting the class indices: {'cats': 0, 'dogs': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJtHEnZVQB-u"
      },
      "source": [
        "Alright! Now is the big game of converting our generator to Dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG8kCl1fQIII",
        "outputId": "7cce649e-645f-482a-c9eb-4daf186fa2f8"
      },
      "source": [
        "train_dataset_gen = tf.data.Dataset.from_generator(\n",
        "    lambda: train_gen , \n",
        "    output_types = (tf.float32 , tf.int64), \n",
        "    output_shapes = ([None, 256, 256 ,3] , [None , 2])\n",
        ")\n",
        "\n",
        "valid_dataset_gen = tf.data.Dataset.from_generator(\n",
        "    lambda: valid_gen, \n",
        "    output_types = (tf.float32 , tf.int64), \n",
        "    output_shapes = ([None , 256 , 256 , 3] , [None , 2])\n",
        "\n",
        ")\n",
        "\n",
        "train_dataset_gen  , valid_dataset_gen"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<FlatMapDataset shapes: ((None, 256, 256, 3), (None, 2)), types: (tf.float32, tf.int64)>,\n",
              " <FlatMapDataset shapes: ((None, 256, 256, 3), (None, 2)), types: (tf.float32, tf.int64)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2k2I9mZQ95k",
        "outputId": "d7f5926e-12de-4491-f483-a091663afb7c"
      },
      "source": [
        "train_dataset_gen.take(1)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: ((None, 256, 256, 3), (None, 2)), types: (tf.float32, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT01sL9ZRAeQ"
      },
      "source": [
        "# Just creating a simple model \n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape = (160 , 160 , 3) , name = 'Input layer')\n",
        "\n",
        "x = layers.Conv2D(3 , 2 , padding = 'same' , activation ='relu')(inputs)\n",
        "x = layers.MaxPooling2D(3 , padding = 'same')(x)\n",
        "#x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv2D(3 , 2 , padding = 'same' , activation ='relu')(x)\n",
        "#x = layers.MaxPooling2D(3 , padding = 'same')(x)\n",
        "x = layers.Dense(128 , activation= 'relu')(x)\n",
        "x = layers.Conv2D(3 , 2 , padding = 'same' , activation ='relu')(x)\n",
        "#x = layers.MaxPooling2D(3 , padding = 'same')(x)\n",
        "x = layers.Dense(128 , activation= 'relu')(x)\n",
        "\n",
        "outputs = layers.Dense(2 , activation = 'softmax' , name = 'Output_layer')(x)\n",
        "\n",
        "# Packing into a model \n",
        "model = tf.keras.Model(inputs , outputs)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRP-ZCUlUX9O",
        "outputId": "aac6ca5d-53db-4980-9743-e189699fa285"
      },
      "source": [
        "# Model summary \n",
        "model.summary()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input layer (InputLayer)     [(None, 160, 160, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 160, 160, 3)       39        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 54, 54, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 54, 54, 3)         39        \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 54, 54, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 54, 54, 3)         1539      \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 54, 54, 128)       512       \n",
            "_________________________________________________________________\n",
            "Output_layer (Dense)         (None, 54, 54, 2)         258       \n",
            "=================================================================\n",
            "Total params: 2,899\n",
            "Trainable params: 2,899\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18s4lGLvWmMd"
      },
      "source": [
        "model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy() , \n",
        "              optimizer = tf.keras.optimizers.Adam(), \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "696lbjqCc0Gy"
      },
      "source": [
        "model.fit(train_dataset_gen , \n",
        "          epochs = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1NhFUj9XNJY",
        "outputId": "6f423dc8-15a0-4f34-abd8-ce84e5bfbc68"
      },
      "source": [
        "train_dataset_gen.element_spec"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(None, 2), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL_tZu3YXxZx"
      },
      "source": [
        "Extracting images and labels from our dataset object. \n",
        "\n",
        "Useful link: https://stackoverflow.com/questions/56226621/how-to-extract-data-labels-back-from-tensorflow-dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIUfaQU_Yz-t"
      },
      "source": [
        "# Extracting images and labels from our dataset object\n",
        "for images , labels in train_dataset_gen.take(1):\n",
        "   sample_images = images \n",
        "   sample_labels = labels\n",
        "\n",
        "\n"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Kkhp7FWZDL7",
        "outputId": "11505cf0-5744-4f32-d36d-e6adfe27bc3a"
      },
      "source": [
        "len(sample_images) , len(sample_labels)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eObiJiugaIBd",
        "outputId": "0b7f828f-2379-41df-e94a-38adb7675fed"
      },
      "source": [
        "# Checking the image \n",
        "sample_images[:1]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 256, 256, 3), dtype=float32, numpy=\n",
              "array([[[[0.12156864, 0.16862746, 0.21568629],\n",
              "         [0.12156864, 0.16862746, 0.21568629],\n",
              "         [0.12156864, 0.16862746, 0.21568629],\n",
              "         ...,\n",
              "         [0.5529412 , 0.5176471 , 0.45882356],\n",
              "         [0.5529412 , 0.5176471 , 0.45882356],\n",
              "         [0.5647059 , 0.5294118 , 0.47058827]],\n",
              "\n",
              "        [[0.1137255 , 0.16078432, 0.20784315],\n",
              "         [0.10980393, 0.15686275, 0.20392159],\n",
              "         [0.10980393, 0.15686275, 0.20392159],\n",
              "         ...,\n",
              "         [0.5529412 , 0.5176471 , 0.45882356],\n",
              "         [0.5529412 , 0.5176471 , 0.45882356],\n",
              "         [0.56078434, 0.5254902 , 0.4666667 ]],\n",
              "\n",
              "        [[0.1137255 , 0.16078432, 0.20784315],\n",
              "         [0.10980393, 0.15686275, 0.20392159],\n",
              "         [0.10980393, 0.15686275, 0.20392159],\n",
              "         ...,\n",
              "         [0.5529412 , 0.5176471 , 0.45882356],\n",
              "         [0.5529412 , 0.5176471 , 0.45882356],\n",
              "         [0.56078434, 0.5254902 , 0.4666667 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.8313726 , 0.7607844 , 0.74509805],\n",
              "         [0.8470589 , 0.77647066, 0.7607844 ],\n",
              "         [0.8470589 , 0.77647066, 0.7607844 ],\n",
              "         ...,\n",
              "         [0.6313726 , 0.5921569 , 0.5529412 ],\n",
              "         [0.6313726 , 0.5921569 , 0.5529412 ],\n",
              "         [0.61960787, 0.5803922 , 0.5411765 ]],\n",
              "\n",
              "        [[0.8313726 , 0.7607844 , 0.74509805],\n",
              "         [0.8470589 , 0.77647066, 0.7607844 ],\n",
              "         [0.8470589 , 0.77647066, 0.7607844 ],\n",
              "         ...,\n",
              "         [0.6313726 , 0.5921569 , 0.5529412 ],\n",
              "         [0.6313726 , 0.5921569 , 0.5529412 ],\n",
              "         [0.61960787, 0.5803922 , 0.5411765 ]],\n",
              "\n",
              "        [[0.8352942 , 0.7490196 , 0.7058824 ],\n",
              "         [0.8470589 , 0.7686275 , 0.7254902 ],\n",
              "         [0.8470589 , 0.7686275 , 0.7254902 ],\n",
              "         ...,\n",
              "         [0.5803922 , 0.5411765 , 0.5019608 ],\n",
              "         [0.5803922 , 0.5411765 , 0.5019608 ],\n",
              "         [0.57254905, 0.53333336, 0.49411768]]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vrc-HpYNaJx0",
        "outputId": "3b0697b5-59ed-4c22-ce66-81db96d0c4d1"
      },
      "source": [
        "# Checking our labels \n",
        "sample_labels[:10]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 2), dtype=int32, numpy=\n",
              "array([[0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIe3gm-Aaa3J"
      },
      "source": [
        "# Applying the same on the whole dataset \n",
        "#for images , labels in train_dataset_gen.take(-1):\n",
        "#  train_images = images\n",
        "#  train_labels = labels\n",
        "\n",
        "# train_images , train_labels = tuple(zip(*train_dataset_gen))\n",
        "\n",
        "# The for loop is taking *infinitely* long time "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhI_1XNga4DH"
      },
      "source": [
        "def preprocess_func(image , label):\n",
        "  image = tf.image.resize(image , [224 , 224])\n",
        "  return tf.cast(image , tf.float32) , label"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX8qh4R6b2D0"
      },
      "source": [
        "# Map preprocess function to train and valid \n",
        "train_dataset_gen = train_dataset_gen.map(map_func=preprocess_func , num_parallel_calls=tf.data.AUTOTUNE)\n",
        "#train_dataset_gen = train_dataset_gen.shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "\n",
        "valid_dataset_gen = valid_dataset_gen.map(map_func=preprocess_func , num_parallel_calls=tf.data.AUTOTUNE)\n",
        "#valid_dataset_gen = valid_dataset_gen.batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "\n"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvSWaMHpb9iI",
        "outputId": "2697f0c9-3d8f-4026-dfe3-135b721b3100"
      },
      "source": [
        "train_dataset_gen , valid_dataset_gen"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<ParallelMapDataset shapes: ((None, 224, 224, 3), (None, 2)), types: (tf.float32, tf.int64)>,\n",
              " <ParallelMapDataset shapes: ((None, 224, 224, 3), (None, 2)), types: (tf.float32, tf.int64)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MB1ce2zzgOlW"
      },
      "source": [
        "model.fit(train_dataset_gen , \n",
        "          epochs = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "bb7Y_XHJi_Tp",
        "outputId": "3549806c-a701-4a92-f4dc-2c9ffaebe240"
      },
      "source": [
        "train_dataset_gen.class_names"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-1b2230350457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'PrefetchDataset' object has no attribute 'class_names'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnrNbRXVga7O"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# Create base model\n",
        "input_shape = (256, 256, 3)\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable = False # freeze base model layers\n",
        "\n",
        "# Create Functional model \n",
        "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "# Note: EfficientNetBX models have rescaling built-in but if your model didn't you could have a layer like below\n",
        "# x = preprocessing.Rescaling(1./255)(x)\n",
        "x = base_model(inputs, training=False) # set base_model to inference mode only\n",
        "x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
        "#x = layers.Dense(2)(x) # want one output neuron per class \n",
        "# Separate activation of output layer so we can output float32 activations\n",
        "outputs = layers.Dense(2, activation=\"softmax\")(x) \n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", # Use sparse_categorical_crossentropy when labels are *not* one-hot\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0Z5AYekjZkF",
        "outputId": "cd518206-58e4-4845-993f-d8a294850eaa"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (InputLayer)     [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "efficientnetb0 (Functional)  (None, None, None, 1280)  4049571   \n",
            "_________________________________________________________________\n",
            "pooling_layer (GlobalAverage (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 2)                 2562      \n",
            "=================================================================\n",
            "Total params: 4,052,133\n",
            "Trainable params: 2,562\n",
            "Non-trainable params: 4,049,571\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-OS8baSjcqO"
      },
      "source": [
        "# Compile the model \n",
        "model.compile(loss = tf.keras.losses.CategoricalCrossentropy() , \n",
        "              optimizer = tf.keras.optimizers.Adam() , \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "K1JKEGdljm7v",
        "outputId": "5228e32c-dde1-4cb6-ecd1-dcff122f8335"
      },
      "source": [
        "# Fit the model \n",
        "history = model.fit(train_dataset_gen , \n",
        "                    epochs = 3 , \n",
        "                    steps_per_epoch = len(train_dataset_gen) , \n",
        "                    validation_data = valid_dataset_gen , \n",
        "                    validation_steps = int(0.15 * len(valid_dataset_gen)) \n",
        "                    )"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-143-76d57164cbe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m history = model.fit(train_dataset_gen , \n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_gen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_dataset_gen\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.15\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataset_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset length is infinite.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mUNKNOWN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset length is unknown.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: dataset length is unknown."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kZLW06oj8p5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}