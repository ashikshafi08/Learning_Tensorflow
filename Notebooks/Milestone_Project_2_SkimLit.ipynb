{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Milestone Project 2: SkimLit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning_Tensorflow/blob/main/Notebooks/Milestone_Project_2_SkimLit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NwEKeznKJUb"
      },
      "source": [
        "# Milestone Project 2: SkimLit\n",
        "The purpose of this notebook is to build an NLP model to make reading medical abstracts easier. \n",
        "\n",
        "In this project, we're going to be putting what we've learned into practice.\n",
        "\n",
        "More specificially, we're going to be replicating the deep learning model behind the 2017 paper [PubMed 200k RCT: a Dataset for Sequenctial Sentence Classification in Medical Abstracts](https://arxiv.org/abs/1710.06071).\n",
        "\n",
        "When it was released, the paper presented a new dataset called PubMed 200k RCT which consists of ~200,000 labelled Randomized Controlled Trial (RCT) abstracts.\n",
        "\n",
        "The goal of the dataset was to explore the ability for NLP models to classify sentences which appear in sequential order. In other words, given the abstract of a RCT, what role does each sentence serve in the abstract?\n",
        "\n",
        "### What we're going to cover\n",
        "Time to take what we've learned in the NLP fundmentals notebook and build our biggest NLP model yet:\n",
        "- Downloading a text dataset (PubMed RCT200k from GitHub)\n",
        "- Writing a preprocessing function to prepare our data for modelling\n",
        "- Setting up a series of modelling experiments\n",
        "  - Making a baseline (TF-IDF classifier)\n",
        "  - Deep models with different combinations of: token  embeddings, character embeddings, pretrained embeddings, positional embeddings\n",
        "- Building our first multimodal model (taking multiple types of data inputs).\n",
        "  - Replicating the model architecture from [paper](https://arxiv.org/pdf/1612.05251.pdf)\n",
        "- Find the most wrong predictions\n",
        "- Making predictions on PubMed abstracts from the wild"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2aTpsv5MIJW"
      },
      "source": [
        "### Get Data \n",
        "Let's download the PubMed 200k PCT data. \n",
        "https://github.com/Franck-Dernoncourt/pubmed-rct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOB0c4aOhZ4W",
        "outputId": "66639605-5710-4c37-9a6a-61316119708a"
      },
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'pubmed-rct' already exists and is not an empty directory.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X11jn_SZhcI5"
      },
      "source": [
        "\n",
        "Checking the contents of the downloaded repository, you can see there are four folders.\n",
        "\n",
        "Each contains a different version of the PubMed 200k RCT dataset.\n",
        "\n",
        "Looking at the README file from the GitHub page, we get the following information:\n",
        "\n",
        "\n",
        "- PubMed 20k is a subset of PubMed 200k. I.e., any abstract present in PubMed 20k is also present in PubMed 200k.\n",
        "- PubMed_200k_RCT is the same as PubMed_200k_RCT_numbers_replaced_with_at_sign, except that in the latter all numbers had been replaced by @. (same for PubMed_20k_RCT vs. - PubMed_20k_RCT_numbers_replaced_with_at_sign).\n",
        "- Since Github file size limit is 100 MiB, we had to compress PubMed_200k_RCT\\train.7z and PubMed_200k_RCT_numbers_replaced_with_at_sign\\train.zip. To uncompress train.7z, you may use 7-Zip on Windows, Keka on Mac OS X, or p7zip on Linux.\n",
        "\n",
        "To begin with, the dataset we're going to be focused on is PubMed_20k_RCT_numbers_replaced_with_at_sign.\n",
        "\n",
        "Why this one?\n",
        "\n",
        "Rather than working with the whole 200k dataset, we'll keep our experiments quick by starting with a smaller subset. We could've chosen the dataset with numbers instead of having them replaced with @ but we didn't.\n",
        "Let's check the file contents.\n",
        "\n",
        "- Paper for Modelling : https://arxiv.org/abs/1612.05251\n",
        "- Application paper: https://arxiv.org/abs/1710.06071\n",
        "\n",
        "**Problem in a sentence**\n",
        "\n",
        "The number of RCT papers released is continuing to increase, those without structured abstracts can be hard to read and in turn slow down researchers moving through the literature.\n",
        "\n",
        "**Solution in a sentence**\n",
        "\n",
        "Create an NLP model to classify abstract sentences into the role they play (e.g. objective, methods, results, etc) to enable researchers to skim through the literature (hence SkimLit ðŸ¤“ðŸ”¥) and dive deeper when necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYd49SCfmcEu",
        "outputId": "c7eafd2e-228f-4a26-e0af-a7551fbcd6e6"
      },
      "source": [
        "# Check what files are in the PubMed_20k dataset \n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKfCPURez8hs",
        "outputId": "426a80bc-c31e-4249-a92f-ec652ab0d041"
      },
      "source": [
        "# # Start our experiments using thhe 20K dataset with numbers replaced by '@' sign\n",
        "data_dir = 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/'\n",
        "\n",
        "# Check all of the filenames in the target direcotry \n",
        "import os \n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cULq2iAkz8wd"
      },
      "source": [
        "## Preprocess data \n",
        "\n",
        "Now we've got some text data, it's time to become one with it. \n",
        "And one of the best ways to become one with the data is to... \n",
        "\n",
        "> Visualize , Visualize , visualize....\n",
        "\n",
        "So with that in mind, lets write a function to read in all of the lines of a target text file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sH3TbbP69Ow"
      },
      "source": [
        "# Create function to read the lines of a document \n",
        "def get_lines(filename):\n",
        "  '''\n",
        "  Reads filename (a text filename) adn returns the line of text as a list. \n",
        "\n",
        "  Args: \n",
        "    filename: a string containing the target filepth \n",
        "\n",
        " Returns: \n",
        "  A list of stings with one string per line from the target filename\n",
        "  '''\n",
        "  with open(filename , 'r') as f: \n",
        "    return f.readlines()"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV3wVQU17ikr",
        "outputId": "6e9582cf-608e-4ba2-a5b1-f96c035c1ff0"
      },
      "source": [
        "# Using our function , lets read in training lines \n",
        "train_lines = get_lines(data_dir + 'train.txt') # read the lines within the training file \n",
        "train_lines[:20]"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RGOZ-MY7v2_"
      },
      "source": [
        "We can't pass this train lines straight into our model because they are quite messy and our model will start to learning something irrelavant. \n",
        "\n",
        "But we can turn this lines into our desired way from which our model can learn. \n",
        "- Every new abstract starts with a **###somenumbers** so we can differentiate between different abstracts through this.\n",
        "- And every label is at the starting line of the sentence, for instance **OBJECTIVE , METHODS** these are present at the very starting line of a sentence.\n",
        "- Each abstract ends with an **\\n** new line command.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK1ADq5h9Dyh"
      },
      "source": [
        "Lets think about how we want our data to look...\n",
        "\n",
        "How the data would be best represented? \n",
        "\n",
        "```\n",
        "[{'line_number': 0,\n",
        "  'target': 'OBJECTIVE',\n",
        "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
        "  'total_lines': 11},\n",
        "  ...]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJl6Gy0Y-KYF",
        "outputId": "6d5742ce-7c5b-432c-a0ce-13baf556aff0"
      },
      "source": [
        "# Number of lines \n",
        "len(train_lines)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210040"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM2TL1Va0yCM"
      },
      "source": [
        "Let's write a function to perform the following steps:\n",
        "\n",
        "- Take a target file of abstract samples.\n",
        "- Read the lines in the target file.\n",
        "- For each line in the target file:\n",
        "  - If the line begins with ### mark it as an abstract ID and the beginning of a new abstract.\n",
        "    - Keep count of the number of lines in a sample.\n",
        "  - If the line begins with \\n mark it as the end of an abstract sample.\n",
        "    - Keep count of the total lines in a sample.\n",
        "  - Record the text before the \\t as the label of the line.\n",
        "  - Record the text after the \\t as the text of the line.\n",
        "- Return all of the lines in the target text file as a list of dictionaries containing the key/value pairs:\n",
        "- \"line_number\" - the position of the line in the abstract (e.g. 3).\n",
        "- \"target\" - the role of the line in the abstract (e.g. OBJECTIVE).\n",
        "- \"text\" - the text of the line in the abstract.\n",
        "- \"total_lines\" - the total lines in an abstract sample (e.g. 14).\n",
        "- Abstract ID's and newlines should be omitted from the returned preprocessed data.\n",
        "\n",
        "\n",
        "Example returned preprocessed sample (a single line from an abstract):\n",
        "\n",
        "```\n",
        "[{'line_number': 0,\n",
        "  'target': 'OBJECTIVE',\n",
        "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
        "  'total_lines': 11},\n",
        "  ...]\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW6Y8KZ9-y30"
      },
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"Returns a list of dictionaries of abstract line data.\n",
        "\n",
        "  Takes in filename, reads its contents and sorts through each line,\n",
        "  extracting things like the target label, the text of the sentence,\n",
        "  how many sentences are in the current abstract and what sentence number\n",
        "  the target line is.\n",
        "\n",
        "  Args:\n",
        "      filename: a string of the target text file to read and extract line data\n",
        "      from.\n",
        "\n",
        "  Returns:\n",
        "      A list of dictionaries each containing a line from an abstract,\n",
        "      the lines label, the lines position in the abstract and the total number\n",
        "      of lines in the abstract where the line is from. For example:\n",
        "\n",
        "      [{\"target\": 'CONCLUSION',\n",
        "        \"text\": The study couldn't have gone better, turns out people are kinder than you think\",\n",
        "        \"line_number\": 8,\n",
        "        \"total_lines\": 8}]\n",
        "  \"\"\"\n",
        "  input_lines = get_lines(filename) # get all lines from filename\n",
        "  abstract_lines = \"\" # create an empty abstract\n",
        "  abstract_samples = [] # create an empty list of abstracts\n",
        "  \n",
        "  # Loop through each line in target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"): # check to see if line is an ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" # reset abstract string\n",
        "    elif line.isspace(): # check to see if line is a new line\n",
        "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
        "\n",
        "      # Iterate through each line in abstract and count them at the same time\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # create empty dict to store data from line\n",
        "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
        "        line_data[\"target\"] = target_text_split[0] # get target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
        "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
        "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
        "    \n",
        "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
        "      abstract_lines += line\n",
        "  return abstract_samples"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2bzWXOd0wBB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "476ac23d-e4b8-49a0-8fd3-5a29ad16c141"
      },
      "source": [
        "# Using the above function on our data samples\n",
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") \n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "\n",
        "print(len(train_samples), len(val_samples), len(test_samples))"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "180040 30212 30135\n",
            "CPU times: user 989 ms, sys: 171 ms, total: 1.16 s\n",
            "Wall time: 1.16 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j3_OS7z1Qnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b528565-b892-4e5f-a8b3-100a36c0b97d"
      },
      "source": [
        "# Check the first abstract of our training data\n",
        "train_samples[:14]\n"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'line_number': 0,\n",
              "  'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 1,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 2,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 3,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 4,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 5,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 6,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 7,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 8,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 9,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 10,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 11,\n",
              "  'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 0,\n",
              "  'target': 'BACKGROUND',\n",
              "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
              "  'total_lines': 10},\n",
              " {'line_number': 1,\n",
              "  'target': 'BACKGROUND',\n",
              "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
              "  'total_lines': 10}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7G0FI5Z1TsG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "6ee20c42-b80c-425f-ed11-0843a0e3137a"
      },
      "source": [
        "# Turning our dictionary into a DataFrame for better visualization\n",
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head(14)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         target  ... total_lines\n",
              "0     OBJECTIVE  ...          11\n",
              "1       METHODS  ...          11\n",
              "2       METHODS  ...          11\n",
              "3       METHODS  ...          11\n",
              "4       METHODS  ...          11\n",
              "5       METHODS  ...          11\n",
              "6       RESULTS  ...          11\n",
              "7       RESULTS  ...          11\n",
              "8       RESULTS  ...          11\n",
              "9       RESULTS  ...          11\n",
              "10      RESULTS  ...          11\n",
              "11  CONCLUSIONS  ...          11\n",
              "12   BACKGROUND  ...          10\n",
              "13   BACKGROUND  ...          10\n",
              "\n",
              "[14 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fPx0p201ZyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b117c50-ec1b-4439-e60a-ee24dceb2032"
      },
      "source": [
        "# Distributions of labels (checking the balance spread of our labels)\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "uIWxXBtd16Jf",
        "outputId": "ed0bff41-dc91-42a2-e4c7-735eb3c6092b"
      },
      "source": [
        "# Distribution of our abstract length (spread of the abstract lines)\n",
        "train_df.total_lines.plot.hist()"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f601e6ea990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD6CAYAAABgZXp6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXpUlEQVR4nO3df7BfdX3n8efLRCpSkVDSLJNgg21Gl7r+gCvg1HatjCHg1tBdl4WtS5ZhiDNgV8f9QXQ6i8Uyk+5spdJatqlkTVwV8SfZEppGxHb7Bz+CIAjo5IqwJAJJDRDRFhZ97x/fz5Wv4ebyzbn53i/35vmY+c49530+55zPZ74TXpxzPt/vN1WFJEldvGjUHZAkzV6GiCSpM0NEktSZISJJ6swQkSR1ZohIkjobWogkeVWSO/tee5O8L8nRSbYm2d7+Lmjtk+TKJONJ7kpyYt+xVrX225Os6quflOTuts+VSTKs8UiSnisz8TmRJPOAncApwMXAnqpam2QNsKCqLklyJvC7wJmt3Uer6pQkRwPbgDGggNuBk6rqsSS3Av8BuAXYDFxZVTdM1Zdjjjmmli5dOpRxStJcdPvtt/99VS2cbNv8GerDacB3qurBJCuBt7T6BuBrwCXASmBj9VLt5iRHJTm2td1aVXsAkmwFViT5GnBkVd3c6huBs4ApQ2Tp0qVs27bt4I5OkuawJA/ub9tMPRM5B/hMW15UVQ+35UeARW15MfBQ3z47Wm2q+o5J6pKkGTL0EElyGPAO4HP7bmtXHUO/n5ZkdZJtSbbt3r172KeTpEPGTFyJnAF8vaoebeuPtttUtL+7Wn0ncFzffktabar6kknqz1FV66pqrKrGFi6c9LaeJKmDmQiRc3n2VhbAJmBihtUq4Lq++nltltapwBPtttcWYHmSBW0m13JgS9u2N8mpbVbWeX3HkiTNgKE+WE9yBPA24N195bXAtUkuAB4Ezm71zfRmZo0DPwLOB6iqPUk+DNzW2l028ZAduAj4BHA4vQfqUz5UlyQdXDMyxfeFZGxsrJydJUmDS3J7VY1Nts1PrEuSOjNEJEmdGSKSpM5m6hPrmqWWrrl+JOd9YO3bR3JeSQfGKxFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSps6GGSJKjknw+ybeS3JfkTUmOTrI1yfb2d0FrmyRXJhlPcleSE/uOs6q1355kVV/9pCR3t32uTJJhjkeS9LOGfSXyUeCvqurVwOuA+4A1wI1VtQy4sa0DnAEsa6/VwFUASY4GLgVOAU4GLp0Intbmwr79Vgx5PJKkPkMLkSQvB34DuBqgqp6uqseBlcCG1mwDcFZbXglsrJ6bgaOSHAucDmytqj1V9RiwFVjRth1ZVTdXVQEb+44lSZoBw7wSOR7YDfzPJHck+XiSI4BFVfVwa/MIsKgtLwYe6tt/R6tNVd8xSV2SNEOGGSLzgROBq6rqDcAPefbWFQDtCqKG2AcAkqxOsi3Jtt27dw/7dJJ0yBhmiOwAdlTVLW398/RC5dF2K4r2d1fbvhM4rm//Ja02VX3JJPXnqKp1VTVWVWMLFy6c1qAkSc8aWohU1SPAQ0le1UqnAfcCm4CJGVargOva8ibgvDZL61TgiXbbawuwPMmC9kB9ObClbdub5NQ2K+u8vmNJkmbA/CEf/3eBTyU5DLgfOJ9ecF2b5ALgQeDs1nYzcCYwDvyotaWq9iT5MHBba3dZVe1pyxcBnwAOB25oL0nSDBlqiFTVncDYJJtOm6RtARfv5zjrgfWT1LcBr5lmNyVJHfmJdUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOhtqiCR5IMndSe5Msq3Vjk6yNcn29ndBqyfJlUnGk9yV5MS+46xq7bcnWdVXP6kdf7ztm2GOR5L0s2biSuQ3q+r1VTXW1tcAN1bVMuDGtg5wBrCsvVYDV0EvdIBLgVOAk4FLJ4Kntbmwb78Vwx+OJGnCKG5nrQQ2tOUNwFl99Y3VczNwVJJjgdOBrVW1p6oeA7YCK9q2I6vq5qoqYGPfsSRJM2DYIVLAXye5PcnqVltUVQ+35UeARW15MfBQ3747Wm2q+o5J6s+RZHWSbUm27d69ezrjkST1mT/k47+5qnYm+UVga5Jv9W+sqkpSQ+4DVbUOWAcwNjY29PNJ0qFiqFciVbWz/d0FfIneM41H260o2t9drflO4Li+3Ze02lT1JZPUJUkzZGghkuSIJC+bWAaWA98ENgETM6xWAde15U3AeW2W1qnAE+221xZgeZIF7YH6cmBL27Y3yaltVtZ5fceSJM2AYd7OWgR8qc26nQ98uqr+KsltwLVJLgAeBM5u7TcDZwLjwI+A8wGqak+SDwO3tXaXVdWetnwR8AngcOCG9pIkzZChhUhV3Q+8bpL694HTJqkXcPF+jrUeWD9JfRvwmml3VpLUiZ9YlyR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktTZQCGS5J8NuyOSpNln0CuRP0tya5KLkrx8qD2SJM0aA4VIVf068DvAccDtST6d5G1D7Zkk6QVv4GciVbUd+D3gEuCfA1cm+VaSfzmszkmSXtgGfSby2iRXAPcBbwV+q6r+aVu+Yoj9kyS9gM0fsN2fAB8HPlhV/zBRrKrvJfm9ofRMkvSCN+jtrLcDn54IkCQvSvJSgKr65FQ7JpmX5I4kf9nWj09yS5LxJJ9Nclir/1xbH2/bl/Yd4wOt/u0kp/fVV7TaeJI1BzJwSdL0DRoiXwEO71t/aasN4r30boNN+EPgiqr6FeAx4IJWvwB4rNWvaO1IcgJwDvCrwAp6M8XmJZkHfAw4AzgBOLe1lSTNkEFvZ72kqp6cWKmqJyeuRKaSZAm9q5jLgfcnCb3nKP+2NdkAfAi4CljZlgE+D/xpa78SuKaqngK+m2QcOLm1G6+q+9u5rmlt7x1wTHoBW7rm+pGd+4G1bx/ZuaXZZtArkR8mOXFiJclJwD9M0X7CHwP/BfhJW/8F4PGqeqat7wAWt+XFwEMAbfsTrf1P6/vss7+6JGmGDHol8j7gc0m+BwT4J8C/mWqHJP8C2FVVtyd5y7R6OU1JVgOrAV7xileMsiuSNKcMFCJVdVuSVwOvaqVvV9X/e57dfg14R5IzgZcARwIfBY5KMr9dbSwBdrb2O+l9mHFHkvnAy4Hv99Un9O+zv/q+/V8HrAMYGxur5+m3JGlAB/IFjG8EXgucSO8h9nlTNa6qD1TVkqpaSu/B+Fer6neAm4B3tmargOva8qa2Ttv+1aqqVj+nzd46HlgG3ArcBixrs70Oa+fYdADjkSRN00BXIkk+CfwycCfw41YuYGOHc14CXJPkD4A7gKtb/Wrgk+3B+R56oUBV3ZPkWnoPzJ8BLq6qH7d+vQfYAswD1lfVPR36I0nqaNBnImPACe3K4IBV1deAr7Xl+3l2dlV/m38E/vV+9r+c3gyvfeubgc1d+iRJmr5Bb2d9k97DdEmSfmrQK5FjgHuT3Ao8NVGsqncMpVeSpFlh0BD50DA7IUmanQad4vs3SX4JWFZVX2mfVp833K5Jkl7oBv0q+AvpfRXJn7fSYuDLw+qUJGl2GPTB+sX0Pjy4F376A1W/OKxOSZJmh0FD5KmqenpipX2i3E9+S9IhbtAQ+ZskHwQOb7+t/jngfw+vW5Kk2WDQEFkD7AbuBt5N7wN+/qKhJB3iBp2d9RPgL9pLkiRg8O/O+i6TPAOpqlce9B5JkmaNA/nurAkvofcdV0cf/O5IkmaTgZ6JVNX3+147q+qP6f3srSTpEDbo7awT+1ZfRO/KZNCrGEnSHDVoEPxR3/IzwAPA2Qe9N5KkWWXQ2Vm/OeyOSJJmn0FvZ71/qu1V9ZGD0x1J0mxyILOz3sizv2H+W/R+53z7MDoljdLSNdeP5LwPrHWuimafQUNkCXBiVf0AIMmHgOur6l3D6pgk6YVv0K89WQQ83bf+dKtJkg5hg16JbARuTfKltn4WsGE4XZIkzRaDzs66PMkNwK+30vlVdcfwuiVJmg0GvZ0F8FJgb1V9FNiR5PipGid5SZJbk3wjyT1Jfr/Vj09yS5LxJJ9Nclir/1xbH2/bl/Yd6wOt/u0kp/fVV7TaeJI1BzAWSdJBMOjP414KXAJ8oJVeDPyv59ntKeCtVfU64PXAiiSnAn8IXFFVvwI8BlzQ2l8APNbqV7R2JDkBOAf4VWAF8GdJ5iWZB3wMOAM4ATi3tZUkzZBBr0R+G3gH8EOAqvoe8LKpdqieJ9vqi9urgLfS+7126D1XOastr+TZ5yyfB05Lkla/pqqeqqrvAuPAye01XlX3t19dvKa1lSTNkEFD5OmqKtrXwSc5YpCd2hXDncAuYCvwHeDxqnqmNdkBLG7Li4GHANr2J4Bf6K/vs8/+6pKkGTJoiFyb5M+Bo5JcCHyFAX6gqqp+XFWvp/c5k5OBV3fu6TQkWZ1kW5Jtu3fvHkUXJGlOet7ZWe2W0mfpBcBe4FXAf62qrYOepKoeT3IT8CZ6QTS/XW0sAXa2ZjuB4+g9tJ8PvBz4fl99Qv8++6vve/51wDqAsbGx5/y4liSpm+e9Emm3sTZX1daq+s9V9Z8GCZAkC5Mc1ZYPB94G3AfcBLyzNVsFXNeWN7V12vavtnNvAs5ps7eOB5bR+8qV24BlbbbXYfQevk98LYskaQYM+mHDryd5Y1XddgDHPhbY0GZRvQi4tqr+Msm9wDVJ/gC4A7i6tb8a+GSScWAPvVCgqu5Jci1wL72vob+4qn4MkOQ9wBZgHrC+qu45gP5JkqZp0BA5BXhXkgfozdAKvYuU1+5vh6q6C3jDJPX76T0f2bf+j/R+dneyY10OXD5JfTOwebAhSJIOtilDJMkrqur/AqdP1U6SdGh6viuRL9P79t4Hk3yhqv7VTHRKkjQ7PN+D9fQtv3KYHZEkzT7PFyK1n2VJkp73dtbrkuyld0VyeFuGZx+sHznU3kmSXtCmDJGqmjdTHZEkzT4H8lXwkiT9DENEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktTZoD9KpRFauub6UXdBkibllYgkqTNDRJLUmSEiSerMEJEkdWaISJI6G1qIJDkuyU1J7k1yT5L3tvrRSbYm2d7+Lmj1JLkyyXiSu5Kc2HesVa399iSr+uonJbm77XNlkjy3J5KkYRnmlcgzwH+sqhOAU4GLk5wArAFurKplwI1tHeAMYFl7rQaugl7oAJcCpwAnA5dOBE9rc2HffiuGOB5J0j6GFiJV9XBVfb0t/wC4D1gMrAQ2tGYbgLPa8kpgY/XcDByV5FjgdGBrVe2pqseArcCKtu3Iqrq5qgrY2HcsSdIMmJFnIkmWAm8AbgEWVdXDbdMjwKK2vBh4qG+3Ha02VX3HJPXJzr86ybYk23bv3j2tsUiSnjX0EEny88AXgPdV1d7+be0Koobdh6paV1VjVTW2cOHCYZ9Okg4ZQw2RJC+mFyCfqqovtvKj7VYU7e+uVt8JHNe3+5JWm6q+ZJK6JGmGDHN2VoCrgfuq6iN9mzYBEzOsVgHX9dXPa7O0TgWeaLe9tgDLkyxoD9SXA1vatr1JTm3nOq/vWJKkGTDML2D8NeDfAXcnubPVPgisBa5NcgHwIHB227YZOBMYB34EnA9QVXuSfBi4rbW7rKr2tOWLgE8AhwM3tJckaYYMLUSq6u+A/X1u47RJ2hdw8X6OtR5YP0l9G/CaaXRTkjQNfmJdktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnQ0tRJKsT7IryTf7akcn2Zpke/u7oNWT5Mok40nuSnJi3z6rWvvtSVb11U9Kcnfb58okGdZYJEmTmz/EY38C+FNgY19tDXBjVa1NsqatXwKcASxrr1OAq4BTkhwNXAqMAQXcnmRTVT3W2lwI3AJsBlYANwxxPNJQLV1z/UjO+8Dat4/kvJobhnYlUlV/C+zZp7wS2NCWNwBn9dU3Vs/NwFFJjgVOB7ZW1Z4WHFuBFW3bkVV1c1UVvaA6C0nSjJrpZyKLqurhtvwIsKgtLwYe6mu3o9Wmqu+YpC5JmkEje7DeriBqJs6VZHWSbUm27d69eyZOKUmHhJkOkUfbrSja312tvhM4rq/dklabqr5kkvqkqmpdVY1V1djChQunPQhJUs9Mh8gmYGKG1Srgur76eW2W1qnAE+221xZgeZIFbSbXcmBL27Y3yaltVtZ5fceSJM2Qoc3OSvIZ4C3AMUl20JtltRa4NskFwIPA2a35ZuBMYBz4EXA+QFXtSfJh4LbW7rKqmnhYfxG9GWCH05uV5cwsSZphQwuRqjp3P5tOm6RtARfv5zjrgfWT1LcBr5lOHyVJ0+Mn1iVJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSps/mj7oCk0Vq65vqRnfuBtW8f2bl1cHglIknqbNZfiSRZAXwUmAd8vKrWDutco/w/NmkuGtW/Ka+ADp5ZfSWSZB7wMeAM4ATg3CQnjLZXknTomNUhApwMjFfV/VX1NHANsHLEfZKkQ8Zsv521GHiob30HcMqI+iJplnAywcEz20NkIElWA6vb6pNJvj3K/kziGODvR92JIZvrY3R8s9+MjDF/OOwz7Nd0xvdL+9sw20NkJ3Bc3/qSVvsZVbUOWDdTnTpQSbZV1dio+zFMc32Mjm/2m+tjHNb4ZvszkduAZUmOT3IYcA6wacR9kqRDxqy+EqmqZ5K8B9hCb4rv+qq6Z8TdkqRDxqwOEYCq2gxsHnU/pukFe6vtIJrrY3R8s99cH+NQxpeqGsZxJUmHgNn+TESSNEKGyIgleSDJ3UnuTLJt1P05GJKsT7IryTf7akcn2Zpke/u7YJR9nI79jO9DSXa29/HOJGeOso/TkeS4JDcluTfJPUne2+pz4j2cYnxz6T18SZJbk3yjjfH3W/34JLckGU/y2TYhaXrn8nbWaCV5ABirqjkzBz/JbwBPAhur6jWt9t+APVW1NskaYEFVXTLKfna1n/F9CHiyqv77KPt2MCQ5Fji2qr6e5GXA7cBZwL9nDryHU4zvbObOexjgiKp6MsmLgb8D3gu8H/hiVV2T5H8A36iqq6ZzLq9EdNBV1d8Ce/YprwQ2tOUN9P7Rzkr7Gd+cUVUPV9XX2/IPgPvofTvEnHgPpxjfnFE9T7bVF7dXAW8FPt/qB+U9NERGr4C/TnJ7+2T9XLWoqh5uy48Ai0bZmSF5T5K72u2uWXmrZ19JlgJvAG5hDr6H+4wP5tB7mGRekjuBXcBW4DvA41X1TGuyg4MQnobI6L25qk6k903EF7dbJXNa9e6hzrX7qFcBvwy8HngY+KPRdmf6kvw88AXgfVW1t3/bXHgPJxnfnHoPq+rHVfV6et/kcTLw6mGcxxAZsara2f7uAr5E782eix5t96In7knvGnF/DqqqerT9o/0J8BfM8vex3Uf/AvCpqvpiK8+Z93Cy8c2193BCVT0O3AS8CTgqycTnAyf9mqgDZYiMUJIj2oM9khwBLAe+OfVes9YmYFVbXgVcN8K+HHQT/3FtfptZ/D62h7JXA/dV1Uf6Ns2J93B/45tj7+HCJEe15cOBt9F79nMT8M7W7KC8h87OGqEkr6R39QG9bw/4dFVdPsIuHRRJPgO8hd63hj4KXAp8GbgWeAXwIHB2Vc3Kh9P7Gd9b6N0GKeAB4N19zw9mlSRvBv4PcDfwk1b+IL3nBrP+PZxifOcyd97D19J7cD6P3sXCtVV1WftvzjXA0cAdwLuq6qlpncsQkSR15e0sSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkzv4/2LyLCkd/AwYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l-DFRdF2FRc"
      },
      "source": [
        "It looks like most of the abstracts are around 7 to 15 sentences in length. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W29uO-r2V17"
      },
      "source": [
        "### Get a list of sentences \n",
        "\n",
        "While building a model the main inputs will be a list of strings (the line of the abstract). \n",
        "\n",
        "Lets get that lines from our dataframe by calling `tolist()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab1oQMVx2kf8",
        "outputId": "1c227ddc-1ed7-4d94-8b27-0e3b9b28646b"
      },
      "source": [
        "# Convert abstract text lines from df to a lists \n",
        "train_sentences = train_df['text'].to_list()\n",
        "val_sentences = val_df['text'].to_list()\n",
        "test_sentences = test_df['text'].to_list()\n",
        "\n",
        "# Printing the shapes of the sentences \n",
        "print(len(train_sentences) , len(val_sentences) , len(test_sentences) )"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "180040 30212 30135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFzIQf2T3CTR",
        "outputId": "063620d9-43b1-4298-fc77-541add4b865c"
      },
      "source": [
        "# View the first 10 lines of the training sentences \n",
        "train_sentences[:10]"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpYrRcv93bMY"
      },
      "source": [
        "## Make Numeric Labels (convert our labels into numbers) \n",
        "\n",
        "We will be building two types of methods: \n",
        "- One hot encoding --> For the TensorFlow \n",
        "- Label Encoder --> For the Baseline (w/o tensorflow)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMq7DDSO5KVN",
        "outputId": "77b1a17e-bca6-46bc-f1e9-2aebc50d02fe"
      },
      "source": [
        "# One hot encode labels \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Instantiating as a method \n",
        "one_hot_encoder = OneHotEncoder(sparse = False)\n",
        "\n",
        "# Performing One hot encoding to our labels \n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df['target'].to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df['target'].to_numpy().reshape(-1 , 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df['target'].to_numpy().reshape(-1 , 1))\n",
        "\n",
        "# Checking the length \n",
        "print(len(train_labels_one_hot) , len(val_labels_one_hot) , len(test_labels_one_hot))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "180040 30212 30135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21AvZTVb5VUV",
        "outputId": "0bcd892b-79b7-4525-a9e2-6cadab7d18ad"
      },
      "source": [
        "# Checking a example of our. train labels one hot encoded \n",
        "train_labels_one_hot[:10]"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtfoOEoX6wdM"
      },
      "source": [
        "### Label encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRTE89Zo63yZ",
        "outputId": "7a6da62f-b9e9-4b09-d793-496f006385cf"
      },
      "source": [
        "# Extract labels ('target' columns) and encode them into integers \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Instantiating a method \n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df['target'].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df['target'].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df['target'].to_numpy())\n",
        "\n",
        "# Check how the training labels looks like \n",
        "train_labels_encoded"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_I2SOqn7S-t"
      },
      "source": [
        "A great functionality of `LabelEncoder` is we can get the class names and number of classes using the `classes_attribute`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2WH41W_8OZ1",
        "outputId": "12791450-4a6e-4b96-d3f4-3c70345ffe05"
      },
      "source": [
        "# Get class names and number of classes from LabelEncoder instance \n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "\n",
        "# Looking inside how it looks like\n",
        "num_classes , class_names"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsnqnBEL8dT4"
      },
      "source": [
        "## **Creating a series of model experiments**\n",
        "\n",
        "We've preprocessed our data, so the next step would be performing some series of modelling experiments. \n",
        "\n",
        "At first like always let's build a baseline model and obtain a score from that. Then we'll try to beast that score by building more and more complex models. \n",
        "\n",
        "For each model, we'll train it on the training data and evaluate on the validation data.\n",
        "\n",
        "### Model 0: Getting a baseline \n",
        "\n",
        "Our first model will be a TF-IDF Multinomial Naive Bayes. For this we will create a Scikit-learn Pipeline which uses the `TfidVectorizer` class to convert our abstract sentences to number using the **TF-IDF** algorithm and then learns to classify our sentences using the `MultiNomial` algorithm. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBA7pYEe-QTb",
        "outputId": "e5704f26-eaed-41e1-ab1e-2dd1352b18aa"
      },
      "source": [
        "# Building a sklearn Pipeline for our baseline model \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Creating a pipeline \n",
        "model_0 = Pipeline([\n",
        "  ('tf-idf', TfidfVectorizer()), \n",
        "  ('clf' , MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(X = train_sentences , \n",
        "            y = train_labels_encoded)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tf-idf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMVOq2cMCcWn",
        "outputId": "09276496-c590-4f6f-addb-e625b228b8ec"
      },
      "source": [
        "# Evaluating our baseline model on the validation data \n",
        "model_0.score(X = val_sentences, \n",
        "              y = val_labels_encoded)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7218323844829869"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd12HF_Q-otz",
        "outputId": "83267117-30de-462b-dda1-a5adb65a4dd6"
      },
      "source": [
        "# Making predictions on the val sentences\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, ..., 4, 4, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmNh2aAlDOSt"
      },
      "source": [
        "# Creating a function to calculate the evaluation metircs \n",
        "\n",
        "def calculate_metrics(y_true , y_preds):\n",
        "  '''\n",
        "  Arguments: \n",
        "  y_true --> true labels of the data \n",
        "  y_preds --> predicted labels of the data \n",
        "\n",
        "  Returns: \n",
        "  A dictionary of evaluation metrics like precision , recall and f1_score\n",
        "  '''\n",
        "\n",
        "  # Let's first import the needed metrics \n",
        "  from sklearn.metrics import precision_score , f1_score , accuracy_score , recall_score\n",
        "\n",
        "  # Creting the metrics \n",
        "  accuracy = accuracy_score(y_true , y_preds)\n",
        "  f1_score = f1_score(y_true , y_preds , average = 'weighted')\n",
        "  precision = precision_score(y_true , y_preds , average = 'weighted')\n",
        "  recall = recall_score(y_true , y_preds , average = 'weighted')\n",
        "\n",
        "  # Now will create a dictionary of these metrics and pack them\n",
        "  evaluation_dict = {'Accuracy:': accuracy * 100 , \n",
        "                     'F1_Score: ': f1_score , \n",
        "                     'Precision: ': precision , \n",
        "                     'Recall: ': recall }\n",
        "\n",
        "  # Return our dictionary \n",
        "  return evaluation_dict"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPbakPVAEMk8"
      },
      "source": [
        "`macro` --> Insensitive to the label imabalance \n",
        "`micro` --> takes in account of the fp,fn etc.. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmOAuHRSDlIv",
        "outputId": "b165b745-45c6-4bfc-964c-64e9582fa660"
      },
      "source": [
        "# Getting the evaluation metrics dict for our model \n",
        "baseline_results = calculate_metrics(val_labels_encoded , baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 72.1832384482987,\n",
              " 'F1_Score: ': 0.6989250353450294,\n",
              " 'Precision: ': 0.7186466952323352,\n",
              " 'Recall: ': 0.7218323844829869}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Kl7lj3pFdHW"
      },
      "source": [
        "Thats great! We got our baseline results now lets do some more preprocessing works on our data so we can build a deep sequence model with it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9oH2BaQGjKs"
      },
      "source": [
        "## Preparing our data for deep sequence models \n",
        "\n",
        "Before we start building deep models we gotta create vectorization and Embedding layers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0JK5738G8XO"
      },
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import layers "
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFSj9ygkHCLT"
      },
      "source": [
        "Before jumping into the modelling we have to do some analysis on our data so that it will be quite appropriate for us to converting our text into numbers. \n",
        "\n",
        "Its a good idea to figure out how many words are in each sentence. Because when our model goes through our sentences, it **works best when they're all at the same length (crucial for creating batches).** \n",
        "\n",
        "> For example, if one sentence is eight words long and another in 29 words long, we want to pad the eight word sentence with zeros so it ends up being the same length as the 29 word sentence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILAT2BIIH5c6",
        "outputId": "2369501a-5c83-43f1-98aa-b3ce21a66b61"
      },
      "source": [
        "# How long is each sentence on average? (spread of sentence len)\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "\n",
        "# Taking average of the sentence lens \n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "UEVAhj-GILqM",
        "outputId": "b96dea31-7b7c-43ed-e7e5-6f29133848a5"
      },
      "source": [
        "# Whats the distribution look like? \n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens , bins = 20)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([4.2075e+04, 8.3771e+04, 3.6877e+04, 1.0945e+04, 3.9310e+03,\n",
              "        1.4450e+03, 5.6000e+02, 2.2600e+02, 1.0100e+02, 4.5000e+01,\n",
              "        2.0000e+01, 1.2000e+01, 9.0000e+00, 1.0000e+01, 6.0000e+00,\n",
              "        2.0000e+00, 3.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00]),\n",
              " array([  1.  ,  15.75,  30.5 ,  45.25,  60.  ,  74.75,  89.5 , 104.25,\n",
              "        119.  , 133.75, 148.5 , 163.25, 178.  , 192.75, 207.5 , 222.25,\n",
              "        237.  , 251.75, 266.5 , 281.25, 296.  ]),\n",
              " <a list of 20 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4z0ewBLIqoQ"
      },
      "source": [
        "Our vast majority of sentence lengths are between 0 to 50 tokens in length. It would be ideal if we pad all the sentences to 50. \n",
        "\n",
        "Lets see in % to find the value which covers 95% of the sentence lengths. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwFMk7_NJMu6",
        "outputId": "cd0b8986-a4e3-4d1e-aeab-ce9c0302bd8f"
      },
      "source": [
        "# How long a sentence covers 95% of the lengths? \n",
        "output_seq_len = int(np.percentile(sent_lens , 95))\n",
        "output_seq_len"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lAOmkfHJkdO"
      },
      "source": [
        "It seems the 95% of the sentences in our training set have a length of 55 tokens or less. \n",
        "\n",
        "When we create our tokenization layer, we will use this value to turn all our sentences into the same length. \n",
        "\n",
        "That means sentences with a length below 55 get padded with zeros and sentences with a length above 55 get truncated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iv7BUAYJ2Oe",
        "outputId": "e546649e-af3e-40de-8e5a-8162d2a9518a"
      },
      "source": [
        "# Maximum seq lenght in our training set \n",
        "max(sent_lens) # Something is 296 words long "
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-PrYB5KKTpU"
      },
      "source": [
        "#### Create a text vectorizer layer \n",
        "Now we got some infos abour our data we can now turn our text into numbers.\n",
        "\n",
        "The first step we would do is turning our texts into tokens by using the text_vectorizer layer from TensorFlow. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zow_ErkLKaJ"
      },
      "source": [
        "# Creating a text vectorizer layer \n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Variables for our text vectorizer layer \n",
        "max_vocab = 68000 # from the paper (taken from 3.2 in https://arxiv.org/pdf/1710.06071.pdf)\n",
        "\n",
        "# Creating the layer \n",
        "text_vectorizer = TextVectorization(max_tokens= max_vocab , \n",
        "                                    output_sequence_length = output_seq_len , \n",
        "                                    output_mode = 'int')\n",
        "\n",
        "# Calling the adapt method on our train sentences so our inherits the texts \n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfFnEms7L0O5"
      },
      "source": [
        "![Screenshot 2021-07-17 at 7.31.57 AM.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZMAAAC6CAYAAABryKArAAABSWlDQ1BJQ0MgUHJvZmlsZQAAKJFjYGASSSwoyGFhYGDIzSspCnJ3UoiIjFJgf8rAziDIwMLAysCWmFxc4BgQ4ANUwgCjUcG3awyMIPqyLsgsjy13pMKbDs07lvpyw5FzBo6Y6lEAV0pqcTKQ/gPE6ckFRSUMDIwpQLZyeUkBiN0BZIsUAR0FZM8BsdMh7A0gdhKEfQSsJiTIGci+AWQLJGckAs1gfAFk6yQhiacjsaH2ggCvU2peoIJ7uJGJuakHAfeSDEpSK0pAtHN+QWVRZnpGiYIjMJRSFTzzkvV0FIwMjAwZGEBhDlH9OQgcloxi+xBi+UsYGCy+MTAwT0SIJU1hYNjexsAgcQshpjKPgYG/hYFh26GCxKJEuAMYv7EUpxkbQdg89gwMrHf///+swcDAPpGB4e/E//9/L/7//+9ioPm3GRgOVAIAsyliBfvPSiYAAABiZVhJZk1NACoAAAAIAAIBEgADAAAAAQABAACHaQAEAAAAAQAAACYAAAAAAAOShgAHAAAAEgAAAFCgAgAEAAAAAQAAAZOgAwAEAAAAAQAAALoAAAAAQVNDSUkAAABTY3JlZW5zaG90qQZz6wAAAj1pVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IlhNUCBDb3JlIDYuMC4wIj4KICAgPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4KICAgICAgPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIKICAgICAgICAgICAgeG1sbnM6ZXhpZj0iaHR0cDovL25zLmFkb2JlLmNvbS9leGlmLzEuMC8iCiAgICAgICAgICAgIHhtbG5zOnRpZmY9Imh0dHA6Ly9ucy5hZG9iZS5jb20vdGlmZi8xLjAvIj4KICAgICAgICAgPGV4aWY6UGl4ZWxZRGltZW5zaW9uPjE4NjwvZXhpZjpQaXhlbFlEaW1lbnNpb24+CiAgICAgICAgIDxleGlmOlVzZXJDb21tZW50PlNjcmVlbnNob3Q8L2V4aWY6VXNlckNvbW1lbnQ+CiAgICAgICAgIDxleGlmOlBpeGVsWERpbWVuc2lvbj40MDM8L2V4aWY6UGl4ZWxYRGltZW5zaW9uPgogICAgICAgICA8dGlmZjpPcmllbnRhdGlvbj4xPC90aWZmOk9yaWVudGF0aW9uPgogICAgICA8L3JkZjpEZXNjcmlwdGlvbj4KICAgPC9yZGY6UkRGPgo8L3g6eG1wbWV0YT4KjMH9kAAAQABJREFUeAHtnQncp1P1wI9dBqkoIVnDKNmyFU3WiRkh+xJCTGRfUnZZQpaslS3MoMU6lqxRDYOISmQYe2VX/JF4/ud73jmP+3veZ/st7zu/3zv3fD7v+3uWe8+99zzn3nPvueeeM12iIBEiBSIFIgUiBSIF2qDA9G3kjVkjBSIFIgUiBSIFjAJRmERGiBSIFIgUiBRomwJRmLRNwoggUiBSIFIgUiAKk8gDkQKRApECkQJtUyAKk7ZJGBFECkQKRApECkRhEnkgUiBSIFIgUqBtCkRh0jYJI4JIgUiBSIFIgShMIg9ECkQKRApECrRNgShM2iZhRBApECkQKRApEIVJ5IFIgUiBSIFIgbYpEIVJ2ySMCCIFIgUiBSIFojCJPBApECkQKRAp0DYFojBpm4QRQaRApECkQKRAFCaRByIFIgUiBSIF2qZAFCZtkzAiiBSIFIgUiBSIwiTyQKRApECkQKRA2xSYsS6G0047TU4++WSZbrrp6maJ6ZqkgMcp6zYad2u9miTvVE3+/vvvW9/ptm87tYgCT/E3/fRxPuvf4MMf/rD86U9/6tkxdjr9oLUiLW6yySYyfPhw2Wabbbzt8bfDFDj00ENlwQUXlF122aXDmNtDd8QRR8gnPvEJGTNmTHuIpuHcO++8s9CH1l9//WmYCh80/cYbb5Rf/OIXcv7553/wcBq/WmONNeSBBx6QBRZYoCcpUXtlMtNMM9mAstRSS/VkQ3uh0sxM5plnHuk2Gn/kIx+Rueeeu+vq1Qvf1Os4bNgwmX/++SMNpxDkL3/5i8w222yRHs4g+jvDDDMEd713WVuY9F7TpoEa//dtkb/cL/L430SeeFTkX8+LvPkfkf97QzlTP+2wOUTm+LDIgouILLKEyBKfE1lYfyNECkQKRAp0mAJRmHSYoAOO7p/PilwzTuTOG0Xuv0vkHRUozcDHPymyyldE1ttYZM3RIjPP0kzumDZSIFIgUiCXAlGY5JKlCx/efp3IBaeI3HW7iG7mGrB5OXzZvhUHK4/5Py0y+5wis80u8t7/+lYpr70i8tSkvpXLg/eIvPCPPmGEQJpzLpENtxbZZX+RBRbuwkbHKkUKRAr0CgWiMOn2L3X7eJGTDxV5+E99NZ1lVpF1viYPLbCkvLbksrLG6I2aa8ETj4jccaP845wT5ZMvqVrskrNELvtpn1DZ9wcin/xUc/hi6kiBSIFIAaVAW8LkiSeekP33318nylNmyoqQTbUlllhCVl99dVlzzTUjkVulwPNPiRy5p8gt1/RhmHd+kZ11BbHpjrYPcsfpp8v0Tz8na+jbp556Sr7zne/If/7zHzO1xOLum9/8ZlrytttuK88884zMPvvscumll8qcO+4tW/38Khn/qytk9svOEbl6rMgVF4nc+GuRPVRw7bSvcsZMaf7BurjrrrvkpptuKiwOa8LNNtus8H32xQUXXCD33XefnHnmmdlXXXP/4x//WF599VWrD2bDBx98sGDs8tJLL6X1xgBizz2VFwL473//K1dffbXccMMN8o1vfENGjBghj096XPb4zh5y4YUXmrFMkFz+/ve/m/XUm2++Kccdd1z4qvS6DGdpxqn4kn7AMYYigM6HHXZY0ev4vEUKTN9iPsu2yCKLyIEHHmhMDWN/7nOfk2OOOcYGt7XWWstMXN95551aRbzxxhuy5JJLCr8DAQy2Z5999kCg7jzO6y4X+apuliNI2EA/9FSR2x8XUSFg95kSP/3pT5uJ5W9/+1tZe+21GwQJSTfccEP56Ec/KldccYXMOeecae73F1XLvB9eIHLbYyKjttCN+zdFTviuyOZfEnnuyTTdYF385je/kSuvvFLmm28+mWWWWQST5MmTJ8vCCy9s9vfnnXdeU1V57bXX5B//ULVeF8Po0aPlpz/9qbV13XXXNUFCdbGeo91nnHGGjBo1ql8L3nvvPRM4CMwXX3zR3r/7v3flX//6lyAwsvC///3PJhJ//OMfs6/63f/f//1fKuDKcPbL2CUP/vnPfwrn4maeeWYbU+j3l19+uU1yOQlx7LHHCvRrBkKaNJNvWkrbljCBUKEZ67zzzmsdgE6/4ooryrnnnisbb6wbvRXAh91iiy3k0UfVImkAgHrQKbsdpkvel3X/cLXInluKvKFWWevrLPwWVUvtsFflRjmDD2dBnn766YZmIsx//vOfy2WXXWYDdMNLv5lP91pOu0zk4lt072QhEfZWRi2n6rAbPMWg/L711lvC4Mg5GyYjABMUZt6/+tWvBPPaZmCfffYxAdpMnsFOi8A4/PDDrdg777yzofhJkyYZLZi0ZeFDH/qQbLfddg2PmYzdf//9kpeeVd1nPvOZhvRFNzvttJOt6HhfhrMo/9R+Dh/RBlZ5jCtoS1jdbbnllia0Oe+TJ3DL6h3SpCzdtPyuLTVXEeFYRvLhUDHccccdglRnZsTS85FHHpFXXnlFVlllFVvVoHpBDXP99dcbOq4ZBJZbbrnC9AgdcD3++ON2LmOllVayPBMmTJDjjz/e8HMA6Mgjj5RrrrkmPWzHDJDZKkzWdaBmvrv/5VZZ7uVnRNgXYTWy1a5NVZMDj9AkBA5C7rfffsWCJEy8mg7g4x8QOVBVaTddJfKtDUWOPy9MMaDXDKp0/DzABp9JCnyCWg+++etf/2rf+8EHH7QVDaq8Aw44wAZAcNx99932/ZmJImQRqCuvvLLce++9pvbbe++9bfKTV95gPttxxx3l6KOPlp/85CdWf/oPM2jqe+utt1pVWLFxzQrzu9/9bi6dWIUxceBg5DLLLGP5OFGNgAbfCy+80CCQ83DS9ygX1fXLL78sX/7yl/vh5GDd2LFjbUD+yle+IptvvrmVRf/jICI4TjnlFPnUpz4l3/72twXBN5jABOSoo44qLJJxgIkJYxPtQB2P0IHu8BZqQsYJ8KAuztKEsS1CDgWUyWqBMkyi+t1+aZXoiaK1P539p++106fPVb2S7LHHHokyVfL6668nhxxyiL1T3b6lV6GTptWOnoCzLL0KimSdddZJVG+cqPoq0UEh+dvf/pboQJRsuummdq1uGhIdWBLVRyfLL7+84deBNVFmSevYNRfvvJ0k23wlSRaR5M2lPpQkD9xVWTW+RUhvMuh+QrL44ouneVWlkey6667pfXihg4R9i/BZw/WPvm/1SRadLrlkg9UTFcwNrwf65p577rFvdtJJJ6VF6UCV6OrL/r7+9a8nuvpNVHgmOsAmOmgm115zrfHYc889l+jAZt9dV2yWX9Uehm+xxRZLVBWbfP7zn090QpPiHugL+FX3qwqLgb70I1XHWBr6j6q97PpnP/tZMnyp4YlOyBKdbCVf+tKX7LnuDVge6EKf4R04rrvuOnuvK51EVaBGl4l3T7T+QT2AIpzkAYeeTE904tcPJ7hVSCS333578vDDD9u17uckKqiSr33ta5ZX1aqJCsdED+EmJ5xwgpWX/UeddRDPPh6Qe139JauttloDbsaJH/zgB8nvf//75JOf/GSiGhR7/4UvfMGeMZ5wDYQ0ef755+3ZQPyDt3VCNBCoBwXn9Mo4AwKhSgKdLpuK6DBZlXz2s5+1MjkFCzCjdmBZzUnwovTMmND7KhPYCoNZ2kYbbWQ6UlZACy20kMykm8fguOqqq2SuueaSWWfVmb6CMk1DWV7mVP1V1ZbsvZWZ/L46y2xy8WhdjSy7SktVUkEizz77rM0qoRObjNqZW8IlWHYddpoOK4ls9bffyVJPP9wang7mYvNdhYCoQDC1FysMgM1n+GbRxRYVVBysflddddV0xkwaNrDhSfbOvve978luu+1mKqFmdefgGgigXvAsM3rgnHPOkW9961t2zaps6222thPS7I9lV58kIu8Pf/hDS+//WIGr4JFRo0fJSiuvZKsMf1eEk/4D4NIDQ5oszu9///vCqh+ao+LeaqutUhWyu1pidaQTRllhhRUkq7oz5FP5H+MO+4cYPjBGsMpVIWm889hjj9kKcdFFF5WDDjrIahrShDEkQj4FBkTNRVE6O0xLhKnQg6OO0pmyWZakLwsufvSjH+WmxzEcTMtSlTQsq/nzDnbLLbeIrn5EZx7pZmZBEd3x+LgDRH5zpY4GH5GTPzNCZpvr4y3XC504g+nkJybLZZdfJqhPwg33phFvv6fIW2/K9Cd+Tza+81cif75PNzFWbBpNJzOgikDV48D+AEIT31cf+9jH7DEqVSDrRJC87rKCwReLqHfffTd9Zpmm0j90+qha4GsGuD//+c/pfiPfkQGa9+j6Q+vJsLphe3UqajgwvnDAqMFp0wpO8DDYfvGLX3SUJlSYsCA0vHz/hfea3ZtIEQ/gxR/+8AdBKKv2w0rZfffd7Rf6IICZoKIiRT0YoT4FBmxlgmURwCpk2WWXtQ/HLIaZJfsaVcCHzktP52dWqct0W2WgJ8fqh1kUwAyVDslfN5uEWmVvVWut804WlXoiP7tWnh/2EXvc6j+nwfjrxouqIERVQa2i+iDfbgfLHQsMlxmxftlTLb7+8/oH77rgCv09s2/2P+ADAKHRi3DgAQfKjDPOKNtvv719Ox+U2feiz4wbN06w+KoLaALYkM+DVnFiaacqyBQlQhnopRk7goTJLns5C+lKjD94hhXt1zf5umBVCKy33nq20reb+K+SAm0LE2y6Hd5++227RA2F9Q0WRsyomAGeddZZ9o5NLQYAAMGAmoEO5ADz03GK0rM0Vd2sWfjw8VmOo75wb6x4I8UTKe9YnTCL89moCx7Knerw8gt9G91U5CBVT6zwwWyv1bq5ZR2qCVZtnYJfLLGaPD/3fCJPPyFyeN8srlO4i/BwzgJglRkC/BKam1900UU2I0bF52avrM5Ixy+8BzBT55nP6nkH+L3dTOV/qOlGjhxp5vFsXDsgRFiBMeAxSfAVlfOxrzZQ8wK0jbSo+thkxlSWtKrvt41laFGEc4455rC8pOUcWYgT3F/96lfN8IENauC2226zCZzuL1gZ9nDKP8YDaD61gTEqHKewFGTMYHzg/A2rENSMjCXf+/73RPeVTO0FnZ9/7nnJ0mRqt6dry6+7M5O3Ac/mJ5tU2jj701lLwuY4G95qBZGozXuKns1O0ulSMlGVV6KzLvtTs11Lo4xv79kMU2st2xzNS3/qqacmunxOdLWTqLleorpN2zBTprVNP96RT2cbiepGDTebgDzDAICN2K6A/bbr2+D+5lfT6kAztTxK78su8jbgSc8mnloFlWW1d5Ub8AEGNvFP23+vJFl6tr46T7g1eNv5S50ZJmrNZ99M99MSvjmgE5NEVVmJqoQSFZb2jLR8V57pHkOi5ulGAzaYVbgaDrXGSdRSzK7h19/97ncp36qlm+EZ6H9VG/Bevg7+ie5H+K396ko8pQUGJyoobENZ1V72nM1l2sQmMnzOBj190/sntMHwAOMMNRFOLr744iQPp2/s0xd1r9E237M4MQLAcEZV1/aLEQT9TC2/rFzKBzcGBBg/8KcTvIb2cDMYG/AYBTBuUSfdg7UxSdVuVhcMO1SgGC3hCQw+VHgkun9i7dp3330T6OvgNGHsGijo9Q14Zmy1IE+Y1Mo4JRGDveqBE/+YWC2ElhEwKUJEZ4qWoyg96cirsy9jYk/vdVHzSLNC8Xv/ffLJJ5N///vffjt1f+/7fd+gPFwtt555Iq1LJ4SJmsmm+MoumhUmZs119nF99V5nySR5739l6Af1nRp1pJZpWAt2zXcOqFBXmJBFDVaCnH2X8Dx9AtCVRnrd97b4P3n04KdZgmHZGEIRTvoUA3EZ0I/DyWJZ2rx3gyFM8soNnzGGMF6EoKtes4zLfoM6NAnxtHLd68LkA/2Siu+BBPS/bsVFOdkAMKiiwkNVZek979JLL92vyhyc5C8L6Em7Bk47vK8qux7YcQeLfr5gQNqKm5Vfna8u7x/R8yh6yHHDbQakmGaRsnnt0JbBgSOZyr+oh7PgPM9zHXSyrwvv6Ue6Srf3WDaGUIQTFRlxdcqA80BFZ4LK8nXTO6w8s2MF+0z8ZaEOTbJ5prX7tvdMpjWCtd3eByeK/EEPouEmZcd92kY3qAhm0k425nt9RZ51rP6iQYgQKRApECmg1pORCINMgYumuHXZTjeyESgtArb+ONNsFbCIw76+afiarkbm03NBjz0sMuG2prPHDJECkQJDkwK1Y8Bji43dNcvmCK1RYNh0iTwxz//JbGq5uvRLH5Kn32ukJVY50LfbaJyt18HD/ivfn/1dGfv2jLLr67O0RoxpLFeWhtNY8/s1V/cgzJIutOTsl2gae4CFme7tDrr7mU6RubYw4fQxfo2Y0UZojQIzXn+5zHrwzvKemgG/df6N/ZBgDsrJW3xpdRPstddedo6Aw1zAdM88IcNGfV6S2YbJm3c8VemEspvaMrXqwuFBHFZijhpBIx7oCXRM+MePHx/JMYUC9H3M28O9rF4iTu0NeGbLnBBtSTXSSxQZyLre9zvDPoN6A86jo7uQyXs3kNWqwt2vXkstYxEep9OAXbM/9meRlUdUoZjm3zMDZ8O3277t1PowHBjE6CbS44MvwCZ/L0OjnqWXW9ILdb9ryh7Dqmv2Qm3L6+ht8DaVp45vIwUiBYY4BaIwGawP/MLzIs+re/m51K/UEp8drFIHrpyVv9yH+4G7B66MiDlSIFKgZygQhclgfaonHu0rabHh+tvby1lryOJTzvh4uwaLjrGcSIFIga6kQBQmg/VZfNBdpM8h5WAVO2DlLLCQbrzruZN/6GrrnT4/VwNWVkQcKRAp0PUUqL0Bn9cS4pS4Q0bes0nPKfYVV1jRYkvk5fFnOPIjLjNO1tRXkD+2XxzTEXUO4CRu6PTOHuo/HNHhORjAJTmO2urATTfdZC6+1//q+hbnIZsH99QXaqQ1NkvxWqx+j9IkOLfDPJpIj1jn4FySZ7/85S8FB5NEAsyeMk4zv/Svvst5508ftXuhrjKsrliAUE+iVKobB7n99tvl17/+tZ1Q3nrrrS1qpQb7MeebOMokSmXbMP0MGqhcPQ08/7TIyy/2nT0JkBIVkLCzhBwI4Z6J98gNN95gj3AiiANDzszgGLSZutF2nFkeeKB6EZgCeWUW0cPz4DiR70263Xbdzfi2ilZEbtx///1zT0o73mZ+y3guiwf+89DM0JcIjUScJB4HUQ+xuqwDWfrhEJJ+SH/Dei88Gd4sjYjuSN1atVxjbFDfWeaxd+211zYruCJzeXjoxBNPTJvMuICj01p9Ms3Vd0EUT9qtvgUt4iLhvhmLCI8Mjzq0Mg50mme8Ll31W9eHTJFvLo29wDHoRA/QJery3RyrqeVKovESSlHjF0g9kCY4h8wDIi7i0I4/ouhlQRneylW36/3862TThvcaktTy5TlDpC1EkaNe6lo7UbcKyc0332zZcWSH7xyiRuK3RwdBi0aHDyMVdoaz1FfRcfv3+bX62YlhdRqum/HNpZ6XzckleUJfVDguJIId/qqIikc7cPiHzy6iC+KwrlnA0WNupMWRS/e16e99DjXBC53ciaAK435F4UwQB4z8qQfpluqm3miTDTbYILnhhhsMf1mZRfQgI5EP1c2O+ZgiSqOaZJofqypaUS5RBfETVxeKfHOV8VwWN1FCcYTq9NOgcJZEBbH1kzAqZTZveJ+ln54hS4hcSWRSeFzjDqXJW6URDinzIrM64iLfXPCtTkgtyuTCGiGRsQV+KgIVJObU1Wmik1vzK1arTwZIwUOdAZ2MmSNLIrPi0BJHovQhoNVxoA7P9LpvrrYdPeJpkw++ww47GLH5R8dBCKgb+PRZ3oXGaS4UJqSHuOAJvXfyHCdzeEGl3E022YRHTQFCIk+YqGtqc6IHMp39mTDxARGGxpOtA6FfETw40mMgoi6lwuRQ7RAaljcZe7aj6PdbV5joTNFowyCQBTzDaiTB9DF1RIACeHvtqDDZWAcd2vTgxLQ8v0BQOO38GZ5tR40a5bcNv83UjYkEvJOFvDKL6IEgQJCEePCAi+dhoKo+DDSEfa0LRcKkjOeyuBkg1eV+9rHdE7q4rjAJ6UdfCvmFNqm5ruFsl0Z44yX8bR4UCRPC/erqy7LgXBGPyLSN6yxQP/XPlzr5DN/X6pNTMtx1110WAtrL4NviMBRAgNO3EdhAO+NAFc/0ujBpS82lRM49rU0ALJ3RWywF4k1gU04YTwJW6cexw49hBDiitBFfYf755xfCgvqSlkA8OuMwtZSuZEQHRoo0PORHFabCxp7xjzgO4Jk4caKFaQ0dS+oMy+qEc0hlwjRPeKEDS+pEj7LUXbfFPSDNb3/7WwvC5OmJNkddCR883fQf1EEHTFN5YUNPOGGWzAazzNr3+87bjqLlX8KJKl8bTVFBUE8H1IyobVB3sBwnpgTxG7Jw9tlnmxqBb0MgskL1XDZjeP/fd/ruZu5/Ct5DJYfJUT9wSE1nnBb8SQeuNKRymK6sbsTYIEYOfJSFvDKL6IFqCBxh1EAiguYdosurDwdLUdGhWlShlK1K7fsynguR8C3hbVS76pLf1HtEXsyCTmisXxDzhRgvOslrSJKlH84adWKUpoEu6nbe7tulkU6OLPRwM6F7dVWdqpbp28R3mTx5ckM/98qOHTvWVHwLLbSQfUfUnnxvoFafnIKIwGpEgvWxhG/iQOwlwop7H2pnHOgUz3jduu234xvw7CforMMGfvYc0GlqDBFrN4zNO/SZDqomMr0v98cdd5wNwP6OX3TidIxQL8reBB8mBPBozBTr2AyuCLRxY8dZEnCwt8MJblUJFQZECvdHCIxDx9OZtAUj4jr05qqzCMOty9+wGqb3J2AQexWpICHFsDn60r35QTCxhow1b2inLpktEJGuykRn0xYEiWBggO+HjBgxwjoycdLDepMGQcReFQGDNG5Da4IERN4WbxvPSoB9Br4xhyDp+ESyoy4hVNXtkksuEQaPut6Bi+iBXh/w78g1dFKX5A1BnorqQ4RBJj9MUtqBIp7L4sSTLXHhx4wZYyGqt9xyy7RfhWmp77XXXit4j84KEtIV0U/VS6IrFLn66qvTaI7t0og9HCZX7GPUhZAe5GEwh5fzgAib0IQ8TALo/49PauyP5GMvLrdP6jv6NZNPXTk2FIG7F/Z0mWiBF6HrY0LYn5x/6owDneKZhop20U3HhAmhLomiyIYZYXqR4EQoC8N50iGyrq1JAyPAFLqEtGsGTAciu4GXToAguOaaa2wmzqolBAYNZuHU49lnn7VBauy4sXatulsTJMxaWE3U8QdEHgY7ojoizGCkcObLjB6gEzog5FSlZCsywgc3wJxT3H+/2hdBsOFdEzcIDVZWtHfChAkWeQ9G1uBPhoXZKLM76ke8bmaxIZCXgYgOShvbciPubdH49XVAY6jYd9BgSrZyZMbKprlDnbqxOZ7lIc+f91tEjzfeeMOS+3fkhu/LIMIqAKiqD5u1zN47BSHPZXHynViJMDF76KGHbKKCYA6BTW8mcPSVvFULaYvoR8x52o+QVlWfDcDt0gihD3hkVbtp4h9REKGvT0azWVkZYuDB+OETrGOPO7YhWWmf1JTQEsiOJ2y8E9qXVQkTYFW9dWQc6DTPWOW75F/HhAkDLwyJOorZDR+6DtCZcdMCIIh8JhjmZRnK7ILOBmOh5snCfffdJwxWOKRkNsGMA0ZiBo4wQIUBINBcjZbF4ffMyGAgfAcBCDxmIGHoTx9wQqGBoNJIgPlWPgst3od+8t/7flv873V3/z10WNVNm7oNlE4rHMYRAx5hopu8aWmsVLhH1dQWvKzWaf/5d98hzDnrCRMvj2+AagVXGgwYDnXqhhqnGQFYRA/dc7Ni/Ttyw/fl+7mwqqoPjvng905AlufKcDLA7bnnngItQp5kQsbKihVTERTRj75z2GGH2SwdgcqkqF0a0a9ZhcKLzQJhhlGTodbz71GGA3UYFleoxEIo7ZOakFUTdfQxyPMiXFi1s7JiBcR40IlxoJM843Xtlt+OCZNONMhVF87ECBZg++23N7XZKaecYrPFBvXRlIIZXJl1Mbj6H7OOWafsVegm25SU5T+sahBWqArcbxADDnUKO4Uva11IgRXVjVq02cywXyl+voTAUm0Aez7odsNBDMHt+l5mpaym6ByoE0kfChPdgDc9NGq4ZtQP/ars7fB29UtQ/gDasuznWznUqRvO8MIB1PMW/RbRAzUQK1T/juTn+7KScaiqD/VoZ7/EyyniOX+f98tkAHULA5yDWmOJbhyLGg/4o36/VfRDUJEGgdIujdjDRCjUnVh6Zen3O++8s6m43SQ3FPqeLvvLPqdPsvxdaZ/URGoNanX0VZjn818mb9QBU2qg3XGgUzzj9eum37aFiat5UEHlAWdAYARmDMxC2VMJBwP/SORlqUoHZs8DhkLdBVOzmY2umLI0nrcVAw6Y1XGNHj3aZufMrpidsapA5bX2OmvbJjqGAOCkHqgvsGXPAudmUKuxqcry+pZbbkn3HVjtIJBQpQEsrdlgZ9kKPoBOrCbRtjJipdQAn9KV2uza8Z99UuTFfzS8auaGqILMwpgpOTCrZWYJMCvVeNZ2jYBhwGa2DUBLAFqg0qD+7Gm1BPdP6Mu21LK52fk2Xh4JoL2rIrhHh80KA5Uc4Gmr6oZRRShILfOUf9kyeVxED74bPMN3BFi9ct6DGT9Qpz7wGcK6HSjjOdrJPh88h9qFVbYDQhKVlgP1/fjHP27qGM5LuNrT3/tvHv1QO3p7EWxq/mqr2nZp5KsE9i+bAfZ6EJJMOOATVifeHla0nKsCoAd0AaARZ8hQ0QG1+qSmUwtNm4ihEnbAMCMUXtTB95/aHQc6wTNez6771U5eC/LOmejMNlH1FssHM99Txu+HSz+2nYdQxjDbccwFVVgkekgq0cHabPt1cLRzAzqwWHx3VVHZWQnw8gwzXc5SkBdQJk3Iw3sdLBO1FLOY8NRFB1B7pgemEmUwS68Db6JLZTPlVWGV6GzDzJeJOR+CrngMJ3j9T2eqlkQ7W6JCxtpw8MEHW7uV6cz8WWcull5nU4nuAxh+HcATbNcbYKf1+0xprx7b8Nhv6poGQx83g6WdapGUmjTrXpWdgcG0VS1UEj1YaedidDPRaK3CKFH1X6KrL6szZ0/4FmWQe87kG+v0teX6XzRkxdRUO759B1UVJGrBZe9V4CW6xDdTcM5HrLvuuqntfjN1005uOHSgTcstKpMERfTgndNRDQMS3UdKMJkF6tRHB4VEVwa58doNSeZfkWlwGc+p1Zp9o4l3T0x0kmQ0pQ/oxCFRFUyiAtBK8TNXvCOtCjjLh0k95yJCyNKPe3iCMzaYctOvdC8uzdIOjeB/FdgprvCCPknfzgKmwd73wl8VIHYkgHHEvxO8qxMSK4O260FdQ8eRhNp9UnNAJ91/SqtCnSmHs0R8N1UVp+/aGQeqeEZV6Tb+pYX12AUzxlqQJ0xqZdREDOoIFQDmzQJEznueTVfnXnXCxnTZtLqCST+U7r9kX9e+19VSiqd2Jk947kl9A/DeW/uTht+6wsQzqYrG7OD9PvzVVWBCmzsB/YTJf9QGf6lZk2RRDYfzyou1i2DwQ6gwMWgHGGSpUzNQRg8GH12hNYPOyndBWSdjkTCpysuEzYHDsrpibuqwpOcNf7P08+9S1gebpZGuEu1wJXTPgyJhkpc2fMY4wtkuByaE4cTCnzfzy5iBYHLhTF7qrWrPQjStjAPwbBnP9LowaVvNpbOHSkB/7yZ0qF2ywHI673k2XZ17lvp5G7QsmV2f2tKZiimFsxnoeOrUpyHNVzUwkqqe5GbdEP+/PmuihvdN3qCLRsedB+j+afOAwI2/Ur2QqvtWGSHykblrF8HGOyqPUM9fO3OQkCBT7HdgkFEXyuiB3jy06qrCefrpp5tqJHTlUpWn1fehNSR7JKiAUfu2A1n6+Xcp64PN0EgHZXNBgguRcA+qnTp7XsYRN0LhGRaaLffHKUgZM7CMw8oRdRlAvcv2w5odBwaTZ6Y0a9B/BkWYDHqrurXA+T4tspL6+HlL9ymu/2DPo1urW1ivX17Q92rjbxQmGegXZ5xxRoPZ+UCXF+Jn8OIgYy/DQNIPowZ8hrEn1yvAXukRRxzRzxqsU/UfCjxTRYsoTKoo1On3W+zch/Gn6pwu6dsQ73QRA4qPjff7fi/CuRlWWlMR6jo17HQV/YR4p/EONr6Boh+rp9BkfrDb1Wp5WK/hcWMgYKjwTBltagsT7KNZDkdokwKjthT5lJ7xwLT2xl83IEPVgs17twH1Sr/9mT/oq9723xGZbYDUaN1GgA7UB9Veu+qpDlSja1BAi3bVnV3TmA5VBMvXXobawkQtZuwUeC83tivqPsOMIrt9t68qP9TDl0EsEExbscvvNqBeeACQO29UJ2U39Jk477BXt1Wzq+uDCXtoBt/VlR2EykELN+sfhOJ6ogg/ZtETlc2pZG1hkpM3PmqVApvvJDJcz2c8M1nkrGNbxTKo+WZ4T4XckboaAfY6Qk++951dsfv4L1IgUmCap0AUJlODBQgsddRZfZZd5xwv4gcAp0Zdapa57r2/0SPik/ri12/fd7CvZtaYLFIgUmAaoEAUJlPrIy+3qsi3DuCors70dR/ltZenVk0qy13hX4/LFx69V9RHi8hJF4mgqosQKRApECkQUCAKk4AYg3653zEiK6ym3uaeEdlltMz8fn6clUGvV1igrpq2/8vtfU++r+F+hy8Xvo3XkQKRApECRoG2ppj4FZrWY8A7H+np4ebjwzPDP+OXIpt9UVVdd8mYjz0jNy66mKNs+MVfUFFM6rJ3IMHHE4emTjjhBMNJXWvFyH70IZGdR6mQe0/++JkVZIVtvt1QJ7/J4vfnBA7DhxQb+Dju09DO/sp8H+HWG19tBDpTty/2rFa9Uix9F/iTwo8a/pOaiR+eF3sdX08EXQM4mKbRDfsKCf7jIBN/UQAWOBwOVRcnTTs0dJR59fB32V9o1ukY8HrM2wLOEQceX2N46/XDkv4O77l40sU3Hu9wqqrRB82bt8eM8briK66dGPCOp4wuef3N85W98zThb13+YbyjrepixkI44AcMqzQNj21/xG/JmlvzvdrhjbCeXX9d6C8g86LInQoxrLWR02wMeMjUalzolMST1UfYinObq5Unv7RIkuCuJICymNRl70ChXlPNlxX+lxxwBVEZI/ve3yXJsnNZne5fZaHkqCMO9+wNv3n4SUDYVD2dn0x6bFJCvHp8o11xxRWWt216BTXAPYt2Yov7rdYwteOHw7eENNbDaubLTU2fE40OapjV9bz5wcLPG/iz4L6w9FR4gisg6KnhExLCKRdBkTuVsnpkceELTgfyjseA32677SwktQaZsnarZ9zUJZF67E70jIS5wMF/lXp5Nn9kDz74oLkgwdddHrQaA95xldGliH/IW/bOcYe/dfmHML56It782uGmSN3SW2hncBHSF17JC5tchze8Pr3uTqVt31xqMmrCRGeFTpNpLgZ8O3GhU6I98lDyypIf6vPdtf4ySfLkY+mrspjUZe8cAU4CQ2HC89IY2b++sM/3FvHdd9802X2XnZMjjzzS0fX7zcOPA0N8jTmoCw8bcLnvCL0UD7yHU0MfxJuJH14Ve52OzQCBE8AQcCrJYMsESiNdpq/wmaUR+XJjlZOoSJhU1SMtQC8GIgY8TlNxBuqAc0bapjGJzBEmNFBvvPYan1jqeiTRlZvd40y0SJiQAOeLuoKxtNl/Vb65yuhSxj9l77J1aIZ/4C14wkE9MydMQDxWPHHq84QJ6at4w3H2ujBpe88k9JPjyzD8LymBLOIgwWmI9Q0QA557oiWGQMQ9ZQJzweCusHnPspolos5SGtyOgwfVCAcpldlTVKhTCIjF8hO32iEQXpXlO/EN3D11+J7rsnjc6n02DbBFWmKHo95BlVP2LhuLmvbjJv/+++8HzQewxOfkuBVGy8sfVl9Xj6h6acPlRa4ZZ++pl8d6ycakLnvnyPP8TuXV6wcHHyQv77yhyAE79Pne2lZVPKdfLv/D+qwE8vCj5ggDDhEtk2BTnKPpCL20PsS3gUf81DLu7FF1AfAFrvqpQ8gj9lL/lX1r0jTLe5z6xidcM/7CKKeqHqQBUN0QA36nnXYyPiSkbB4Q/Aqc8NmFF17YLwkqGnX0KLq6snf0X1fr8YCAagCqO3iNfuwRRklLrBNcvWcB9zLe16krQH9zl/DZ9FX3ZXQp45+yd9kym+EfAv+FB4qJqcTZK8JchJBH/1Z5I8TbC9dtC5NsI9GB66xjmokBT3vpoK3GhQ7p9/Iss8uFG+0uMlqtu974j8g+24jsOFLkqUkWb4IBJIxJ7XkRwEXvPE3ZL1Esp1NfYQfdcoF87PZrRT40m8gJF+i5kjN1VG6NRQhU5HFVKFtXRha4iU7ZKXoxQSAKnkMz8cPDtAwK1GnUqFGOyn5x5IjTQp2tp8+ZrOy3337pfXjBBGPs2LHho8rrOvUACR4IBiIGPI5CQ0eJxEOHl9nfYhAE2C9x4NQ6sX5CQOAQW4RDiEQndEeqrcSAd7xFdPFvldffmumLlNMM/+D4kb0V36/y0+oeW8XrDS0IrIdrFp/Y8K4V3nCcvfLb2kiR07ppNQY8m3IwuM/eII3P1MMTrQxChfHhA3r+dyY1vz31UpEfntcXEvdOnfmMXFre2mdbeePhBxtiUns2No2z8ar9Xdkvi7o7D99fhh+yo/zg35NkpldeFFleTZavvk+nqDuUZa18p3FWLL42AzJhnD0WPYNAp+ilLsLTjeJshdSFeGn88DB9Uex1nP+xosKIgOBvrKgZYFm15AECFKHUKhTVA3yseojrPlAx4CmDgZBIoawymIXjXwstA/cXX3yxGXGwEscwwYFVPt52R4wYYauy0GO37q9YslZjwHsZIV0Q7kX8U7cvOt5m+Ad+ZrVG1FfGOo0VZGjcUIEbVuMELINf+FYhtMsbIa5uve6YMJlWY8DT2VTX2eAawpf5obM7VACF8eHzuGPTb4rc8qgIp+XV9cSw8ZfKTpeeIL9f8sNy+ApLyFWXq8CZAgxu2XjV/i7397knZbGbLpdHFhDZ9KaLZbE3XxGZ+xMix58r8ss/iCzavrM7PLBifcagTqQ63Ri1WPXMhDtBL2bB0HnYbMP6NbGZ+OFYHrGSJjJnHngMeQY0BnJCOhcBgw3tLIo6WpSP51X1CPNCw07HgAe/7ovJSiutJAycDkQXZWBkQsCqksicCFkHVJeooRfWMMJZQMWIUGLQbhWydGFlVMQ/dfsidWmWf5Zddllh1UbZrD5pE21D3e7AylENMiy6pz/z33Z4w3F0+2/HhEknGur7AsRZBpgpAcwGkOzdGgO+3bjQ1si8f8QKOU4H+Jsf6RMqM8wg06lvrCNefVSufvpOjRP8FZEfHyly05U6LXpYplc/X2G8alGTXnn1JZnvX0/JVjO/I3KY7oGss6TIGgvLEuMvls/MpJ1qjrlkLz0veekYdeuymQoumS6vJi09I24GAw2hYulkHnK5E/RiUGFW+Pq/X2+oGzxTN344aguEA2oJOjvgE4FmeM8rQPx1Vl7Ox/686resHkV5GbwpK3SW2E4MeNSkfCP2FAEEIjRgla0by2YGjAk6E6LQXJow2+xNbb311oLJdAjua67ZGPCOo4guZfxT9s7x8tsK/7AqRbuA2lOt2WSDDTZoEKJl9G+VN8I6d/t128LEVTlFszF0i3RQtRoZsjHg240LXcUkT8lM8tpBJ4ncpZ31qDPlzzPNrk8U7v6tyGlHiIzZRGS9pUU+O7scfdmxctMLE/VaZ+yLzyiy4jzyjWvOkTOHaQyVsWeLPKGrnTnmlGeXX0NGavjst258WN74+jdlzN77Sr+49ZRRA5ithoYTYRZWJmymsnLymOWdohcDR1athJ6agQLhUBY/HJUIM2wNxWzqMM6psFnMTJtBVE06rU2cIxgzZozA5y4MmdUyUPIbAgYZzQ6cZfUA32DEgCdm/PHHH29nJKAZ6jxUV+E3ZeXGzJyzJR5Ey99fdNFFpuYlfgm84ECfB1gxNAtldCnjn7J32To0yz/kR80GnxA468ILL0xRQguCbHGuBHp6zHpP0ApveN6e+dWOUwvyzpnEGPBPGe2UkdqPD6+YMKXV6HT9vkduTOrXX0mSm65Mrlhp0eT6+WdInltqWPLWotP3mRZj0svf4jMk7yw9LHlokZmTsR+X5KqRqyT//M3VySMP/7WpGNn9wvYGNdRNTIs5rwyf7L777oluUNpbtaZLdKM6Gb7U8ESX/0GOxMxndRC3OPAHH3xwoipSCz/cbOxuzq1gfurQTPzwotjrKpwsNjntIUY57dGJUloOprTESee9DqrJIYcc4sWbmawOrOl9eFFkGlxUD/IORgx4zovQDtoT/vHtgCuvvNJioeuGfKIGFfaMf7qSsbjxmJzrfmCiKzzLr4Ij0cOPlq6VGPBeQBldivobecveOW7/bYZ/dEJsseCXW245M23nTJODnzuCFyfePdHM1aElZuWcewEwoS7iDcejKrS2QxA7rqnxyyysFuQJk1oZNdG0EgOeA0o6A6lLln7pioQJCctiUje8e1/jY3Po8a03++Fv9UGZMCnCqabPdmCx6D3P26UXONQCK1FzUC4rIRs/vDJDEwk4PFp25qJImFQVMRgx4MvqoCu2JBw4y9KG73TlNiAx4MMyyvin7F2Ioy7/cDgVQaErkzB7resq3nAkvS5MVA8y8FAnBnynasFSMw9Qe7he3E0X89JVPQstWbJpy95l0zZ7XxZLu+Edpryzz9ks+o6n1xlcJc5O0Av1C/p6dPnszZQBm6cDAZxpOuaYY0Rnuh1HH1oLsUfCX7vAXhZm2xgVsJFfBnp4sOx17jtUQXqqXgYiBnxYYBn/lL0LcdTln3nnnVf4axYGkjearctAp297z2SgKxjxRwqUUYBBQ1Uxwubw1AL04WzitzLYTK06xxjwfZQfaP7pRd5olScHZWXSauVivkiBOhRgxYllzdSC0FR2atWhlXKzTglbwZGXxw875r3rxmcDyT+9yhutfKfp0NfVyYjZ2/jx4xtcZNTJF9PUpwCWMLisCA9A1s89cCm7tV4D1+LOY8bya9ZZZpWZZjY7vM4X0GMY3/3vu/L2O283mDb3WBM6Xl0OY2JRGR787HghA4iwtjDBhpwTnhEiBSIFIgUiBTpPAVzmqLPQziMeJIy1hckg1ScWEykQKRApECnQgxSIG/A9+NFilSMFIgUiBbqNAlGYdNsXifWJFIgUiBToQQpEYdKDHy1WOVIgUiBSoNsoEIVJt32RWJ9IgUiBSIEepEAUJj340WKVIwUiBSIFuo0CUZh02xeJ9YkUiBSIFOhBCkRh0oMfLVY5UiBSIFKg2ygQhUm3fZFYn0iBSIFIgR6kQBQmPfjRYpUjBSIFIgW6jQJRmHTbF4n1iRSIFIgU6EEKRGHSgx8tVjlSIFIgUqDbKBCFSbd9kVifSIFIgUiBHqRAFCY9+NFilSMFIgUiBbqNAlGYdNsXifWJFIgUiBToQQpEYdKDHy1WOVIgUiBSoNsoEIVJt32RWJ+uoMC///1vWXXVVTtSl7322kvGXzu+I7gikkiBbqVA7RjwTz31lJx++umV7VhhhRVkq6226peO6MDXX3+9XHPNNUJ4ygsuuKBfmjfeeMNCA//mN7+R6aabTs4///x+aeo+AD9lAeuvv77ssMMOMtNM9UOm/ulPf5JLLrmkobgZZphBPvzhD8tSSy0l6623Xs+G12xoVBfe/OAHP5DrrrtOfvvb3061MNHwKALF4Yc//KFcfPHF8v7778v//vc/+djHPia33nprygOE5f3iF78o77zzjsDrX/va1+TEE0+07G+++aa88eYbjqryF7zwLpFNocNQgxdeeEEuu+wyufbaa+Wggw6Stddeu6eb+PTTT8svf/lL+2Ynn3yyMAZOi1B7ZfLoo4/Kj370I3niiSdsQH3ttdfs/sYbb5R55pnHOtm4cePk8ssvz6UjHfChhx6Sn/70p4JgyoNXX31VJk+eLBdeeGFhmrx82Wc777yz7LbbbvLggw/KVVddJd/61rdkiy22yCYrvf/c5z4nm2+2ufzsZz+zdhIHfd555xU6wr777mttRmhCh2aAwYi/wQAGxF4EeI0/BuhuAQa9s88+W/72t79ZaNW77rorFSTUcY455pAzzzzTJkrwnAuSVur/+OOPy89//nN57LHHWsnecp6B5M0Q9yuvvCJXX3213HLLLcIEstfh2WeflV/96ldy5513yltvvdXrzWm9/jqLqgVXXnllMmrUqDTt+PHjEy01+epXv5o+u+mmm5J11103vc+70Bld8pWvfCXvVfrsIx/5SLLmmmum981caCdPll9++eTFF1+0bNxTJnV95JFHmkFlaRdffHHLq0I0zfvee+8l3/72t+35ggsumJaVJii5UJVHojPukhSdefXkk08mm2yySWeQDTIWHXgS7ZSDXGpjcfDP8OHDGx7qIGjffPTo0Q3P/QbenzBhgt+mvzvttFNy6aWXpvd1Lj772c8m8N5gwkDyZha3TiqNlowrQwGOO+44a8/vfve7odCcltpQe2Wy8MILy957710qtViuov5xYDafBdRXDjooC39ZmH76/GqRtmq2rQLN1HFzzz23oV1llVVM5cDNX//617QopVZ6XXaRVxeenXHGGaY+Y4n7ne98px8K6vnuu+82PL/ooovkxz/+cW6b89J75jwa+Tt+s7Mh1DMqSGwVFaYru87WtSxt3rtsHTyN46V9dWkOj8w888y56evwgJfd6V+d5MhHP/pR4ZtngW+7yCKLtL3PgpoMCPtJWFZZ+0Nah3my154ufF7Gm2VlVvEmZeThzravrF+XlR+2oZnrPBqE+f07hM/8Oq+vZttTlt/xDLnflkSQZspbmYDr9ddfT775zW8mG220UaIDeTJixIhEB/G0GB3kkzXWWCPRPYxEO2Yy22yzJUcccUT6ngtWEuHKRFUeyVprrZUstNBClh7cql5qyFN2893vfjfRj53861//smSqqko+8YlPJJtttllZNnu3xBJL2IwjXJl4pj/+8Y/2Tvdikrffftseq+400T2a5Otf/3qy6KKLJscff3zCTPv3v/+9lakMlCy55JKJCt7S9Lz85z//aXg23njjZJlllklUF2t5/N8JJ5xgs9e55por+fSnP52oitFe0a4ZZ5wx0f2dRDeRE+3MnqXhF3pQT2bAyy67bMJs+Be/+IWl+f73v5/MP//89qd7GPbsgQceSD7/+c9bXVQVY8+K6qDLfuMB6k1+6rLppptafvCuvPLKCd8VULWhlUOZE++emOyyyy5Gqz//+c/2nn9FPPC9733P8upAnjDL/clPfmK0oAzapurV5J577rFVhtM8RVpykbcyITk0UrVuQ05WLKyGVYg3PPebOisT6LXccssluu+SDF9quJURrkyK2q9qYVsl8/3hNVZHKojtu4f0K/vWRbxZVCbtquJNb3sRblUfW99R1XnyhS98IaEPrbbaagl9yqGsfE/D78MPP1zJV6QrowHvAfoQ9fnyl7+cfPKTn0z22GOPvhf6v6hvkwDa07ePOeYY4xHGG3jF+0mKZAhfMPtrCYqEic7Sjai6/2F4dUVjTOKFIEwg+q677pqoXjjRvQm7P+qoozxJgzBRvbkNyrqPYu9PO+00S/+Nb3wjTV91wcDFoOoAUyHIitQVno7fMmGiMyYbJGnPvffem9DmWWaZJdE9GkPhHQb1H0DHIa1usNp9VXqEIMIYQEgzQDroCsc6EAOYbvAmDKYf+tCHEhd6CMsvfelLnrzfL4Ps0ksvbSpH8gO77767dWq+C0CHor5qjGD3/NOVZ+LfoqwOCDCEHPm32267hO8Fb9xxxx32LFSZQjvojNCFVnwr8vlgWMYDqMPmm2++BtpQFvnDgYkBQvf30nZUXRQJE9S64A4FB+Ux0BRBlTC54YYbEl3t2oQDHAhUynBhUtZ+eGi//faz9HzzX//614karti97htalep86yxvlpUJ0jLetEKDf1ncvPK+gRBUIwMbCxiAmWQCVeVbouBfFV/VoQECHZ6d9NgkwzxmzBijI2NdVV91YcJ4d8455yS6x2bfVPdZre8GVR2ylx0XJuedd54N0gwM/DHbYEXhgDBhFuzA7IOOEz4LVyZnnXWWrSoOPvjghJkrulfSM2uoA7fffrvN8rIzBF2G1sleKkxAAPNQH91QND0/K6grrrjCcKtVmr1jtgxkOxUDYVl6VmDM2FwY6Qaw4eHfpz71KaMtNOHPhfIpp5xiaaqECQKBeqO7dmCAZAXBLBvw+rM/BLCiQ2ghRIGqOrDnQD3oyCEgLFiRgg8AP5MEBwYq6ubCpIoH9t9/f0tPfQG1GrR7eAVQgw9bDdpNzX9FwoQBmrq5oIK/qiYlVcIEesNHIbB6dWFS1X74gzqpJVGKgkEangDqfOssb1aVWcabaSWmXGRx89iFCQO4A+1lUgFUle95wt8yvqpDA8pHq+DwzDPP2MQQ/qnqqy5MvO+Dg5Ux3yV85riH4m9t02AlSi1QFZeoOkOOPfZY0dmC6EawYFIbArpnh8985jOiM275y1/+YpYds88+u7+yX93QEp15ymqrrpY+X3uttWXGmaqrjqUV9cHKBn12COjk2wWdPYkynKFZaaWVZNZZZzULFeq8+eabyz/+8Q97p4NpblFV6XWQlZtvvllGjhwpW265ZWqajTUc5Sqzyiorr2K4/Xf40sNzy8o+1MHQHqkQT19hkaSrFdGVgpnFqsrEzKAxe8TkEVNtVaEJe0Z16kA6TKmz33+P3feQbbbdxiz7DjzwQNGZuWhnTOtBvhCqeAA6Ub9zzz1XqLN2XlE1n5lr8pzvv+2224YoW77WQd/yYnGlagyh/roaaBkfunUVmrLhhhs24MCM3fcjqtrv9Ar19nPOOaeo6tVw1vnWDYXrTVWZRbyZxVN1H/KGTiLT/lRVfh7eMr6qooEa55j1HJagDgsssIDoRNBva/VtLFsddGVvvIGJO30dc2gH7kPc/ryXf6tH5CZbd8/Ee2TTzTa1zst5kXXWWUf+/ve/l2LR2YioGqfB1NIz0CHY3F1v5HpNnRPRVZFsvfXWZjTAADgQoJY7duZAZ5FmNkwZMONtt90mmEy/9NJLdvagrOyy9NCOgVZntoLZ9cSJE0VnwuKGDWwGjxo9qgx94TsGKwChpCqgNB2DEIOYD1C6f2Gm0GqNJPxh0gm0U4ctttxCDjjwADN/XWyxxYxGCLIiqOIBBnjdhxP4TfcQ7Ff3cqze1BdhCO06AboPZmgQJkcffbRNGnSF1jJqXQGZoQbmpUVQ1f6ifP687rf29PxWlVnEm+3Qopnyw7R+XcZXVTTwCR+m/0VQ1lfz8uiK0x4zoWLSoPtMabJOTGZTZF1y0TgFbKJSyfus4PrDvvvta4MRHY2ZEoN6FWC7z7kOH8DC9LpcF+zSsfEPgUFON4TDR+m1LiFlm222kdVXX1323HPP9LkuqaWs06YJa1w8//zzojpVa+NJJ51kObCbVzWfWXex4ipquzNuVfrDDjvM2oAVmurFhQGM8wessqAVVjKsjhxY3e24445+m85s0wfBBYMBoCqS4GmfxRsDvK8Q6UCsJA855BA7W8P3AOrWoQH5lBtmo9tvv73NBGkXs9wyqMMDu+y8i62msCbkTJHuyVm9wc3qK5wxlpVV9c6FCRMG/qh/O8Dsl/ZxBssFdBZfnfZn84T3db81eZw3q8os4s2w3Oy1484+z7uvKj8vTxlfVdGAVaaa+duEKTz7wnkiVs1VfTWvPqzwAd27FFUL2iSHCQ9/HNgcctCq7k5PmJs+MGuL//GPfzwZNmxYosvURJd1tpmOHp5NVjZ62aurxyYAAC2fSURBVDNxnTxlc+YCyyOsPgCdEZk+XdVGdo8FkQ6ctrmM5c7YS8aaVdA+++xj7/P+sQHOpuwBBxyQ/ukga1Yy7OOwN8AeDVZEZcDeAGde9KOnm9DaIRL0vOh2dRafYF/uoAfVLK0OZgn1xqqKvJSjByhtc5R77Yim13ddf1H6Ebr57nRhj4cNdsoA0NODC+MCvoWqFU1H/txzz9l7rK7Yr9CZesO+iL3Uf+iA3TIJ3TDARjs4dRVk9/4PnT/P3dLLn1fVgf0V6pAH1BNjBdfrh2lUgFl52oHtcR0eUHNNK0uFYGq15xvx2nlT9HwHvh06+zIo2jNhYxha8HffffeVoUjfVe2ZwJvgo93gZ0OaPSX6Df2oqv3wI/n1lH5aJvtZ/AF1vjUb9+Bw3sSgoKzflfFmWokpF1nc7IVRV8oL9+z4LrQZqGrzFNT9for4qg4NsCKkThimsGdz+OGHm/GPmoJbv+NdUV/1PRM9sGp1YpyBRirE+tVxqD5oaQOeQVBnVEZ4LDDUdYQNlhDJN08REGxAYSHER1AXJGbOy0Y6FhOYQWLRw6DnVjYctMN8k/QMNHxcQHXe6aDOxjuWYEUb6LpKsPzgyP4deuihho8NNcwnMV0uAgYKrwt4ECpYU2FMgFGBzngTH7gdB/V3uiDMsIoiH51Sz6UkmJCSH3yqT7VDlGXpKZ/BGGsoBm7oqbNXK073Y8yMFFzQGsstpyMJMMfVpb0JvHCT0+vKLxYqHCBl81dVgmY+68YCYTo6P4czEaQhFNWBjkRd4Q3qx6amqjrDrHYN34Qb7zykAzMhIR+8oaeKLW0dHmDDHd5w4AChb2L7MwwlwO285c+zv0XChHR8EyzT6kKVMGGgYwIEvfhjogNfMKjpCt+KKWo/ZvdufMF3xPLI+xzt1LNhlr/qW2d5kzoVlQnCMt60AoN/WdzU0fuBroITjBj4HvAxddZVq+UuKz9A3+8yj69IVEUD+DukHZMhrMSAqr7NJAXTfSbLG2ywQcJkmH7rlpKGZIj/a0mYVNEESQ4DOWBqFw5EDDaTdcbMYFQXyI89uVsS1c1XlA6BQofpNLCywkKNNgIwMDb5DrSDsh3K0iMwnVYhPT0vv6pua8AfvkPYgb8KWKllrd2yeXz1kn3OfVkd8tL7M0y0WVHUhSoewHw6NNkFL4NAFuBH/z7Zd35fJkywFiuazHj+8LdKmHha+o3zRl7fqGq/4yn7LfvWWd4ET1GZdXgzrEce7vB90XVR+UXpeV7FV2U0ID+0z+sPZX2VfAArS8apZvi6L2fv/5+OJuhsIEKkQKRAQAGMJ3T12OA1IXjd1CX7TjqTN4u8pjLGxJECPUSBljfge6iNsaqRApECkQKRAgNMgShMBpjAEX1vUgBrOd2/6EjlwdMpXB2pUEQSKTAAFIhqrgEgakQ5NCiAqTUmo+2C7g+Kbsyam/p2ccX8kQLdSoEoTLr1y8R6RQpECkQK9BAFopqrhz5WrGqkQKRApEC3UiAKk279MrFekQKRApECPUSBKEx66GPFqkYKRApECnQrBaIw6dYvE+sVKRApECnQQxToqNdgdSkg6irBPOaqmwxxr5ndQA88dmpgI1F3CebZd2rUCadxVe7Kcaqo8UkGtHp4RsUdNs7mNIiPHagb0AJbQK7uYER9VAnuu9W1TgsYBiYLTgDhcZz1Ye6LW36gqr56Ktu+/TXXXCPqOsXCKjdbw27g4Wbr7Ok70X7HFX+7kwIdXZmo6wqhs6hzwn5xyad28998403BOzF/UwvUH5moY0zRYEH2pz6oLH4Iz/BYSlyLrHfkTtVV3YekXozVNYu5kscTaughtVNlESO7XVCXNMJf6BW5XZydyK/ucczNvQZbspgujrOqvi+//LIJR4RQM20KadkNPOztbfa32faH/NpsWdn0ncSVxe334XfyZ9Pcb6c9wuBgUImYervtNP528LmTxHZwdCKvh7PN+gbD7xjODQcCcIKIh2YHvLXynYib3knAF9Ymm2zSNkp8Z2Xp0zbSDiLAgeeaa66ZYqxTX+KLQ3Oi/tWBPFp2Cw/XqX82TTPtz/JrFlcz953ElVdu3nfKSzfUn3V0ZYIkDiOncR9CUbyGd99915Ih3ZXgYZaWrwnwlAV14W6BiLLPq+7B1cmZR5HahsiQBMMKwWkTPvNrf1dFN+KeaLz2hvgm2RPZZe2r2351oGfqm7wAQ2V1zeML6kcAoSw/hPV0nE6PgfjNqxvlcEI+hKL6koaZMTTM0jzMny2niJZlPFxGj3boRt4i3P48xB+2q277wzx5/Orvq3iR9yGU4QrThddZHOE7neCEtxZDRydPksfzJCzD1YBoKNzUlZbEVWDWjBt23DIr8cyFPPe4G3cgvofSJV2Z4MlVQ+cmxIzG5Ts+/nGbDeAanefLLLOMuUwnlgExHXCHDl7iMRx55JGWFk+v5KcOeFctAlyo695IouFbLe43cdPx5KmDqbmO33jjjdOsO+ywg7nCxh08rtgXUvfwlOsxFvD+S4x2nhNfgrrqgJ/mb/UCF+bQKJx545GUejgQt4U44BoF0WIqaCjk1CNuEd08b/hLPBQvD3y4Dgc8BjfxuSkDd/W41vfY5qRptv3Eb8GNON+ReNzakQu/cRlfTLx7orkkp964vwd0b8LqThuoOy7+Ncxr4mEFLFGNf3h0dT4mFgxtBIg5w7fX/aqkrG5eBGX7yiSvvqQDD98Nd+SEYKBcvruvTMrKydKSNufxMOWU8Uo7dCOmCeED6N8aFCwhZgcrsMnq8ZsQDJ/WOPM8o68R0oFv7t+rTvtJk4Uifq3ixbx+X4QrW6bf5+Hwdxq508IZoFWg3ayygOx3gueBMlyWYAj+Y+ZXG4itQGfwYEO4oSYQFgLCIStMiPtAHlyxA8RcYNACILyrfPD9TzAj0sOwBG5igAvdtxNo5gINBFUEdE7UDx4Dg9gqRx11lLlIP+WUU6weGms7zU5HYYkKMCBQnkZINLftCCA6kHd84m7QDurYLvjgTvAu4rsQQ4GBhngIwMUXX2xleXwSYoEQ44MYMDqDLaRbUb0QGNT91ltvTZO4MKFjEIyJ2Cs6c04QsECr7adtxFZxKPrGZXyh0R9tYKLOPjgRuMtjv1DHP/zhD1YOwkv18V5crV8mQ+Amno4DwdsIzgTvldXN04fCJK++pIPPEd7g5E+jQFq5zlNV5YS0xM1/Hg9X8UqrdKO/ElOIOCuA8wtt5Z1GmLS2UEeCXyG0oOluu+1m6flX1f40YeYiy69VvFjU70GbxZUpKr0tw4EQp3/iup74JMQ5IVDdE088YfnD78SDMlxpgUPwoilh4gOqCxPooeFQS4WJhrG1wE7eoWAwZvoORGrkYxC3IARnzgMPPNAeE1+CwFhl8TlY8cDQzJQYdBFEMLoDwiIUJvfcc4+90iW6BYZiYGIFBhBpjcGVwZ7ZKnpXcFOHdoH2govoiMx4+GWgcWFCQCeEbgjQgTweya2IbmEev87rUD44hIGzKJcBFWi1/dmOBa68ulbxhQdZc2ECHnhn3nnn5dLgnHPOMZpkI0D6+7JfZtGsNllhA8y0PVBXVd1IHwoT7rP15TvxvXyVSxof+F2YVJWTR8ssD9fhlVboxqqZVfkVV1xB1W0CSXuYcQMIFe5PPvlku+cfExOPnFmn/WnGzEWWX6t4sazfZ3Flikpvy3CgIYGGjAP8eTAyhDuQ/U5luNICh+BFR02Dlbn6gaq4RJf6ogOm6IxQdCXQsK+C7lnVIg3PQKIrAFEVl+hKRI444ggZO3as6Eqi1EwUqyjtABbXXNUhoowuukRP65TVWat6x95pdD9R9YfFbideM6BCRVSVIqutuprd82/ttdaWGWfqHMk09LDMOuushl+jVwrxy9GdE+ud+BchcK+Cx2JRayQ509nn0S3MU+c63OPSAVI0CJZl62T7875xHb7I1j/ryfejH/2oJcnuN2Tz5d3vsfsess2224gO9qKC2vaqiPUNVNUtD192DwX6Aaq6TJNn98paKSfk4WZ4JcxXh27wJdZ+tGPzzTcXDRhl7dBJn/16e0O8GsZadLJn7+u0PyVMxUUVL1b1+wr09roIhwYrsz7BOLLKyqtYWv8dvvTwXNRFuHITD6GHjbuIA9CweybeY55XdXlotvmqO65VCoMcZ0J0RWLmsqqjrHU+hA1sXWob86s+U1Q1V1qeqgFM6OgMzwZrT0ynYLNtvZHryajRo9K/kSNHepKO/uqM00xHQcqgg11+CD4AhJ03fN/p64Fuf6t80al2brHlFjZZUPWe6OxbvvjFL6ZefTtRN/9+qgoprHInyhlIXiGol4bQtTM0GrO9sB15L+q0Py9f3rM6vNhsv88rJw+HT1Tof+E4wLWqu/LQ2LM8XIWJh8iLloSJW3BUWVZAo33329csGhjUGQhV3VWbdAgTVaPZII91i27Al+Z94IEH7PwEZzVUhSWqTpNTTz21sEzqv+OOO1r9zj333HSVcOmll4ou2YXzGNlzHxqrWiinHdAVbm52LHVU9SJqkGDnYUILkYkTJ1qeFVdcMTdvnYc+q6yTtp3217FgaYcv6tS/Kg2TFQbKxx57TFT/L6rmSrN0om6+wr355ptTvNmLOuWU0XIgeYVViarhbLWu+4iFfSjbJr+v035PW/Tr/FrFi3X6veMqKqsIB2MIqzDd+2s4H0R4AsYOh/A7FeFqZuxzvL3025QwYfkGoBqAYHRA3Wyyw1uuHsG8FWDwB+ispOH0N6uLhx56yN7dd999ptJB8vM+D+gslMEsZ6uttspL0vCMA3g++C+77LK2PGfGDzMQhhXzRQSEwzHHHCOsTDiRvMYaa9hj3ey2k8oMNORTXbidSB83dpyw0pljjjmEw4e0A1UaQqgZQBCzSgPUQiU366677iowfzgbZKZDbI1tt93W8pTRLYuUDgHoprWpc+gITgdWfg4cyPNDjFXt9zzZX93TEGbjqDN1X8Ze59W1ii9ckPoMF0S6Edtgoup199kj5alFlri6Klu37P0ee+xhq0BmnbqHkr6uqpsantiq1WlFxmx9R48eLfDeuHHjZMKECcbDl1xyiZVx2223GT9WlZOlZR4P1+GVKrqlDQ8u6BcAkxiuMS0HUMHC+97PQ5Ngnrmaq077DWHOvyy/smos64tl/T6LC97PgyIcTPA22GADmTRpkqgBkFyoh1XVyEjU4lQYP4DsdyrCRRua5dG8unbts2b2gdioxjpFG2OWT6rnN3M5LK/YjGIzmQ1S3mP9wCadb0yyuY2JIZZLvMfEU3X/tsnNPZZVWC1lQYWUmR2qzjb7qt89poCzzz67lU05bLJi3qidIVFhYeXyns1WHaTMEo2ySYdpMCaymLWOGTPGcJ955plmHUYaNt614yZYsAFXX3214dOVit3X+ae630Q7huUDJzTSwSY3K1ZrbOypWs0MCqA7Fj0YMkBHXeUZniK6hUhVcJjRA2WqDj9RdyDp/WKLLZbcfvvtZorLNyKNChLLXtb+EH94zaFVNolVf260L6prEV9gQqsuXsx6zWmEdZ7uaxkf8GyLLbZIdIA2qxru2YTGmAIzcu7ZMK0L8KBvvHuesrphEOB9AGsnvj91w9ourC+4OCSqg5k9Z7Mfa0T4C3NhTLDLysEEPaTlSSed1I+Hvb5FvML7OnRzPOGvTgZS6znMsLH2w1JSB8TkkEMOSTehMRSBn7xfQ4O9997bUFW1PywvvM7yK8YAZbxY1O/BmYcrLMuvy3Aw9ni/pY9greiWluQPvxMGLWW4WuFRr2O3/zZlzeWNUZck6XkLBuUq4FwIH9WBMyM68/bb0l8GWwbMuoDAw4TPzw/UzVeUjnpyNkGXsf2S0A4G94EEysA0sl2gHbqZ2DSasvYXIXvuuedKre48Xzt84TjCX74FZr+cM6oL8C88k4VO1Y2BEOsenbGbySimpSFUlVOXluDsFK94/agz/ch5HJPg0FTf05X9VrW/KG8ev5bxYlm/z8OVV24ZDtIzmStqf/Y7FeFqhUfz6tqNz7oy0iJLZXxo6TkPQfeq5n22xNRZT4RIgUIKYHGE+gGrN7fUK0wcX0QKTAUKDGUe7UphwoYoZr1s2GMuy35BhEiBKgqwTwPPsGEbIVKgGykwlHm0K4UJm2SqlzXTTTah2fSOECkQKRApECnQvRToSmHSveSKNYsUiBSIFIgUyKNAU6bBeQjis0iBSIFIgUiBSIEoTCIPRApECkQKRAq0TYEoTNomYUQQKRApECkQKRCFSeSBSIFIgUiBSIG2KdCVwkQPBpnLkmZdlYTU0Ngdom7jzRWCP9eTquY2A3cY3Qy45sB9Be4b8JHU66AHrMyJJa4/Qn9G3dIu3Pzg/gOfaBpjpulqdXv7mm5QjQy4QMLrsQb+Epyf4i6pDHAxctlll9n3Jx/w4IMPmkuS1VdfXe6///6y7IP2Dvc96vLe2oQD0CLQw6Z2/g2v0OrNoCjZNPW8K4XJm2+8aYcWObjYKuBDCI+w+D9ywBcWf/gq6hToSdeOoNKTsakzPfUWYA4rESR0wl4HPYFs/pzw6YZL724CzjDh/w3nnvhnU7cdqd+yuvXsVPs6xUtl9Q75rCxd1Tv1MiDq7kcuHXepCQJ8kJUBft8mT55svq2cBzhzcc0114i6HzFfZ2X5B+udBlqziY/GbCodJ5599llR1ymirn66pu6DRaPCcrrxWD51Uud9bVcNn2H4bXLAlQHuHToF+C/S+M8dQUfwLXwZORBUST9acuWVV/qjnv8loBQ+0LoJdEWSqFPQtErtuK5pp32d5KW0MTkXWT7LSVL5SFcUxpseOAsXMfStOoB/Lw93THr8WsHn+LPqFiAkL3VSp46lVfKosvjci5Akg7Yy0UG8UKDlvcBbp7u69/fhzC37ztPw62osTkOHwL3GqsYfWfjYrnkW4s8mcM+0/hyvyCpIUm+x/tx/cUldhs/T8Yt7a9RaoRvrbN3LcDVTlpfr9CvD62mLfh0H5TPjDSEPb9gm8oTtDfNyXcQvXib4875jFo/fez6/91/UFWGAMHUE6q9Kf7P8QOK67cu2u4yXvN557c2rg1c6j5/z+MzTZ+vkz/N+8aALON3w7h22nXdeb65DwHNuCI4jfBZeF+EJ0zRzXcRX4ICHoUO2LUX4s+l83ClKP9SfN37ZktY+PulxWXr40qJxuC3iIXp91ALc4xpdw3RabgJT8cxdoJx44olCPASiFi6krtA1xGpJKWJqndNPP92CFal3WEurXlFt/0C97JrLd9yMqxdfOeywwxpwaYheWX755S3aInVl78WBQES4mqce6njPH1vwLfw54eYa1/K4rr/77rvtPZ18p512ko033thw6qzaIjLyksBBuOJWL7KiIT1FQ7JaHlzYExVRvfGKzsIsb5GLfTLgFp5If3R+4rewTxIC7tzRSzPIUcdQt9xsWagVKIPvgLsaXNXgXYD6u2tu2sv30/DGVg0N0ypLL9333aGhOruTfffd176peqS1mCBEaOR7sPcAHxCqALxE6HNX5d4mOiv7JuplV4jMRzTNEIr4hW/LdyCeC66/yc/3LAN4lCif8B801HCrol6kLQt6btqNOpQ/rommVwZl/OD5ytqHPp76EMoAXvbYNHm8VNTeqjrglj+Pn4v4rKhO3p7sr8atFw1lbY/V67HRbfy14+2+jN5ZPGX3ZXg0bK7xJ3774DVUp/AzPAttof+9995rPBv2pSK+oh7QlG9CGAJ4xF3Ll9UxfIeqi3xMgPn1gGjbbLON1WvBBReUo446yrIwjlIO44yH7Qhx9fS1DmK1QV2b2PLPXXYr0RLccIdeWnFHrUGsDKfOts3Nun6shKWwRiZLlOAJ+YoAz5y4s1eipvHacSGvzGLPdthhh0Q7hrmBxh206jgNlQovc4/ty+WJd0+09K7mwh0+rubB63HFdbaXaIdOdAA1HMrEVj9c0QPacSw93lIB3G3roGPX/MvGfkZFokyeLo+hE+VpCOI0T95FXpxqj9GufqaS6667zlyA60woof1AK2XRDvV7ZnWi7jpgJeeff77d6yTA8KKuQBUBrRx08LA0uILnWxL3m3YRbkA3Vc39O98H9+obbbRRooIp0c5jacZeMtbRJHPPPbc9w5U/Ls2149k9aYEyftFZdTLXXHNZ+u22285oyvcpAjzFqhA0tZp76sVNOu7xKdsBF/yEAqgDVfxQ1T5czo8YMcKK0glGopOitNgsLxW1t6wOVfycx2dldUorl7lwnsHdukNdeqMKDNVcriryfluFBzU1LvFD2tG/4Efc+jvQh91NfBlfkZ4+TVgBeJ8/nWQZvio1l8bNsXSMC+ecc46FTsBFP/2C7wsuVO3wXOhtmFAEOkH2qg6ZX2bEtQECMWCEA43O+CwuiLuY58M6oYgrwYfS2YT9+eCBsKgCPoDOjtNk4OEjOfDxYCBd6dgjXZHYYO/v+SVmigsT7j1+hAsT6gkOne3z2kAtOZIzzjjDrjXSXIJO3ZmMOugsaErK/sKEvAz4DL60Gf00+ImFUgZ5ndyFSdhhacsSSyxhqFotC6FKnRAIDggsvo0DnTX8xsSpIQ/CBHjkkUfsnng2DsQtIQ0u3QGEPPcM4A4MtuH+BO7NSePPqvhFVzwmwBlwqoCBANzsPTkgCOFfeMWhGWFSxQ9V7UPQwtd8A0ADuXk1+k1MeJHX3rI6VPFzHp+V1SmtXOYiT5jUpXeVMKmDB77j2+omudXs+uuvt3v6G0CoBfq+Qxlf6eqmH5+olsGe1RUmvndEed4P/JnTSrUPVh1dOdp4gHv/oQYz6kepDaglNLaImfihYkFXqgOLRQ7EcgqTP5Z8brXDMg7VwSor94Xb9d/hS/dFbCwrOKuPRNcaPvOY6OiN0VWibnLVjOPVjtugl8/qa4l4pwOAqbc8jwbG8ktrD0vnY489VjROhqAmKtPx6kacqdFWW3W1FMfaa60tM87UFJnTvFyE5aFO8qVxq2U5DUJa8l1x+18XPK//ks+/hz/jXleOonEeGtCi+nNA/YTKEhUblntV/ELdVRg00MRxZX/dXBN1ggOqN1R2qEFQbdDuZgD+ruKHovZhlYfVGGF8MaXdcsstBXVuGeS1t6wOVfycV1azdcrDwbNO0bsOHuqMmpajA+uuu65gwguvocLkORZ5HpEUy7EyvsIMGMDE10G1LX5Z65fQ4g7gQUWpxjSmltXJtalyVdDLEUccIWPHjrUxtNkyHH83/zY9yjHYYkZJ+Ek2x/bcc08jkIckRdhAKN8cZFAZNXrUgNIAPTF1wVyvGUAIMajwm/dx2SPYdLNNjTExFUQHixAtAgZkNvjWG7mehWwtSteJ54NZVifqW4RDV1oWtllXf5akU/zCRAJgIAljmyBA0Ku7ULVENf81yw+g9fYx8YJ/2EtkXwpTWkLiapRL0ZlzzRqIlNWhip/zCulEncDbKXrXwaNqJduvpU9OVnNjfolhw16eRkA1oQJtgapxiD0jgH0OJjftAnu2AJMegMkg+5TsixJSHHNiBN5QhNob8N54DhhpaFXbcGZGwAdko4kZBR8UwgG6P2IdFguS8FwHs9BOH1xj840YFmyIO/N4fct+2VDHSkbVbmkyXXpaZ6fO++63rw08Rx99tK2KfMBLE+sFA5MDdeCMiMeh9+ca2lUeeOABvy38VfVN4bvsi3bLyuLL3od1GcizLqxI2LTEYIEBvlP8wiAJqEqpoWkYX1BWXautMHMdfgjTc+3to20YjNB/qAMxe/wslOcJecmfZX/L6lDFz44r/LZVdfI8Vb+donddPLvsvItNBDEiwVCHA7GsClm1sBr11ULVOETwPYAVYyeAVS/geLlmTKQ+jI9MXnVPmcdDDpoWJlBAY4QLEh21Eh+QwZJlJlYVWPIAzPQ32GADwYwQBrnwwgtFN9vM0qTKWuKll16yQZ6B2YHBPTQTZDUCuPDQTT1bFaje1CzCVI9qnRXLEA5FAVwDPhuhfgwqhx56qOjGpi2bWVkNGzbMrJE48IglFqd7sVRCWMEM9913n5Wrezg2o0H9xUoNujBoYOWC1cm4sePMSgT1CpZiRQDdACxumLkicL3t3k7ec/DLB/ZWy3LrKoSoA89CNRczP04nMxDTbvdEgAqTbwBNgBCHTxicxtSTwZHZcgiel2eoDmkfljZ1+IVvHeYP8WavR4wYYVaGTHh8xUqbWKmgbgCYOHBIrcxc1BJO+VfFDyQL6xe2j3eoJvnGzL5RnWL9M+uss/JKsrzEs7z2ltUBYVLGz3l8VlYn6pAHWPQBatiQvq5Db3gBWjsPk9n5kX4F1MFDus0238wOTRK5EK8FrPzwYoAFJxalDlV8RR6+ByvFCRMm2NjgWhbUhoxFVQAPAfATKyPGO9RvDtQNIce4s9VWW/njoffbyiYQm6tqmpkQv9oBawg2AEPQD52oOattZmF5pdI6tbAI04XXWG6pybHl0Y6R6EdI1AQ10fMh9kxnIYl+dLMM069hG+z33HOPHUZUU1HbAFe9vW3qYmGERY+uLAwHdSYP1ju+mUxeneWndVQzzTQ+vW/YU3c21thMJr+uzBLtBHbgShkxUdVJ4hvlqq81ayjSsfGO5ZJ2orCJ/a4xXtCObrhV55pgEef3bBCrKiRRgZ1QD/CqIDEczZZFLHI3gsAChXK8TeDde++9DS+bkjpJsLJ06W9WKtxzQBPLMowuSI9FjQqa5NRTT00ttVZeeeVEhW9qEUM+rAABDBOwyFLBmowaNcq+g1vc8L6IXzCAgP58V8pVgZ+oupEspYD1mg6wZpih5rK2oa2mzpaH/Fghgo8/LMR0klCKr4ofqtpHH8Fqi7Iw7KBNKjCsTA7vOS+p7r+wvVV1KOPnLJ9hGVVWpzxiYMHEhjY0gzd0YpgmK6O3TrisLPLpAG/8jGEHRjU8o0+6YUIZnrQwvWDDnf7lwLgQGtz48yK+8vccFvb+pgN/osLADDV0f6zBQszT+y+HN1dYYQXjfZ2YWr/g27r1oKfjVycxNoZRl6EKTVlzhUTQjdXw1ohVZGWDuW9oGteQscM3CDisOYC6H47B/uGHHzaz12x1wEcndJj02KRU2PAMOuis3l/bL3QAn87MG56X3ZDH612WLvuulbKyOPLuaTMDLgO5zrb7tTEvT51n4Js8eXLpt+k0v+isN1GVUp3qVaap4oey9sFn/j7kKS80j5f8XfhbVYcyfs7yWVWdwnLrXneK3lV44EvShIDQKoIyvkKwMtmiL4M3TyAU4dVVufV3TLOLQFc+Ngkqej8UnsdIizotihApECkQKdBpCqA6Zs+MA5bsoahptqnAOl1Ot+Brac+kWyof6xEpECkQKdCtFGDfFOsuVe2aCbwbF3RrfdutV9Omwe0WGPNHCkQKRApMCxTAahWLPVw46b7hkG9yVHMN+U8cGxgpECkQKTDwFIhqroGncSwhUiBSIFJgyFMgCpMh/4ljAyMFIgUiBQaeAlGYDDyNYwmRApECkQJDngJRmAz5TxwbGCkQKRApMPAUaEuY3HrrrbLHHnuYy5CBr+rAlaAHhizuM/59Ou03rJ1a48oEdw/LLLOMuYxoB9e0lFdPk1sAIj2QN+SbPVT64JD/UNNAA5sWJnqCNw3Rqqe8zScV5m+9DHoq2Pxuuev8bmgLPrrw54OHZiJa4lZbT00PatVC31uDWnCbhWmcFOHP/YW1ia7rsg/FPth1RI4VapoCTZsGq/8m89OvPqSsMLxycignDCfbdC26JAOxTVgF4OBtagNONHFK6N6GcY7XiqfbVttBHAg8QhObodeAlSarEnei2Gv1r6rvUO6DVW2P77uXAk2tTHAPriEwG9yuZ5sWevbNvqvrnZV8jqed2bHjwHsts7kQ8vB6YCfSkYe/Iihqi5cJfga1KvD02XTqf6khCFSZICmrJ+/y2kp5Xnb2vfo7EnXqmHpZztatFZwhDuiSLTN8X0Rb0pS11XHwHdUxaD/6F7XX8+X9enkIp6LvSVscdxaHP89TuRW1M6SN53e8A9kHva1eVvhb9s3L8oU44vUQp4B2kFpAjGY8nio5LCQm3kYBvM/iBVbjIth7QpcedNBBDTjxDoo3TzzG4qFX9wIa3vsNDgDxEkwavJOqG2fztEkIWQ+1q5HmzFstXlcBwvcS3hQPtsR9x1nePvvsY+XhxZUwwoRqxWMw8cqvvPJK8/qLF+LNNtsswUOpA3XHYzFx1jVIU4IHUXVX7q/tt6gteA0mBKqubMybMGXigTgP1BW1eYWFJoSsJU60hx/Gcy3txWMy9OIab715gPNMPM9uvPHGVi4eTB0IibvWWmuZN1TaQd3wdFyHxtAFD8W0gfJ1ADO07eAEgbqnT9QFt+Hkm+EpFg/DDkW05T3efvHyC08QkjUMeev5+YUH8LAMr8Izddob5udaAyUl6tbceJv49MQTx6Mv4Yxx2OeAd188GPMN1P+S8SyOHHHYqWENjAfhYzw18y3d2WRROwnxSr+ifYRtpjzC3IILGKg+WEbbom9Ofcr4j/cRpi0KMNuqDXkxpBEmCBiEAAMDgzGuwt1jr65kbNDAuyeeOFUtlmgcB+uw2YIZ2DVokOFjMFAVS+IxlDVGgSWns+LWnEHOAaFBHXArTznEN+ce99YIENxy446ewZFBVeOFJAwSpBl7yVhHk7pRx621hiFO3bWTFihrCwMuAwY4cUONENMYKSluv8BrK27xcY3unklxA89gRZkOdWKT445c4z9YFjydIlABvJgyuGkMGbs/7bTTrF7UqQ6NyQT9CRng0C5OnW0nK664YqJRBg0lggU+YKAGymhL2/jmHjaAdvs3sczBP9yYwxt8B4RJ3fYGKGzQx/04OHC3jpt9De9q/IP7dI3BYni5JuwBwOBPesqHvxDw3CMQcNO+2mqrmVfasnYSfgE+JR8TGo19Yt8AwU7YB6DTfbCMtmXfnLoU8R/vIkx7FOiIMGGG6UBMEzqDz2bpjHQkdXpmfx5PQ6MbepaGXzoj+REIDqxUyOdABw2FCTM98vhgo3Hp7X7//ff3LDZ7JA2rAoDOyT0DuQMrE1YKDszKSOPPqtrCbJtBGIFRBAzw4NTN/jQJAhBBp07h0md1hAmCESHkcSB8ts7Ah0BHyEJ34j5QJvFVgDo0zgqTdnE6X+jeWtpGcJ5xxhl2X0ZbXINTf1YlxP9gRsxEowg85oevZuu0N4sL/qXM8847L33ldOSdqqhs5afBt+y9ho619B4vRQ0n7N5juTiSsnaShr7CJMiBlTf18JVrkTBptQ+W0bbqmxfxn9c9/k5bFOiIo8cwnrYOWMr7fRHU2MRlE1nVALLKyn2hKv13+NJ9ERktcfDPcYX7F8TtDiMBBslzLz2v/5KI2OKAP+NeZ3yiajF77v90BuyXFhNaZ/sW+RBX0lVtoe4qFBr2OlJkUy4IbwwQWtSBSIy6WhFCfrJfQXvrANZehBsdOXKkbLnllnL66adbNqLnqcCV1VZdLUWz9lpry4wz9X3uVmjcLk6MGjBwCCNOjhkzxupXxScYeajKziI/qgrIYmjDU0Xg7fP3fu/fnudVPDXD9DNYdqLkORDJUFd5FiFSV59yyy23WPTEzTffXHQlbsmwDAS8TCIoOlS10/OF9XS+JepiGXh5pGmmD5bRtuqbF/FfWT3ju6FLgY4IkyLyeAegQ4waPaooWVc/X2KJJSwUq2/gt9sWXUlYexFMquJJ287gxkZmOCikLwsucGmNCbGqjizs6MSJE0WjMprgZXN3vZHrWUjSguxNPUaYt4OTDWgEJb+EUg2hDp/Qzj333FN0pWDnmo488kgLtxziGehrjSxoRfiEQ/fEzPJPo0VaeFeNKlpahTrtLEXQwss6ZRbRtuqbF/Gfrr5aqGnM0usUaMqayxvrsy+/L/pl1sPgqGqBBpt/Ypy3ezgwrEMYU7qoLq0+Z0WiKjZRtVNH2uIxDVT10lAlVTdYGWVWWw0Z9EaNHmT11VcX8upek7m71n0XUbWgnUlRtVdDFt2YTk2NG14U3IRWOu3iZFaPlZKqN9PSVAlggnCeeeYppS3m0cTWpj26/yUaYlU0VHA/C70U8QBd6Aa4YdawxbYqQbDpvpitYH2yUVZ0J/tDyP/tlFlG26pvXsR/ZfWJ74YuBZoSJnRiQDcGbUaMUOBgmFoJ2XP+6Z6EXevGp81ANTayTJo0ySKM6X6BHHfccaLxuEU3JdM84YXjCs0jeRaquXTTXzT+sqk9OCWuG6SGQvdMzERTNxXtPsRBPQHd+LVfBBCDZdZk0/OS6I477hDdbJUTTzyxVluYBYb5raDMP90wF7XeEtW1y7PPPmtvaQsrFbUcs3sGWd3TsZVAJnvDLWoIvgWrnWOPPVZ0Q9vOVmiMeBucde9ACNAzbuw4m82jTkPNVIfGqGfUqkk0DKodTG0XJ3yAoFTLJBuA+WZqCSXDhg0z9VcZn/CtXDCiHkStRJuLVnH+jZ0X67S3gbDBjaslecSZG84h6ea86Ga5pWI1yLVurNs9B3gfeuihdPIE/ziwIitrJ+ng09Ac2PP7CqPTfbCMtlXfvIj/aIcazAhCN+yDPI8whCnQzBYRcauVmW1DUA8tJioU7Fp1vIkyXqKDr5lDKrnMCoYNcay6dPlv6bBKwUJI1QK5xbIZ6Bv0WImNHz/eNsjBx58e1rJ8V111lVn38ExVD2aKjLUPJrTXXXddokxs6bFuwhJHZ7GppdbKK69sVmfrrbeepSGfb5KyYY1FFqbOo0aNMiu0sK5FbcHCDPNQ6ECdMBclfnoRYGGENRdthIZs3PvGLfkwgfU2YxmGuXAeYEbKRjlpMJWmDjroWFI9MZ/SiI13LNRUcJpFUR0aq0sS29xX9VuC2TPQLk6s6nS2a22DFzCd1hm24S6iLS8xicVUmk1mDCYwvsAsNw8OP/xwMwOHfqQPrfLKeCqLCys/cLAZjsUZf/AuccQBFbKp5RUGIZQDL6mAM1pTFvnZcHf+Il9ZO6k7Juvk22KLLZIJEyaY9SP3mJFDv073wSraFn1z2lLGf1juYa3n9CJ9hKFNgaZPwDObZ9N6wQUXVB6vD9qJbCapg1/9TCUpWfm89NJLphpiNsesL6uLL8le+Eo/t7BRyunpcPM0zNCptlBvZp6oP1oBZn3M0KkvG/+uy3dcfCsVTsK+T9Es3tPm/epAIHrOoYGu7eKkzsze1QRWWClloYi2zNZZnfLe9y6yeTt5z2pum223sb0oFV62qsKAIARWtdBeB3oz7GAFxLM6PF7UzhB/0XWn+2AVbYu+eRn/wdtq+l7Yh4raFp/3LgWaFia929RY80iB+hQIhYketKyfMaaMFJhGKdDUnsk0SqPY7GmQAk9MfsJajQFGhEiBSIFqCsSVSTWNYoppjAJstLPhj8qTMx+rrLKK4NY+QqRApEAxBaIwKaZNfBMpECkQKRApUJMCUc1Vk1AxWaRApECkQKRAMQWiMCmmTXwTKRApECkQKVCTAlGY1CRUTBYpECkQKRApUEyBKEyKaRPfRApECkQKRArUpEAUJjUJFZNFCkQKRApEChRTIAqTYtrEN5ECkQKRApECNSkQhUlNQsVkkQKRApECkQLFFPh/aS59ok/XN+QAAAAASUVORK5CYII=)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1DtE6RAM8vs",
        "outputId": "48375355-3275-4f74-ef63-5f32a3202153"
      },
      "source": [
        "# Looking into our test vectorizer \n",
        "import random \n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f'Text:\\n {target_sentence}')\n",
        "print(f'\\nLength of text: {len(target_sentence.split())}')\n",
        "print(f'\\nVectorized text:\\n {text_vectorizer([target_sentence])}')"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text:\n",
            " fifty-one patients were enrolled in the investigation .\n",
            "\n",
            "Length of text: 8\n",
            "\n",
            "Vectorized text:\n",
            " [[6205   12    9  230    5    2 1437    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecyw3bfWRo9j",
        "outputId": "8f654620-71b3-4549-f0ed-fee994b812f2"
      },
      "source": [
        "# How many words in our training vocabulary \n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary() \n",
        "\n",
        "# Printing the top 5 and least 5 \n",
        "print(f\"Number of words in vocabulary: {len(rct_20k_text_vocab)}\"), \n",
        "print(f\"Most common words in the vocabulary: {rct_20k_text_vocab[:5]}\")\n",
        "print(f\"Least common words in the vocabulary: {rct_20k_text_vocab[-5:]}\")"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocabulary: 64841\n",
            "Most common words in the vocabulary: ['', '[UNK]', 'the', 'and', 'of']\n",
            "Least common words in the vocabulary: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FhCiTzYNym5",
        "outputId": "360321f5-bd34-4cf3-afc6-c8d00b08cb6a"
      },
      "source": [
        "# Configuratio of our Text vectorizer \n",
        "text_vectorizer.get_config()"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dtype': 'string',\n",
              " 'max_tokens': 68000,\n",
              " 'name': 'text_vectorization_2',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'split': 'whitespace',\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'trainable': True,\n",
              " 'vocabulary_size': 64841}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrJj90k1ONeI"
      },
      "source": [
        "#### Create a custom text embedding \n",
        "\n",
        "Out `text_vectorization` helps to map the words in our text directly to numbers but yet it doesn't necessarily caputre the relationships between those numbers. \n",
        "\n",
        "We use **embedding**, to create a richer numerical representation of our text. \n",
        "\n",
        "As our model learns by going through the test, it will update its embedding to better represent the relationships betwen the tokens in our corpus (vocab).\n",
        "\n",
        "The main parameter we're concerned here is the input_dim and output_dim of our Embedding layer. \n",
        "\n",
        "- `input_dim` --> defines the size of our vocabulary \n",
        "- `output_dim` --> defines the dimensions of the embedding output. \n",
        "\n",
        "Our embedding layer will take the integer outputs of our text_vectorization layer as inputs and convert them to feature vectors of size `output_dim`\n",
        "\n",
        "**Links**: \n",
        "- https://stackoverflow.com/questions/47485216/how-does-mask-zero-in-keras-embedding-layer-work/61102319#61102319\n",
        "- https://www.tensorflow.org/guide/keras/masking_and_padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYgJOX1-TigD"
      },
      "source": [
        "# Create a token embedding layer \n",
        "token_embed = layers.Embedding(input_dim= len(rct_20k_text_vocab) , \n",
        "                               output_dim = 128  , # different embedding sizes result in drastically different numbers of parameters to train\n",
        "                               mask_zero = True, \n",
        "                               name ='token_embedding')"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loSVKn7eU6cU",
        "outputId": "ef6799fd-bd9d-4a3b-c7dd-82aa9b99243b"
      },
      "source": [
        "# Show example embedding\n",
        "print(f\"Sentence before vectorization:\\n{target_sentence}\\n\")\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f\"Sentence after vectorization (before embedding):\\n{vectorized_sentence}\\n\")\n",
        "embedded_sentence = token_embed(vectorized_sentence)\n",
        "print(f\"Sentence after embedding:\\n{embedded_sentence}\\n\")\n",
        "print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence before vectorization:\n",
            "fifty-one patients were enrolled in the investigation .\n",
            "\n",
            "Sentence after vectorization (before embedding):\n",
            "[[6205   12    9  230    5    2 1437    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
            "\n",
            "Sentence after embedding:\n",
            "[[[ 0.00805219 -0.04976409 -0.04312688 ...  0.02359844  0.04819236\n",
            "   -0.00205771]\n",
            "  [-0.00678971 -0.03960628 -0.03311465 ...  0.04170339  0.01055507\n",
            "    0.0099654 ]\n",
            "  [-0.03487266  0.03513915  0.03138718 ...  0.00855287 -0.03678551\n",
            "   -0.0046935 ]\n",
            "  ...\n",
            "  [ 0.04562858  0.04391524  0.04047927 ... -0.04623264 -0.02069979\n",
            "    0.00678185]\n",
            "  [ 0.04562858  0.04391524  0.04047927 ... -0.04623264 -0.02069979\n",
            "    0.00678185]\n",
            "  [ 0.04562858  0.04391524  0.04047927 ... -0.04623264 -0.02069979\n",
            "    0.00678185]]]\n",
            "\n",
            "Embedded sentence shape: (1, 55, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19qveu5_U8nI"
      },
      "source": [
        "Our each vector will be the size of 128 long vectors. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tufvs6MVGyB"
      },
      "source": [
        "#### Create datasets (as fast as possible) \n",
        "\n",
        "Now its time to pack our texts into datasets to be used with a ml model, now we will look into some methods to make the process faster. \n",
        "\n",
        "- We will use a `PrefetchDataset` of batches (will use prefetch). Doing so we'll ensure TensorFlow loads our data onto the GPU as fast as possible, so faster training time. \n",
        "- We will use `batch()` and `prefetch()`and `tf.data.AutoTune` will help us to determine optimal amount of compute to use to prepare datasets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G4nB2j8WvRB",
        "outputId": "5539aa1d-13f2-45ec-a927-f8bcfed56661"
      },
      "source": [
        "# Turn our data into TensorFlow Datasets \n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences , train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences , val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences , test_labels_one_hot))\n",
        "\n",
        "# Looking into our train dataset \n",
        "train_dataset"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((), (5,)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vHzSbMUXiH3",
        "outputId": "3011941c-0722-4f36-ccda-e089f52f687f"
      },
      "source": [
        "# Applying batch and prefetch on our dataset \n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaiiGXvQYA5h"
      },
      "source": [
        "### Model 1: Conv1D with token embeddings \n",
        "\n",
        "So far we got everything we needed to model our data. Our deep models will follow a similar structure: \n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "```\n",
        "We will be changing some Layers components, because the modern deep NLP models requires text to be converted into embedding before meaningful patterns can be discovered within. \n",
        "\n",
        "The first model we're going to build is a 1-dimensional Convolutional Neural Networks. And we will follow the below workflow: \n",
        "- Build Model \n",
        "- Train Model \n",
        "- Evaluate model (make preds and compare with the ground truth). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPuaYRAaZFre",
        "outputId": "db3df870-5300-4ab9-9de8-e789ddef14c5"
      },
      "source": [
        "# Building the Conv1D model to process sequences \n",
        "inputs = layers.Input(shape = (1, ),  dtype= tf.string)\n",
        "\n",
        "# Preprocessing layers \n",
        "text_vectors = text_vectorizer(inputs) # vectorize text inputs \n",
        "token_embeddings = token_embed(text_vectors) # create embedding \n",
        "\n",
        "# Conv1D layer \n",
        "x = layers.Conv1D(filters= 64 , kernel_size= 5 , padding= 'same' , activation= 'relu')(token_embeddings)\n",
        "x = layers.GlobalMaxPooling1D()(x) # condense the output of our feature vector(patterns learned by our model)\n",
        "\n",
        "# output layer \n",
        "outputs = layers.Dense(num_classes , activation= 'softmax')(x)\n",
        "\n",
        "# Packing into a model \n",
        "model_1 = tf.keras.Model(inputs , outputs)\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss = tf.keras.losses.CategoricalCrossentropy() , # because of one hot encoded labels\n",
        "                optimizer = tf.keras.optimizers.Adam() , \n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "# Summary of our model \n",
        "model_1.summary()"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_2 (TextVe (None, 55)                0         \n",
            "_________________________________________________________________\n",
            "token_embedding (Embedding)  (None, 55, 128)           8299648   \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 55, 64)            41024     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_5 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 8,340,997\n",
            "Trainable params: 8,340,997\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIz2M3lzbHio"
      },
      "source": [
        "By looking at the model summary we can notice the majority of the trainable parameters are within the embedding layer. And if we're to increase the size of the embedding layer (output_dim) the number of trainable parameters would increase dramatically. \n",
        "\n",
        "We will use only the first 10% of batches (about 18k samples) of the training set to train and first 10% of batches from the validation set to validate on. \n",
        "\n",
        "> **ðŸ”‘ Note:** It's a standard practice in machine learning to test your models on smaller subsets of data first to make sure they work before scaling them to larger amounts of data. You should aim to run many smaller experiments rather than only a handful of large experiments. And since your time is limited, one of the best ways to run smaller experiments is to reduce the amount of data you're working with (10% of the full dataset is usually a good amount, as long as it covers a similar distribution)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYCJZBUSi5y5"
      },
      "source": [
        "We are conduction experiments on our data so we train only on 10% of the data. This is to ensure we speed up our experimentation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMUh7eaVixj1",
        "outputId": "be2b4e00-7db8-4ece-af31-98902958e06a"
      },
      "source": [
        "int(0.1 * len(train_dataset)) * 32 # Num of samples"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17984"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1F0yYXQcE8i",
        "outputId": "9cb2a6a7-fd83-49e7-cf5d-2de26001e5b6"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_dataset)), # only fit on 10% of batches for faster training time\n",
        "                              epochs=3,\n",
        "                              validation_data=valid_dataset,\n",
        "                              validation_steps=int(0.1 * len(valid_dataset))) # only validate on 10% of batches"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 57s 100ms/step - loss: 0.8322 - accuracy: 0.6858 - val_loss: 0.5874 - val_accuracy: 0.7803\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 55s 98ms/step - loss: 0.5778 - accuracy: 0.7885 - val_loss: 0.5380 - val_accuracy: 0.7985\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 55s 97ms/step - loss: 0.5433 - accuracy: 0.8011 - val_loss: 0.5207 - val_accuracy: 0.8105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oux3QI3GcqaD",
        "outputId": "7913f6d2-afe0-4a51-df76-b7f2ad616567"
      },
      "source": [
        "# Evaluate the model on a whole validation dataset \n",
        "model_1.evaluate(valid_dataset)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "945/945 [==============================] - 5s 5ms/step - loss: 0.5240 - accuracy: 0.8057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5240457057952881, 0.8057394623756409]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTrEsCOndg8Q",
        "outputId": "8f07332c-031e-46ec-cf3a-cf00f41d80a2"
      },
      "source": [
        "# Make predictions (our model outputs prediction probabilties for each class)\n",
        "model_1_pred_probs = model_1.predict(valid_dataset)\n",
        "model_1_pred_probs"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.0659543e-01, 1.6346435e-01, 5.4537761e-03, 3.1690213e-01,\n",
              "        7.5843497e-03],\n",
              "       [2.4078377e-01, 6.3042325e-01, 1.0693299e-03, 1.2373083e-01,\n",
              "        3.9927638e-03],\n",
              "       [2.6858875e-01, 3.4968719e-02, 2.9224216e-03, 6.9327831e-01,\n",
              "        2.4178780e-04],\n",
              "       ...,\n",
              "       [2.7653560e-04, 3.2579026e-03, 1.9875847e-02, 2.2083493e-04,\n",
              "        9.7636890e-01],\n",
              "       [1.8029863e-02, 6.3557762e-01, 3.3737000e-02, 1.3074844e-02,\n",
              "        2.9958078e-01],\n",
              "       [1.4835026e-02, 9.7374392e-01, 1.7261684e-03, 6.6171526e-03,\n",
              "        3.0777152e-03]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNijRwemdtnA",
        "outputId": "55e7a55e-4a6f-4c8c-f452-9277b35b059e"
      },
      "source": [
        "# Converting our pred probs to class preds \n",
        "model_1_preds = tf.argmax(model_1_pred_probs , axis = 1)\n",
        "model_1_preds"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 1, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as_tWwwDecAJ",
        "outputId": "6139e29f-6bf6-4fec-86a3-c60841b8bd24"
      },
      "source": [
        "# Calculate the model 1 results \n",
        "model_1_results = calculate_metrics(val_labels_encoded , \n",
        "                                    model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 80.57394412816099,\n",
              " 'F1_Score: ': 0.8040572285791225,\n",
              " 'Precision: ': 0.8044002095493342,\n",
              " 'Recall: ': 0.8057394412816099}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2glunOYjo33",
        "outputId": "e9e98b58-f303-4d4c-ea48-9f6f9fa26639"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 72.1832384482987,\n",
              " 'F1_Score: ': 0.6989250353450294,\n",
              " 'Precision: ': 0.7186466952323352,\n",
              " 'Recall: ': 0.7218323844829869}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_1LyX2ejMhr"
      },
      "source": [
        "### Model 2: Feature extraction with pretrained token embeddings \n",
        "\n",
        "Rather using a Conv1D model let's use a pretrained token embedding from the Tensorflow Hub. \n",
        "\n",
        "The model structure will look like this: \n",
        "\n",
        "```\n",
        "Inputs (string) -> Pretrained embeddings from TensorFlow Hub (Universal Sentence Encoder) -> Layers -> Output (prediction probabilities)\n",
        "```\n",
        "\n",
        "> **ðŸ”‘ Note:** We could use GloVe embeddings as per the paper but since we're working with TensorFlow, we'll use what's available from TensorFlow Hub (GloVe embeddings aren't). We'll save [using pretrained GloVe embeddings](https://keras.io/examples/nlp/pretrained_word_embeddings/) as an extension.\n",
        "\n",
        "\n",
        "But we dont have a Glove embedding in our TensorFlow Hub, so we will go with our universal  \n",
        "[sentence encoder layer](https://tfhub.dev/google/universal-sentence-encoder/4) as our pretrained token embedding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6euY4Eekmcv"
      },
      "source": [
        "# Download pretrained TensorFlow Hub USE\n",
        "import tensorflow_hub as hub \n",
        "tf_hub_embedding_layer = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4' , \n",
        "                                        trainable = False , \n",
        "                                        name = 'universal_sentence_encoder')"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3YWEucamZ8V",
        "outputId": "ee4e87de-e6c3-409d-bbbb-5a5020a3c4d3"
      },
      "source": [
        "# Test out the embedding on a random sentence\n",
        "random_training_sentence = random.choice(train_sentences)\n",
        "print(f\"Random training sentence:\\n{random_training_sentence}\\n\")\n",
        "use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])\n",
        "print(f\"Sentence after embedding:\\n{use_embedded_sentence[0][:30]} (truncated output)...\\n\")\n",
        "print(f\"Length of sentence embedding:\\n{len(use_embedded_sentence[0])}\")"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random training sentence:\n",
            "patients and treating investigators were masked to treatment allocation .\n",
            "\n",
            "Sentence after embedding:\n",
            "[-0.04303445  0.03076015  0.0022611  -0.02538441  0.00484251 -0.07594035\n",
            "  0.04436538 -0.04616628 -0.08282986 -0.06992276  0.09325808 -0.01177157\n",
            "  0.04398174 -0.02281059  0.00676768  0.01257386 -0.09435748 -0.06189109\n",
            " -0.05588175  0.00980177  0.0031279   0.0735094  -0.03354086 -0.08727518\n",
            "  0.06832913  0.00068152 -0.01471595 -0.00055831  0.04657191  0.07775136] (truncated output)...\n",
            "\n",
            "Length of sentence embedding:\n",
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIWt9mw5muS9"
      },
      "source": [
        "USE module (pretrained embedding) takes care of tokenizing our text for us and outputs 512 dim embedding vector. \n",
        "\n",
        "Now lets build a model with our pretrained embedding layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-szBPeJnEHc",
        "outputId": "f561c0b7-dcf1-49a2-88ae-d30b07e62b5f"
      },
      "source": [
        "# Building our model with the feature extraction layer \n",
        "inputs = layers.Input(shape = [] , dtype= tf.string)\n",
        "\n",
        "# Our pretrained embedding layer \n",
        "pretrained_embedding = tf_hub_embedding_layer(inputs)\n",
        "\n",
        "# FC layer \n",
        "x = layers.Dense(128 , activation = 'relu')(pretrained_embedding)\n",
        "outputs = layers.Dense(num_classes , activation= 'softmax')(x)\n",
        "\n",
        "# Packing into a model \n",
        "model_2 = tf.keras.Model(inputs , outputs)\n",
        "\n",
        "# Compile the model \n",
        "model_2.compile(loss = tf.keras.losses.CategoricalCrossentropy() , \n",
        "                optimizer = tf.keras.optimizers.Adam(), \n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "# Sumamry of the model \n",
        "model_2.summary()"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None,)]                 0         \n",
            "_________________________________________________________________\n",
            "universal_sentence_encoder ( (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 256,864,133\n",
            "Trainable params: 66,309\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UNvdF0job3I",
        "outputId": "fff556db-0400-4227-b98a-4e47804db206"
      },
      "source": [
        "# Fit the feature extractor model for 3 epochs \n",
        "model_2_history = model_2.fit(train_dataset , \n",
        "                              epochs = 3 , \n",
        "                              steps_per_epoch = int(0.1 * len(train_dataset)) , \n",
        "                              validation_data = valid_dataset , \n",
        "                              validation_steps = int(0.1 * len(valid_dataset)))"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 12s 14ms/step - loss: 0.9186 - accuracy: 0.6511 - val_loss: 0.7953 - val_accuracy: 0.6898\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 7s 13ms/step - loss: 0.7674 - accuracy: 0.6996 - val_loss: 0.7503 - val_accuracy: 0.7074\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 7s 13ms/step - loss: 0.7489 - accuracy: 0.7141 - val_loss: 0.7321 - val_accuracy: 0.7174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzYPO_SPo5HF",
        "outputId": "0d5ad31f-6b1d-4e6c-bf9e-509102f711c3"
      },
      "source": [
        "# Evaluating our model on the whole valid data \n",
        "model_2.evaluate(valid_dataset)"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "945/945 [==============================] - 10s 11ms/step - loss: 0.7375 - accuracy: 0.7152\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7375247478485107, 0.7152456045150757]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D9kWAbBpaTE",
        "outputId": "614eeb7c-a97c-4eae-ef64-64e92bf0d627"
      },
      "source": [
        "# Make predictions with our feature extraction model \n",
        "model_2_pred_probs = model_2.predict(valid_dataset)\n",
        "model_2_pred_probs"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.19940293e-01, 3.72419119e-01, 1.69984438e-03, 1.98476747e-01,\n",
              "        7.46400282e-03],\n",
              "       [3.68039042e-01, 4.65337783e-01, 2.88721453e-03, 1.61240324e-01,\n",
              "        2.49554543e-03],\n",
              "       [2.37688527e-01, 1.20984495e-01, 1.81309711e-02, 5.85724592e-01,\n",
              "        3.74714471e-02],\n",
              "       ...,\n",
              "       [1.92533911e-03, 6.24932023e-03, 4.77047786e-02, 7.91533268e-04,\n",
              "        9.43329036e-01],\n",
              "       [4.33295174e-03, 4.59638275e-02, 2.17140049e-01, 1.79745967e-03,\n",
              "        7.30765700e-01],\n",
              "       [1.74248517e-01, 2.84747005e-01, 4.76526141e-01, 1.11438427e-02,\n",
              "        5.33346087e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAt4ElTrpj5I",
        "outputId": "91eff4eb-b82b-4f05-b877-951c24abc50c"
      },
      "source": [
        "# Convert the pred probs to class preds \n",
        "model_2_preds = tf.argmax(model_2_pred_probs , axis = 1)\n",
        "model_2_preds"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 2])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjtwCEmzpwl1",
        "outputId": "35cb28b4-2375-48b8-e746-ba89db571bf1"
      },
      "source": [
        "# Results for our feature extraction model \n",
        "model_2_results = calculate_metrics(val_labels_encoded , \n",
        "                                    model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 71.52455977757182,\n",
              " 'F1_Score: ': 0.7121762006886146,\n",
              " 'Precision: ': 0.7155028567077586,\n",
              " 'Recall: ': 0.7152455977757183}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW0KDzGQp-WV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b7b3e4b-61bc-4b9a-c724-e98036a941f1"
      },
      "source": [
        "label_encoder.classes_"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq7zye0CuPkD"
      },
      "source": [
        "### Model 3: Conv1D with character embeddings \n",
        "\n",
        "The paper which we're replicating they used a combination of token and character-level embeddings. Previously we've token-level embeddings but we'll need to do similar steps for characters if we want to use char-level embeddings. \n",
        "\n",
        "The difference between a character and token embedding is that the **character embedding** is created using sequences split into character (e.g hello --> [h, e, l, l, o] whereas token embedding is created on sequences split into tokens. \n",
        "\n",
        "**How to create character-level embbedding?**\n",
        "We can create a character-level embedding by first vectorizing our sequences (after they have been split into characters) using the `TextVectorization` class and then ppassing those vectorized through an `Embedding` layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ6McBnuu8mS",
        "outputId": "a5389614-20fa-477d-b5b2-6bfd6ec39a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Make function to split sentnces into character \n",
        "def split_chars(text):\n",
        "  return ' '.join(list(text))\n",
        "\n",
        "# Teest splititng non-character level sequence into characters \n",
        "split_chars(random_training_sentence)"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'p a t i e n t s   a n d   t r e a t i n g   i n v e s t i g a t o r s   w e r e   m a s k e d   t o   t r e a t m e n t   a l l o c a t i o n   .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agKIF5YUwn78",
        "outputId": "9811b034-a434-4b3f-c2c3-36a640d1d250",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "random_training_sentence"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'patients and treating investigators were masked to treatment allocation .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi30bOVcwoy8"
      },
      "source": [
        "Create character-level datasets by splitting our sequence datasets into characters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BgnRtQU-dp1"
      },
      "source": [
        "#### Character level Text vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvzFO87ewy4e",
        "outputId": "beb7995a-d5aa-4c04-c511-160271b7616d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Split sequence level data splitsi nto character level data spplits \n",
        "train_chars = [split_chars(sentence)  for sentence in train_sentences]\n",
        "valid_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
        "\n",
        "# Checking the train chars \n",
        "train_chars[:5]"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .',\n",
              " 'a   t o t a l   o f   @   p a t i e n t s   w i t h   p r i m a r y   k n e e   o a   w e r e   r a n d o m i z e d   @ : @   ;   @   r e c e i v e d   @   m g / d a y   o f   p r e d n i s o l o n e   a n d   @   r e c e i v e d   p l a c e b o   f o r   @   w e e k s   .',\n",
              " 'o u t c o m e   m e a s u r e s   i n c l u d e d   p a i n   r e d u c t i o n   a n d   i m p r o v e m e n t   i n   f u n c t i o n   s c o r e s   a n d   s y s t e m i c   i n f l a m m a t i o n   m a r k e r s   .',\n",
              " 'p a i n   w a s   a s s e s s e d   u s i n g   t h e   v i s u a l   a n a l o g   p a i n   s c a l e   (   @ - @   m m   )   .',\n",
              " 's e c o n d a r y   o u t c o m e   m e a s u r e s   i n c l u d e d   t h e   w e s t e r n   o n t a r i o   a n d   m c m a s t e r   u n i v e r s i t i e s   o s t e o a r t h r i t i s   i n d e x   s c o r e s   ,   p a t i e n t   g l o b a l   a s s e s s m e n t   (   p g a   )   o f   t h e   s e v e r i t y   o f   k n e e   o a   ,   a n d   @ - m i n   w a l k   d i s t a n c e   (   @ m w d   )   .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qirbqWfZxQxg"
      },
      "source": [
        "To figure our how long our vectorized character sequence should be (avg character length), distribution of our character sequence lengths. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3-rrs2ixec1",
        "outputId": "e86b19dc-7172-4529-d07d-481772652843",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Whats the average character length\n",
        "char_lens = [len(sentence) for sentence in train_sentences]\n",
        "mean_char_len = np.mean(char_lens)\n",
        "mean_char_len"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149.3662574983337"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM_J4rpbxvx9",
        "outputId": "471a56fb-4ad4-45e0-f6d1-ad0e68fdb0bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Chheck the distribution of our sequences at character-level \n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(char_lens , bins = 7);"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ityft31Ex0TP",
        "outputId": "1227eb2b-65b8-4353-9ed1-37964e62893b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Find what character length covers 95% of sequences \n",
        "output_seq_char_len = int(np.percentile(char_lens , 95))\n",
        "output_seq_char_len"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEIyoj68yBIh"
      },
      "source": [
        "Now we know the sequence length which covers 95% of sequences, we will use that in our `TextVectorization` layer as the `output_sequence_length` parameter. \n",
        "\n",
        "> **Note**: You can experiment here to figure out what the optimal `output_sequence_length` should be, perhaps using the mean results in as good results using the 95% percentile. \n",
        "\n",
        "We'll set `max_tokens` (total number of different characters in our sequences) to 28, in other  words 26 letters of the alphabet + space + OOV tokens. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2Drg1T0zLKC",
        "outputId": "9e835569-e34b-4934-b47b-2f64df38cf21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Get all the keyboard character for char-level embedding \n",
        "import string \n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation \n",
        "alphabet"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD3565Wt04YH",
        "outputId": "3babd931-abbb-46b9-c200-bd4cfa7b2441",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(alphabet) + 2"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrXIHjE31Caq"
      },
      "source": [
        "# Create char-level token vectorized instance \n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2 \n",
        "\n",
        "# Text Vectorizer \n",
        "char_vectorizer = TextVectorization(max_tokens= NUM_CHAR_TOKENS , \n",
        "                                    output_sequence_length = output_seq_char_len, \n",
        "                                    standardize = 'lower_and_strip_punctuation' , \n",
        "                                    name ='char_vectorizer')\n",
        "\n",
        "# Adapt character vectorized to training characters \n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBVd1u5p1487",
        "outputId": "a0623d8f-4065-4604-df24-ea2421aae4cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check character vocabulary characteristics\n",
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "len(char_vocab)"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK5D7ZoS1-9g",
        "outputId": "9f14bea1-84ee-4466-9365-53df2533745c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Checking our character and the corresponding vectorized chars \n",
        "random_train_chars = random.choice(train_chars)\n",
        "print(f'Charified text:\\n {random_train_chars}')\n",
        "print(f'\\n Length of chars: {len(random_train_chars.split())}')\n",
        "print(f'5 most common character: {char_vocab[:5]}')\n",
        "print(f'5 least common character: {char_vocab[-5:]}')"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Charified text:\n",
            " s u r a l   s e n s o r y   n e r v e   a t   e i g h t   w e e k s   s h o w e d   a   s i g n i f i c a n t   d i f f e r e n c e   i n   t w o   g r o u p s   f o r   c o n d u c t i o n   v e l o c i t y   ,   d f   =   @   ,   @   ,   f   =   @   ,   a n d   p   =   @   .\n",
            "\n",
            " Length of chars: 108\n",
            "5 most common character: ['', '[UNK]', 'e', 't', 'i']\n",
            "5 least common character: ['k', 'x', 'z', 'q', 'j']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4y5MziL9ehj",
        "outputId": "040f34f4-8894-4f07-97a0-f4c411894f66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vectorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f\"\\nVectorized chars:\\n{vectorized_chars}\")\n",
        "print(f\"\\nLength of vectorized chars: {len(vectorized_chars[0])}\")\n"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Vectorized chars:\n",
            "[[ 9 16  8  5 12  9  2  6  9  7  8 19  6  2  8 21  2  5  3  2  4 18 13  3\n",
            "  20  2  2 23  9  9 13  7 20  2 10  5  9  4 18  6  4 17  4 11  5  6  3 10\n",
            "   4 17 17  2  8  2  6 11  2  4  6  3 20  7 18  8  7 16 14  9 17  7  8 11\n",
            "   7  6 10 16 11  3  4  7  6 21  2 12  7 11  4  3 19 10 17 17  5  6 10 14\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0]]\n",
            "\n",
            "Length of vectorized chars: 290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__jtsHGD9387"
      },
      "source": [
        "We can notice the sequences with a length shorted than 290 (output_seq_char_lenght) get padded with zeros at the end, this ensures all sequences passed to our model are the same length. \n",
        "\n",
        "#### Creating a character-level embedding \n",
        "We have created our character-level vectorizer and now its time to create a character level embedding. \n",
        "\n",
        "We can do that by using `tf.keras.layers.Embedding(())` where, \n",
        "- `input_dim` will be equal to the different characters in our **char_vocab** (28). \n",
        "- The output dimension `output_dim` will be 25. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FarKu8oZ_HdQ",
        "outputId": "27658c66-304a-42d5-acc9-26b2c98874df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create char embedding layer \n",
        "char_embed = layers.Embedding(input_dim= NUM_CHAR_TOKENS, # number of diff characters, \n",
        "                              output_dim = 25, #embedding dimension of each character (on the papper)\n",
        "                              mask_zero = True , \n",
        "                              name = 'char_embed')\n",
        "\n",
        "# Test out character embedding layer \n",
        "print(f\"Charified text (before vectorization and embedding):\\n{random_train_chars}\\n\")\n",
        "\n",
        "# Applying the embedding layer on a random sentence\n",
        "char_embed_example = char_embed(char_vectorizer([random_train_chars])) \n",
        "\n",
        "print(f\"Embedded chars (after vectorization and embedding):\\n{char_embed_example}\\n\")\n",
        "print(f\"Character embedding shape: {char_embed_example.shape}\")"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Charified text (before vectorization and embedding):\n",
            "s u r a l   s e n s o r y   n e r v e   a t   e i g h t   w e e k s   s h o w e d   a   s i g n i f i c a n t   d i f f e r e n c e   i n   t w o   g r o u p s   f o r   c o n d u c t i o n   v e l o c i t y   ,   d f   =   @   ,   @   ,   f   =   @   ,   a n d   p   =   @   .\n",
            "\n",
            "Embedded chars (after vectorization and embedding):\n",
            "[[[-0.0163065  -0.02876065 -0.02399766 ...  0.01711187 -0.04641572\n",
            "   -0.00094452]\n",
            "  [ 0.01314605 -0.01746011 -0.02210599 ...  0.00628064  0.01256064\n",
            "    0.01419634]\n",
            "  [-0.00981891  0.02266112  0.01493381 ...  0.01560047 -0.00193534\n",
            "    0.04218156]\n",
            "  ...\n",
            "  [-0.0353893   0.02878877  0.04367952 ... -0.04428059  0.02474694\n",
            "    0.00508871]\n",
            "  [-0.0353893   0.02878877  0.04367952 ... -0.04428059  0.02474694\n",
            "    0.00508871]\n",
            "  [-0.0353893   0.02878877  0.04367952 ... -0.04428059  0.02474694\n",
            "    0.00508871]]]\n",
            "\n",
            "Character embedding shape: (1, 290, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJWUN8SwG6HO"
      },
      "source": [
        "(1,290,25) --> 1 is the single sequence of 290 long (char sequence) and they are represented as 25 long embedding vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8Du7TmsFRK1"
      },
      "source": [
        "#### Building a Conv1D model to fit on character embedding \n",
        "Till now we have turned our character-level sequence into numbers (`char_vectorizer`) as well as numerically represent them as an embedding (`char_embed`). \n",
        "\n",
        "\n",
        "The model will have te same structure as our custom token embedding model (`model_1`) except it will take **characeter-level sequences** as input instead of **token-level sequences**.\n",
        "\n",
        "```\n",
        "Input (character-level text) -> Tokenize -> Embedding -> Layers (Conv1D, GlobalMaxPool1D) -> Output (label probability)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DwlQIpQJ2yx",
        "outputId": "84b2139f-be1e-4c41-bbf7-d04abdcd2f69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Building the Conv1D Character level sequence model \n",
        "inputs = layers.Input(shape = (1,) , dtype = tf.string)\n",
        "x = char_vectorizer(inputs)\n",
        "x = char_embed(x)\n",
        "x = layers.Conv1D(64 , kernel_size= 5 , padding ='same' , activation= 'relu')(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(num_classes , activation= 'softmax')(x)\n",
        "\n",
        "# Packing into a model \n",
        "model_3 = tf.keras.Model(inputs , outputs)\n",
        "\n",
        "# Compiling the model \n",
        "model_3.compile(loss = tf.keras.losses.CategoricalCrossentropy(), \n",
        "                optimizer = tf.keras.optimizers.Adam(), \n",
        "                metrics = ['accuracy'])\n",
        "# Checking the model summary\n",
        "model_3.summary()"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "char_vectorizer (TextVectori (None, 290)               0         \n",
            "_________________________________________________________________\n",
            "char_embed (Embedding)       (None, 290, 25)           1750      \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 290, 64)           8064      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_6 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 10,139\n",
            "Trainable params: 10,139\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXvm45hIKcXp",
        "outputId": "fc602ae1-37a0-4183-c9c8-8e56ca7a5fc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create char level pre-fetch dataset \n",
        "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars , train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices((valid_chars , val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "train_char_dataset , val_char_dataset"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>,\n",
              " <PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou0YZ1q6KdQN",
        "outputId": "5ec4192c-5d87-40eb-886d-6adb373d31ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Fitting thhe model on character level sequence \n",
        "model_3_history = model_3.fit(train_char_dataset , \n",
        "                              epochs = 3 ,\n",
        "                              steps_per_epoch = int(0.1 * len(train_char_dataset)) ,\n",
        "                              validation_data = val_char_dataset , \n",
        "                              validation_steps = int(0.1 * len(val_char_dataset)))"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 14s 23ms/step - loss: 1.3210 - accuracy: 0.4690 - val_loss: 1.1250 - val_accuracy: 0.5725\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 13s 23ms/step - loss: 1.0632 - accuracy: 0.5801 - val_loss: 0.9704 - val_accuracy: 0.6160\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 13s 23ms/step - loss: 0.9436 - accuracy: 0.6324 - val_loss: 0.8869 - val_accuracy: 0.6566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okn7Js7nM9XR",
        "outputId": "c24b17ba-f9f4-4f16-e28d-7bf0264c3e90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate the model3 on validation set \n",
        "model_3.evaluate(val_char_dataset)"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "945/945 [==============================] - 6s 7ms/step - loss: 0.9078 - accuracy: 0.6483\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9077638983726501, 0.6482523679733276]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7tjw9vYOiTq",
        "outputId": "0512b7b0-fdf4-4816-fc06-73df9e7d09f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Making predictions with our char model \n",
        "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
        "model_3_preds = tf.argmax(model_3_pred_probs , axis = 1)\n",
        "\n",
        "model_3_preds"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([1, 1, 3, ..., 4, 4, 0])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTlekh9ROwoI",
        "outputId": "60aa2a60-2f89-46b7-94a5-32684757736c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate the result report on our char only model \n",
        "model_3_results = calculate_metrics(val_labels_encoded , \n",
        "                                    model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 64.8252350059579,\n",
              " 'F1_Score: ': 0.6341619909602018,\n",
              " 'Precision: ': 0.6425145963865044,\n",
              " 'Recall: ': 0.6482523500595789}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuBTd34RPAoC"
      },
      "source": [
        ""
      ],
      "execution_count": 231,
      "outputs": []
    }
  ]
}