{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Milestone Project 2: SkimLit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAguwwpMb2CIEjA6F89WX+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning_Tensorflow/blob/main/Notebooks/Milestone_Project_2_SkimLit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NwEKeznKJUb"
      },
      "source": [
        "# Milestone Project 2: SkimLit\n",
        "The purpose of this notebook is to build an NLP model to make reading medical abstracts easier. \n",
        "\n",
        "In this project, we're going to be putting what we've learned into practice.\n",
        "\n",
        "More specificially, we're going to be replicating the deep learning model behind the 2017 paper [PubMed 200k RCT: a Dataset for Sequenctial Sentence Classification in Medical Abstracts](https://arxiv.org/abs/1710.06071).\n",
        "\n",
        "When it was released, the paper presented a new dataset called PubMed 200k RCT which consists of ~200,000 labelled Randomized Controlled Trial (RCT) abstracts.\n",
        "\n",
        "The goal of the dataset was to explore the ability for NLP models to classify sentences which appear in sequential order. In other words, given the abstract of a RCT, what role does each sentence serve in the abstract?\n",
        "\n",
        "### What we're going to cover\n",
        "Time to take what we've learned in the NLP fundmentals notebook and build our biggest NLP model yet:\n",
        "- Downloading a text dataset (PubMed RCT200k from GitHub)\n",
        "- Writing a preprocessing function to prepare our data for modelling\n",
        "- Setting up a series of modelling experiments\n",
        "  - Making a baseline (TF-IDF classifier)\n",
        "  - Deep models with different combinations of: token  embeddings, character embeddings, pretrained embeddings, positional embeddings\n",
        "- Building our first multimodal model (taking multiple types of data inputs).\n",
        "  - Replicating the model architecture from [paper](https://arxiv.org/pdf/1612.05251.pdf)\n",
        "- Find the most wrong predictions\n",
        "- Making predictions on PubMed abstracts from the wild"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2aTpsv5MIJW"
      },
      "source": [
        "### Get Data \n",
        "Let's download the PubMed 200k PCT data. \n",
        "https://github.com/Franck-Dernoncourt/pubmed-rct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOB0c4aOhZ4W",
        "outputId": "70fa4f9b-7fa8-4c5a-a906-e116bcc03d67"
      },
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'pubmed-rct' already exists and is not an empty directory.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X11jn_SZhcI5"
      },
      "source": [
        "\n",
        "Checking the contents of the downloaded repository, you can see there are four folders.\n",
        "\n",
        "Each contains a different version of the PubMed 200k RCT dataset.\n",
        "\n",
        "Looking at the README file from the GitHub page, we get the following information:\n",
        "\n",
        "\n",
        "- PubMed 20k is a subset of PubMed 200k. I.e., any abstract present in PubMed 20k is also present in PubMed 200k.\n",
        "- PubMed_200k_RCT is the same as PubMed_200k_RCT_numbers_replaced_with_at_sign, except that in the latter all numbers had been replaced by @. (same for PubMed_20k_RCT vs. - PubMed_20k_RCT_numbers_replaced_with_at_sign).\n",
        "- Since Github file size limit is 100 MiB, we had to compress PubMed_200k_RCT\\train.7z and PubMed_200k_RCT_numbers_replaced_with_at_sign\\train.zip. To uncompress train.7z, you may use 7-Zip on Windows, Keka on Mac OS X, or p7zip on Linux.\n",
        "\n",
        "To begin with, the dataset we're going to be focused on is PubMed_20k_RCT_numbers_replaced_with_at_sign.\n",
        "\n",
        "Why this one?\n",
        "\n",
        "Rather than working with the whole 200k dataset, we'll keep our experiments quick by starting with a smaller subset. We could've chosen the dataset with numbers instead of having them replaced with @ but we didn't.\n",
        "Let's check the file contents.\n",
        "\n",
        "- Paper for Modelling : https://arxiv.org/abs/1612.05251\n",
        "- Application paper: https://arxiv.org/abs/1710.06071\n",
        "\n",
        "**Problem in a sentence**\n",
        "\n",
        "The number of RCT papers released is continuing to increase, those without structured abstracts can be hard to read and in turn slow down researchers moving through the literature.\n",
        "\n",
        "**Solution in a sentence**\n",
        "\n",
        "Create an NLP model to classify abstract sentences into the role they play (e.g. objective, methods, results, etc) to enable researchers to skim through the literature (hence SkimLit ðŸ¤“ðŸ”¥) and dive deeper when necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYd49SCfmcEu",
        "outputId": "a570fbfc-92f2-4456-b0ae-2854cbbbc0ae"
      },
      "source": [
        "# Check what files are in the PubMed_20k dataset \n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKfCPURez8hs",
        "outputId": "34f58d71-21c9-4c5d-cbf8-4797aed01272"
      },
      "source": [
        "# # Start our experiments using thhe 20K dataset with numbers replaced by '@' sign\n",
        "data_dir = 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/'\n",
        "\n",
        "# Check all of the filenames in the target direcotry \n",
        "import os \n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cULq2iAkz8wd"
      },
      "source": [
        "## Preprocess data \n",
        "\n",
        "Now we've got some text data, it's time to become one with it. \n",
        "And one of the best ways to become one with the data is to... \n",
        "\n",
        "> Visualize , Visualize , visualize....\n",
        "\n",
        "So with that in mind, lets write a function to read in all of the lines of a target text file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sH3TbbP69Ow"
      },
      "source": [
        "# Create function to read the lines of a document \n",
        "def get_lines(filename):\n",
        "  '''\n",
        "  Reads filename (a text filename) adn returns the line of text as a list. \n",
        "\n",
        "  Args: \n",
        "    filename: a string containing the target filepth \n",
        "\n",
        " Returns: \n",
        "  A list of stings with one string per line from the target filename\n",
        "  '''\n",
        "  with open(filename , 'r') as f: \n",
        "    return f.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV3wVQU17ikr",
        "outputId": "d4e10613-c47f-4913-b864-9cd1e3f94214"
      },
      "source": [
        "# Using our function , lets read in training lines \n",
        "train_lines = get_lines(data_dir + 'train.txt') # read the lines within the training file \n",
        "train_lines[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RGOZ-MY7v2_"
      },
      "source": [
        "We can't pass this train lines straight into our model because they are quite messy and our model will start to learning something irrelavant. \n",
        "\n",
        "But we can turn this lines into our desired way from which our model can learn. \n",
        "- Every new abstract starts with a **###somenumbers** so we can differentiate between different abstracts through this.\n",
        "- And every label is at the starting line of the sentence, for instance **OBJECTIVE , METHODS** these are present at the very starting line of a sentence.\n",
        "- Each abstract ends with an **\\n** new line command.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK1ADq5h9Dyh"
      },
      "source": [
        "Lets think about how we want our data to look...\n",
        "\n",
        "How the data would be best represented? \n",
        "\n",
        "```\n",
        "[{'line_number': 0,\n",
        "  'target': 'OBJECTIVE',\n",
        "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
        "  'total_lines': 11},\n",
        "  ...]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJl6Gy0Y-KYF",
        "outputId": "70c35c88-ada6-4261-8d56-02397d073cc2"
      },
      "source": [
        "# Number of lines \n",
        "len(train_lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210040"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM2TL1Va0yCM"
      },
      "source": [
        "Let's write a function to perform the following steps:\n",
        "\n",
        "- Take a target file of abstract samples.\n",
        "- Read the lines in the target file.\n",
        "- For each line in the target file:\n",
        "  - If the line begins with ### mark it as an abstract ID and the beginning of a new abstract.\n",
        "    - Keep count of the number of lines in a sample.\n",
        "  - If the line begins with \\n mark it as the end of an abstract sample.\n",
        "    - Keep count of the total lines in a sample.\n",
        "  - Record the text before the \\t as the label of the line.\n",
        "  - Record the text after the \\t as the text of the line.\n",
        "- Return all of the lines in the target text file as a list of dictionaries containing the key/value pairs:\n",
        "- \"line_number\" - the position of the line in the abstract (e.g. 3).\n",
        "- \"target\" - the role of the line in the abstract (e.g. OBJECTIVE).\n",
        "- \"text\" - the text of the line in the abstract.\n",
        "- \"total_lines\" - the total lines in an abstract sample (e.g. 14).\n",
        "- Abstract ID's and newlines should be omitted from the returned preprocessed data.\n",
        "\n",
        "\n",
        "Example returned preprocessed sample (a single line from an abstract):\n",
        "\n",
        "```\n",
        "[{'line_number': 0,\n",
        "  'target': 'OBJECTIVE',\n",
        "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
        "  'total_lines': 11},\n",
        "  ...]\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW6Y8KZ9-y30"
      },
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"Returns a list of dictionaries of abstract line data.\n",
        "\n",
        "  Takes in filename, reads its contents and sorts through each line,\n",
        "  extracting things like the target label, the text of the sentence,\n",
        "  how many sentences are in the current abstract and what sentence number\n",
        "  the target line is.\n",
        "\n",
        "  Args:\n",
        "      filename: a string of the target text file to read and extract line data\n",
        "      from.\n",
        "\n",
        "  Returns:\n",
        "      A list of dictionaries each containing a line from an abstract,\n",
        "      the lines label, the lines position in the abstract and the total number\n",
        "      of lines in the abstract where the line is from. For example:\n",
        "\n",
        "      [{\"target\": 'CONCLUSION',\n",
        "        \"text\": The study couldn't have gone better, turns out people are kinder than you think\",\n",
        "        \"line_number\": 8,\n",
        "        \"total_lines\": 8}]\n",
        "  \"\"\"\n",
        "  input_lines = get_lines(filename) # get all lines from filename\n",
        "  abstract_lines = \"\" # create an empty abstract\n",
        "  abstract_samples = [] # create an empty list of abstracts\n",
        "  \n",
        "  # Loop through each line in target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"): # check to see if line is an ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" # reset abstract string\n",
        "    elif line.isspace(): # check to see if line is a new line\n",
        "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
        "\n",
        "      # Iterate through each line in abstract and count them at the same time\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # create empty dict to store data from line\n",
        "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
        "        line_data[\"target\"] = target_text_split[0] # get target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
        "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
        "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
        "    \n",
        "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
        "      abstract_lines += line\n",
        "  return abstract_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2bzWXOd0wBB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2450b371-761b-4fe4-be0f-4f5c04f69e29"
      },
      "source": [
        "# Using the above function on our data samples\n",
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") \n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "\n",
        "print(len(train_samples), len(val_samples), len(test_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "180040 30212 30135\n",
            "CPU times: user 561 ms, sys: 108 ms, total: 669 ms\n",
            "Wall time: 680 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j3_OS7z1Qnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90fdfdaa-3662-46a5-d314-0e0f1021d541"
      },
      "source": [
        "# Check the first abstract of our training data\n",
        "train_samples[:14]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'line_number': 0,\n",
              "  'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 1,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 2,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 3,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 4,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 5,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 6,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 7,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 8,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 9,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 10,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 11,\n",
              "  'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 0,\n",
              "  'target': 'BACKGROUND',\n",
              "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
              "  'total_lines': 10},\n",
              " {'line_number': 1,\n",
              "  'target': 'BACKGROUND',\n",
              "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
              "  'total_lines': 10}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7G0FI5Z1TsG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "d37b282f-9c43-4e87-8984-2e452b288fff"
      },
      "source": [
        "# Turning our dictionary into a DataFrame for better visualization\n",
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head(14)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         target  ... total_lines\n",
              "0     OBJECTIVE  ...          11\n",
              "1       METHODS  ...          11\n",
              "2       METHODS  ...          11\n",
              "3       METHODS  ...          11\n",
              "4       METHODS  ...          11\n",
              "5       METHODS  ...          11\n",
              "6       RESULTS  ...          11\n",
              "7       RESULTS  ...          11\n",
              "8       RESULTS  ...          11\n",
              "9       RESULTS  ...          11\n",
              "10      RESULTS  ...          11\n",
              "11  CONCLUSIONS  ...          11\n",
              "12   BACKGROUND  ...          10\n",
              "13   BACKGROUND  ...          10\n",
              "\n",
              "[14 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fPx0p201ZyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02dd81bb-21cb-45a0-f635-3955d2e4fe39"
      },
      "source": [
        "# Distributions of labels (checking the balance spread of our labels)\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "uIWxXBtd16Jf",
        "outputId": "e44736da-5575-4441-d813-59eef91a227f"
      },
      "source": [
        "# Distribution of our abstract length (spread of the abstract lines)\n",
        "train_df.total_lines.plot.hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe9a6b22b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l-DFRdF2FRc"
      },
      "source": [
        "It looks like most of the abstracts are around 7 to 15 sentences in length. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W29uO-r2V17"
      },
      "source": [
        "### Get a list of sentences \n",
        "\n",
        "While building a model the main inputs will be a list of strings (the line of the abstract). \n",
        "\n",
        "Lets get that lines from our dataframe by calling `tolist()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab1oQMVx2kf8",
        "outputId": "ccb0000f-5018-4117-a6df-10c76b6c05f7"
      },
      "source": [
        "# Convert abstract text lines from df to a lists \n",
        "train_sentences = train_df['text'].to_list()\n",
        "val_sentences = val_df['text'].to_list()\n",
        "test_sentences = test_df['text'].to_list()\n",
        "\n",
        "# Printing the shapes of the sentences \n",
        "print(len(train_sentences) , len(val_sentences) , len(test_sentences) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "180040 30212 30135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFzIQf2T3CTR",
        "outputId": "9b58a1fc-f745-4489-abfa-e66f899fd5f6"
      },
      "source": [
        "# View the first 10 lines of the training sentences \n",
        "train_sentences[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpYrRcv93bMY"
      },
      "source": [
        "## Make Numeric Labels (convert our labels into numbers) \n",
        "\n",
        "We will be building two types of methods: \n",
        "- One hot encoding --> For the TensorFlow \n",
        "- Label Encoder --> For the Baseline (w/o tensorflow)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMq7DDSO5KVN",
        "outputId": "82acf776-9e1b-4285-bd88-e5991a0f62ed"
      },
      "source": [
        "# One hot encode labels \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Instantiating as a method \n",
        "one_hot_encoder = OneHotEncoder(sparse = False)\n",
        "\n",
        "# Performing One hot encoding to our labels \n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df['target'].to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df['target'].to_numpy().reshape(-1 , 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df['target'].to_numpy().reshape(-1 , 1))\n",
        "\n",
        "# Checking the length \n",
        "print(len(train_labels_one_hot) , len(val_labels_one_hot) , len(test_labels_one_hot))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "180040 30212 30135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21AvZTVb5VUV",
        "outputId": "2a2539d1-1cfd-45cb-84be-8f039e5b9504"
      },
      "source": [
        "# Checking a example of our. train labels one hot encoded \n",
        "train_labels_one_hot[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtfoOEoX6wdM"
      },
      "source": [
        "### Label encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRTE89Zo63yZ",
        "outputId": "94361847-1f82-4cf2-bf54-23589395ac1d"
      },
      "source": [
        "# Extract labels ('target' columns) and encode them into integers \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Instantiating a method \n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df['target'].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df['target'].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df['target'].to_numpy())\n",
        "\n",
        "# Check how the training labels looks like \n",
        "train_labels_encoded"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_I2SOqn7S-t"
      },
      "source": [
        "A great functionality of `LabelEncoder` is we can get the class names and number of classes using the `classes_attribute`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2WH41W_8OZ1",
        "outputId": "7ae1b9bd-dbcc-4414-96da-ee733c7e78ba"
      },
      "source": [
        "# Get class names and number of classes from LabelEncoder instance \n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "\n",
        "# Looking inside how it looks like\n",
        "num_classes , class_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsnqnBEL8dT4"
      },
      "source": [
        "## **Creating a series of model experiments**\n",
        "\n",
        "We've preprocessed our data, so the next step would be performing some series of modelling experiments. \n",
        "\n",
        "At first like always let's build a baseline model and obtain a score from that. Then we'll try to beast that score by building more and more complex models. \n",
        "\n",
        "For each model, we'll train it on the training data and evaluate on the validation data.\n",
        "\n",
        "### Model 0: Getting a baseline \n",
        "\n",
        "Our first model will be a TF-IDF Multinomial Naive Bayes. For this we will create a Scikit-learn Pipeline which uses the `TfidVectorizer` class to convert our abstract sentences to number using the **TF-IDF** algorithm and then learns to classify our sentences using the `MultiNomial` algorithm. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBA7pYEe-QTb",
        "outputId": "f299ccc1-72f6-403a-9d89-5a1973cbd768"
      },
      "source": [
        "# Building a sklearn Pipeline for our baseline model \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Creating a pipeline \n",
        "model_0 = Pipeline([\n",
        "  ('tf-idf', TfidfVectorizer()), \n",
        "  ('clf' , MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(X = train_sentences , \n",
        "            y = train_labels_encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tf-idf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMVOq2cMCcWn",
        "outputId": "84fcfd04-f30c-42ce-f959-28f61499c290"
      },
      "source": [
        "# Evaluating our baseline model on the validation data \n",
        "model_0.score(X = val_sentences, \n",
        "              y = val_labels_encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7218323844829869"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd12HF_Q-otz",
        "outputId": "7daafa8d-9bff-41ba-b06a-d59dd8549da7"
      },
      "source": [
        "# Making predictions on the val sentences\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, ..., 4, 4, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmNh2aAlDOSt"
      },
      "source": [
        "# Creating a function to calculate the evaluation metircs \n",
        "\n",
        "def calculate_metrics(y_true , y_preds):\n",
        "  '''\n",
        "  Arguments: \n",
        "  y_true --> true labels of the data \n",
        "  y_preds --> predicted labels of the data \n",
        "\n",
        "  Returns: \n",
        "  A dictionary of evaluation metrics like precision , recall and f1_score\n",
        "  '''\n",
        "\n",
        "  # Let's first import the needed metrics \n",
        "  from sklearn.metrics import precision_score , f1_score , accuracy_score , recall_score\n",
        "\n",
        "  # Creting the metrics \n",
        "  accuracy = accuracy_score(y_true , y_preds)\n",
        "  f1_score = f1_score(y_true , y_preds , average = 'weighted')\n",
        "  precision = precision_score(y_true , y_preds , average = 'weighted')\n",
        "  recall = recall_score(y_true , y_preds , average = 'weighted')\n",
        "\n",
        "  # Now will create a dictionary of these metrics and pack them\n",
        "  evaluation_dict = {'Accuracy:': accuracy * 100 , \n",
        "                     'F1_Score: ': f1_score , \n",
        "                     'Precision: ': precision , \n",
        "                     'Recall: ': recall }\n",
        "\n",
        "  # Return our dictionary \n",
        "  return evaluation_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPbakPVAEMk8"
      },
      "source": [
        "`macro` --> Insensitive to the label imabalance \n",
        "`micro` --> takes in account of the fp,fn etc.. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmOAuHRSDlIv",
        "outputId": "fb247fff-9208-4c5b-b59b-fc29120acf22"
      },
      "source": [
        "# Getting the evaluation metrics dict for our model \n",
        "baseline_results = calculate_metrics(val_labels_encoded , baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 72.1832384482987,\n",
              " 'F1_Score: ': 0.6989250353450294,\n",
              " 'Precision: ': 0.7186466952323352,\n",
              " 'Recall: ': 0.7218323844829869}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Kl7lj3pFdHW"
      },
      "source": [
        "Thats great! We got our baseline results now lets do some more preprocessing works on our data so we can build a deep sequence model with it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9oH2BaQGjKs"
      },
      "source": [
        "## Preparing our data for deep sequence models \n",
        "\n",
        "Before we start building deep models we gotta create vectorization and Embedding layers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0JK5738G8XO"
      },
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import layers "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFSj9ygkHCLT"
      },
      "source": [
        "Before jumping into the modelling we have to do some analysis on our data so that it will be quite appropriate for us to converting our text into numbers. \n",
        "\n",
        "Its a good idea to figure out how many words are in each sentence. Because when our model goes through our sentences, it **works best when they're all at the same length (crucial for creating batches).** \n",
        "\n",
        "> For example, if one sentence is eight words long and another in 29 words long, we want to pad the eight word sentence with zeros so it ends up being the same length as the 29 word sentence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILAT2BIIH5c6",
        "outputId": "07a153f8-1609-4b62-b5d3-ce6ffe1006d7"
      },
      "source": [
        "# How long is each sentence on average? (spread of sentence len)\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "\n",
        "# Taking average of the sentence lens \n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "UEVAhj-GILqM",
        "outputId": "7163ef3c-8b63-4c01-9718-733aece61617"
      },
      "source": [
        "# Whats the distribution look like? \n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens , bins = 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([4.2075e+04, 8.3771e+04, 3.6877e+04, 1.0945e+04, 3.9310e+03,\n",
              "        1.4450e+03, 5.6000e+02, 2.2600e+02, 1.0100e+02, 4.5000e+01,\n",
              "        2.0000e+01, 1.2000e+01, 9.0000e+00, 1.0000e+01, 6.0000e+00,\n",
              "        2.0000e+00, 3.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00]),\n",
              " array([  1.  ,  15.75,  30.5 ,  45.25,  60.  ,  74.75,  89.5 , 104.25,\n",
              "        119.  , 133.75, 148.5 , 163.25, 178.  , 192.75, 207.5 , 222.25,\n",
              "        237.  , 251.75, 266.5 , 281.25, 296.  ]),\n",
              " <a list of 20 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4z0ewBLIqoQ"
      },
      "source": [
        "Our vast majority of sentence lengths are between 0 to 50 tokens in length. It would be ideal if we pad all the sentences to 50. \n",
        "\n",
        "Lets see in % to find the value which covers 95% of the sentence lengths. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwFMk7_NJMu6",
        "outputId": "1811c9a9-7cff-4ab4-b341-63c1fce1d7ae"
      },
      "source": [
        "# How long a sentence covers 95% of the lengths? \n",
        "output_seq_len = int(np.percentile(sent_lens , 95))\n",
        "output_seq_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lAOmkfHJkdO"
      },
      "source": [
        "It seems the 95% of the sentences in our training set have a length of 55 tokens or less. \n",
        "\n",
        "When we create our tokenization layer, we will use this value to turn all our sentences into the same length. \n",
        "\n",
        "That means sentences with a length below 55 get padded with zeros and sentences with a length above 55 get truncated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iv7BUAYJ2Oe",
        "outputId": "6750168b-f03e-4367-b31a-4faa4e1afc24"
      },
      "source": [
        "# Maximum seq lenght in our training set \n",
        "max(sent_lens) # Something is 296 words long "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-PrYB5KKTpU"
      },
      "source": [
        "#### Create a text vectorizer layer \n",
        "Now we got some infos abour our data we can now turn our text into numbers.\n",
        "\n",
        "The first step we would do is turning our texts into tokens by using the text_vectorizer layer from TensorFlow. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zow_ErkLKaJ"
      },
      "source": [
        "# Creating a text vectorizer layer \n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Variables for our text vectorizer layer \n",
        "max_vocab = 68000 # from the paper (taken from 3.2 in https://arxiv.org/pdf/1710.06071.pdf)\n",
        "\n",
        "# Creating the layer \n",
        "text_vectorizer = TextVectorization(max_tokens= max_vocab , \n",
        "                                    output_sequence_length = output_seq_len , \n",
        "                                    output_mode = 'int')\n",
        "\n",
        "# Calling the adapt method on our train sentences so our inherits the texts \n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfFnEms7L0O5"
      },
      "source": [
        "![Screenshot 2021-07-17 at 7.31.57 AM.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1DtE6RAM8vs",
        "outputId": "9a1d0f64-123e-458a-d819-13beec037f10"
      },
      "source": [
        "# Looking into our test vectorizer \n",
        "import random \n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f'Text:\\n {target_sentence}')\n",
        "print(f'\\nLength of text: {len(target_sentence.split())}')\n",
        "print(f'\\nVectorized text:\\n {text_vectorizer([target_sentence])}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text:\n",
            " harmonic dissection yielded better outcomes compared to electrocautery with lower estimated blood loss ( @ @ vs. @ @ , p < @ ) , less drain volume ( @ @ ml vs. @ @ ml , p < @ ) , fewer drain days ( @ @ vs. @ @ , p < @ ) , less seroma formation ( @ vs. @ % , p = @ ) , and less postoperative pain -lsb- median ( interquartile range ) @ ( @-@ ) vs. @ ( @-@ ) , p < @ -rsb- , whereas mean operative time ( @ @ vs. @ @ min , p = @ ) and ssi ( @ vs. @ % , p = @ ) did not differ .\n",
            "\n",
            "Length of text: 128\n",
            "\n",
            "Vectorized text:\n",
            " [[7691 2756 2392  252   75   34    6 7374    7  105  597  107  264   44\n",
            "    14  211 3483  326  364   44  364   14  704 3483   84   44   14  211\n",
            "  5324 1931   44   14    3  211  163   65   46  193 1521  283   44   14\n",
            "    45  436   57 1216   63   44  242   14    3 4011   44   14  112]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecyw3bfWRo9j",
        "outputId": "272adc1c-cff2-4565-8862-b58d88b76084"
      },
      "source": [
        "# How many words in our training vocabulary \n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary() \n",
        "\n",
        "# Printing the top 5 and least 5 \n",
        "print(f\"Number of words in vocabulary: {len(rct_20k_text_vocab)}\"), \n",
        "print(f\"Most common words in the vocabulary: {rct_20k_text_vocab[:5]}\")\n",
        "print(f\"Least common words in the vocabulary: {rct_20k_text_vocab[-5:]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocabulary: 64841\n",
            "Most common words in the vocabulary: ['', '[UNK]', 'the', 'and', 'of']\n",
            "Least common words in the vocabulary: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FhCiTzYNym5",
        "outputId": "567f417d-2213-426d-c0a8-07a6209e63e1"
      },
      "source": [
        "# Configuratio of our Text vectorizer \n",
        "text_vectorizer.get_config()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dtype': 'string',\n",
              " 'max_tokens': 68000,\n",
              " 'name': 'text_vectorization_2',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'split': 'whitespace',\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'trainable': True,\n",
              " 'vocabulary_size': 64841}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrJj90k1ONeI"
      },
      "source": [
        "#### Create a custom text embedding \n",
        "\n",
        "Out `text_vectorization` helps to map the words in our text directly to numbers but yet it doesn't necessarily caputre the relationships between those numbers. \n",
        "\n",
        "We use **embedding**, to create a richer numerical representation of our text. \n",
        "\n",
        "As our model learns by going through the test, it will update its embedding to better represent the relationships betwen the tokens in our corpus (vocab).\n",
        "\n",
        "The main parameter we're concerned here is the input_dim and output_dim of our Embedding layer. \n",
        "\n",
        "- `input_dim` --> defines the size of our vocabulary \n",
        "- `output_dim` --> defines the dimensions of the embedding output. \n",
        "\n",
        "Our embedding layer will take the integer outputs of our text_vectorization layer as inputs and convert them to feature vectors of size `output_dim`\n",
        "\n",
        "**Links**: \n",
        "- https://stackoverflow.com/questions/47485216/how-does-mask-zero-in-keras-embedding-layer-work/61102319#61102319\n",
        "- https://www.tensorflow.org/guide/keras/masking_and_padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYgJOX1-TigD"
      },
      "source": [
        "# Create a token embedding layer \n",
        "token_embed = layers.Embedding(input_dim= len(rct_20k_text_vocab) , \n",
        "                               output_dim = 128  , # different embedding sizes result in drastically different numbers of parameters to train\n",
        "                               mask_zero = True, \n",
        "                               name ='token_embedding')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loSVKn7eU6cU",
        "outputId": "90b14295-b0ff-42c4-f8d1-da910f0ae884"
      },
      "source": [
        "# Show example embedding\n",
        "print(f\"Sentence before vectorization:\\n{target_sentence}\\n\")\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f\"Sentence after vectorization (before embedding):\\n{vectorized_sentence}\\n\")\n",
        "embedded_sentence = token_embed(vectorized_sentence)\n",
        "print(f\"Sentence after embedding:\\n{embedded_sentence}\\n\")\n",
        "print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence before vectorization:\n",
            "harmonic dissection yielded better outcomes compared to electrocautery with lower estimated blood loss ( @ @ vs. @ @ , p < @ ) , less drain volume ( @ @ ml vs. @ @ ml , p < @ ) , fewer drain days ( @ @ vs. @ @ , p < @ ) , less seroma formation ( @ vs. @ % , p = @ ) , and less postoperative pain -lsb- median ( interquartile range ) @ ( @-@ ) vs. @ ( @-@ ) , p < @ -rsb- , whereas mean operative time ( @ @ vs. @ @ min , p = @ ) and ssi ( @ vs. @ % , p = @ ) did not differ .\n",
            "\n",
            "Sentence after vectorization (before embedding):\n",
            "[[7691 2756 2392  252   75   34    6 7374    7  105  597  107  264   44\n",
            "    14  211 3483  326  364   44  364   14  704 3483   84   44   14  211\n",
            "  5324 1931   44   14    3  211  163   65   46  193 1521  283   44   14\n",
            "    45  436   57 1216   63   44  242   14    3 4011   44   14  112]]\n",
            "\n",
            "Sentence after embedding:\n",
            "[[[ 0.04608295  0.03181722  0.02956503 ... -0.00966995  0.0206647\n",
            "    0.03075958]\n",
            "  [ 0.0412221   0.04581087 -0.04744446 ...  0.04176444 -0.02133009\n",
            "   -0.04959428]\n",
            "  [ 0.00746019  0.00584238  0.04975094 ... -0.02359192  0.00983846\n",
            "   -0.00805968]\n",
            "  ...\n",
            "  [ 0.00061397 -0.0100312  -0.01510943 ...  0.04561129 -0.04999847\n",
            "   -0.02336743]\n",
            "  [ 0.00048957  0.0387496  -0.01483753 ... -0.0278366  -0.00150012\n",
            "    0.00517495]\n",
            "  [ 0.00242255 -0.01890887 -0.0283895  ... -0.00305903  0.0414752\n",
            "    0.00540312]]]\n",
            "\n",
            "Embedded sentence shape: (1, 55, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19qveu5_U8nI"
      },
      "source": [
        "Our each vector will be the size of 128 long vectors. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tufvs6MVGyB"
      },
      "source": [
        "#### Create datasets (as fast as possible) \n",
        "\n",
        "Now its time to pack our texts into datasets to be used with a ml model, now we will look into some methods to make the process faster. \n",
        "\n",
        "- We will use a `PrefetchDataset` of batches (will use prefetch). Doing so we'll ensure TensorFlow loads our data onto the GPU as fast as possible, so faster training time. \n",
        "- We will use `batch()` and `prefetch()`and `tf.data.AutoTune` will help us to determine optimal amount of compute to use to prepare datasets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G4nB2j8WvRB",
        "outputId": "725db467-ac46-4b82-a2c5-f83354ec4f4c"
      },
      "source": [
        "# Turn our data into TensorFlow Datasets \n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences , train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences , val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences , test_labels_one_hot))\n",
        "\n",
        "# Looking into our train dataset \n",
        "train_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((), (5,)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vHzSbMUXiH3",
        "outputId": "5f617c1b-24a3-4b1e-960b-0f266ee44f8e"
      },
      "source": [
        "# Applying batch and prefetch on our dataset \n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaiiGXvQYA5h"
      },
      "source": [
        "### Model 1: Conv1D with token embeddings \n",
        "\n",
        "So far we got everything we needed to model our data. Our deep models will follow a similar structure: \n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "```\n",
        "We will be changing some Layers components, because the modern deep NLP models requires text to be converted into embedding before meaningful patterns can be discovered within. \n",
        "\n",
        "The first model we're going to build is a 1-dimensional Convolutional Neural Networks. And we will follow the below workflow: \n",
        "- Build Model \n",
        "- Train Model \n",
        "- Evaluate model (make preds and compare with the ground truth). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPuaYRAaZFre",
        "outputId": "3dd1c435-12c2-4f05-9b07-4fc299465598"
      },
      "source": [
        "# Building the Conv1D model to process sequences \n",
        "inputs = layers.Input(shape = (1, ),  dtype= tf.string)\n",
        "\n",
        "# Preprocessing layers \n",
        "text_vectors = text_vectorizer(inputs) # vectorize text inputs \n",
        "token_embeddings = token_embed(text_vectors) # create embedding \n",
        "\n",
        "# Conv1D layer \n",
        "x = layers.Conv1D(filters= 64 , kernel_size= 5 , padding= 'same' , activation= 'relu')(token_embeddings)\n",
        "x = layers.GlobalMaxPooling1D()(x) # condense the output of our feature vector(patterns learned by our model)\n",
        "\n",
        "# output layer \n",
        "outputs = layers.Dense(num_classes , activation= 'softmax')(x)\n",
        "\n",
        "# Packing into a model \n",
        "model_1 = tf.keras.Model(inputs , outputs)\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss = tf.keras.losses.CategoricalCrossentropy() , # because of one hot encoded labels\n",
        "                optimizer = tf.keras.optimizers.Adam() , \n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "# Summary of our model \n",
        "model_1.summary()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_2 (TextVe (None, 55)                0         \n",
            "_________________________________________________________________\n",
            "token_embedding (Embedding)  (None, 55, 128)           8299648   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 55, 64)            41024     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 8,340,997\n",
            "Trainable params: 8,340,997\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIz2M3lzbHio"
      },
      "source": [
        "By looking at the model summary we can notice the majority of the trainable parameters are within the embedding layer. And if we're to increase the size of the embedding layer (output_dim) the number of trainable parameters would increase dramatically. \n",
        "\n",
        "We will use only the first 10% of batches (about 18k samples) of the training set to train and first 10% of batches from the validation set to validate on. \n",
        "\n",
        "> **ðŸ”‘ Note:** It's a standard practice in machine learning to test your models on smaller subsets of data first to make sure they work before scaling them to larger amounts of data. You should aim to run many smaller experiments rather than only a handful of large experiments. And since your time is limited, one of the best ways to run smaller experiments is to reduce the amount of data you're working with (10% of the full dataset is usually a good amount, as long as it covers a similar distribution)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYCJZBUSi5y5"
      },
      "source": [
        "We are conduction experiments on our data so we train only on 10% of the data. This is to ensure we speed up our experimentation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMUh7eaVixj1",
        "outputId": "f0edc62f-2374-4518-b5b4-16c014f20d96"
      },
      "source": [
        "int(0.1 * len(train_dataset)) * 32 # Num of samples"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17984"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1F0yYXQcE8i",
        "outputId": "776e884b-68e6-4132-e2e5-80d94c3e4f07"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_dataset)), # only fit on 10% of batches for faster training time\n",
        "                              epochs=3,\n",
        "                              validation_data=valid_dataset,\n",
        "                              validation_steps=int(0.1 * len(valid_dataset))) # only validate on 10% of batches"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 59s 103ms/step - loss: 0.8221 - accuracy: 0.6912 - val_loss: 0.5865 - val_accuracy: 0.7793\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 57s 102ms/step - loss: 0.5805 - accuracy: 0.7866 - val_loss: 0.5426 - val_accuracy: 0.8009\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 57s 101ms/step - loss: 0.5468 - accuracy: 0.7979 - val_loss: 0.5224 - val_accuracy: 0.8049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oux3QI3GcqaD",
        "outputId": "1c41a4aa-9961-46da-c779-25f4a4956ac2"
      },
      "source": [
        "# Evaluate the model on a whole validation dataset \n",
        "model_1.evaluate(valid_dataset)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "945/945 [==============================] - 5s 6ms/step - loss: 0.5220 - accuracy: 0.8062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.521992564201355, 0.8061697483062744]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTrEsCOndg8Q",
        "outputId": "57c2510d-e5b5-4722-c882-d11e9842e284"
      },
      "source": [
        "# Make predictions (our model outputs prediction probabilties for each class)\n",
        "model_1_pred_probs = model_1.predict(valid_dataset)\n",
        "model_1_pred_probs"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.1249566e-01, 5.0017785e-02, 1.2031391e-03, 3.3473432e-01,\n",
              "        1.5490730e-03],\n",
              "       [3.2144207e-01, 4.9921387e-01, 2.8989129e-03, 1.7237091e-01,\n",
              "        4.0741889e-03],\n",
              "       [1.7884278e-01, 4.9045412e-03, 2.3070378e-03, 8.1376898e-01,\n",
              "        1.7660666e-04],\n",
              "       ...,\n",
              "       [1.9383601e-04, 1.9397850e-03, 2.5724567e-02, 1.6585793e-04,\n",
              "        9.7197592e-01],\n",
              "       [2.5381109e-02, 2.9809108e-01, 3.5480879e-02, 2.3255002e-02,\n",
              "        6.1779189e-01],\n",
              "       [3.1883635e-02, 9.5560461e-01, 3.0067882e-03, 3.1053110e-03,\n",
              "        6.3996580e-03]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNijRwemdtnA",
        "outputId": "1e6cf25f-15fc-4b10-e0bd-c79e71b7b78e"
      },
      "source": [
        "# Converting our pred probs to class preds \n",
        "model_1_preds = tf.argmax(model_1_pred_probs , axis = 1)\n",
        "model_1_preds"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as_tWwwDecAJ",
        "outputId": "e07d8027-16cb-4fd0-8a8a-9f793eaa3902"
      },
      "source": [
        "# Calculate the model 1 results \n",
        "model_1_results = calculate_metrics(val_labels_encoded , \n",
        "                                    model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 80.61697338805772,\n",
              " 'F1_Score: ': 0.8041872143530673,\n",
              " 'Precision: ': 0.8038125441096377,\n",
              " 'Recall: ': 0.8061697338805772}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2glunOYjo33",
        "outputId": "3d384ad0-67c2-4b12-f9e2-824c93b9e004"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 72.1832384482987,\n",
              " 'F1_Score: ': 0.6989250353450294,\n",
              " 'Precision: ': 0.7186466952323352,\n",
              " 'Recall: ': 0.7218323844829869}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_1LyX2ejMhr"
      },
      "source": [
        "### Model 2: Feature extraction with pretrained token embeddings \n",
        "\n",
        "Rather using a Conv1D model let's use a pretrained token embedding from the Tensorflow Hub. \n",
        "\n",
        "The model structure will look like this: \n",
        "\n",
        "```\n",
        "Inputs (string) -> Pretrained embeddings from TensorFlow Hub (Universal Sentence Encoder) -> Layers -> Output (prediction probabilities)\n",
        "```\n",
        "\n",
        "> **ðŸ”‘ Note:** We could use GloVe embeddings as per the paper but since we're working with TensorFlow, we'll use what's available from TensorFlow Hub (GloVe embeddings aren't). We'll save [using pretrained GloVe embeddings](https://keras.io/examples/nlp/pretrained_word_embeddings/) as an extension.\n",
        "\n",
        "\n",
        "But we dont have a Glove embedding in our TensorFlow Hub, so we will go with our universal  \n",
        "[sentence encoder layer](https://tfhub.dev/google/universal-sentence-encoder/4) as our pretrained token embedding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6euY4Eekmcv"
      },
      "source": [
        "# Download pretrained TensorFlow Hub USE\n",
        "import tensorflow_hub as hub \n",
        "tf_hub_embedding_layer = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4' , \n",
        "                                        trainable = False , \n",
        "                                        name = 'universal_sentence_encoder')"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3YWEucamZ8V",
        "outputId": "8321065b-53b0-4b2e-a8f6-3e47d0cfaab8"
      },
      "source": [
        "# Test out the embedding on a random sentence\n",
        "random_training_sentence = random.choice(train_sentences)\n",
        "print(f\"Random training sentence:\\n{random_training_sentence}\\n\")\n",
        "use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])\n",
        "print(f\"Sentence after embedding:\\n{use_embedded_sentence[0][:30]} (truncated output)...\\n\")\n",
        "print(f\"Length of sentence embedding:\\n{len(use_embedded_sentence[0])}\")"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random training sentence:\n",
            "to assess efficacy and safety of lixisenatide once-daily versus placebo in type @ diabetes mellitus ( t@dm ) patients inadequately controlled on sulfonylurea ( su ) metformin .\n",
            "\n",
            "Sentence after embedding:\n",
            "[ 0.02635027 -0.05228478 -0.03472503 -0.03141569  0.00064189  0.02912895\n",
            " -0.06614345 -0.04045834  0.00481357  0.018817    0.07683027 -0.06321398\n",
            "  0.03047598  0.04579177 -0.04374629 -0.03262419 -0.07693796 -0.04200216\n",
            " -0.05257654  0.00819501  0.06093007  0.03953037  0.02442538 -0.05653007\n",
            "  0.06417734  0.00906013  0.0451041   0.05417657 -0.01227856 -0.01259714] (truncated output)...\n",
            "\n",
            "Length of sentence embedding:\n",
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIWt9mw5muS9"
      },
      "source": [
        "USE module (pretrained embedding) takes care of tokenizing our text for us and outputs 512 dim embedding vector. \n",
        "\n",
        "Now lets build a model with our pretrained embedding layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-szBPeJnEHc",
        "outputId": "6f804b05-c3eb-4537-91fb-ed18aeeaa20a"
      },
      "source": [
        "# Building our model with the feature extraction layer \n",
        "inputs = layers.Input(shape = [] , dtype= tf.string)\n",
        "\n",
        "# Our pretrained embedding layer \n",
        "pretrained_embedding = tf_hub_embedding_layer(inputs)\n",
        "\n",
        "# FC layer \n",
        "x = layers.Dense(128 , activation = 'relu')(pretrained_embedding)\n",
        "outputs = layers.Dense(num_classes , activation= 'softmax')(x)\n",
        "\n",
        "# Packing into a model \n",
        "model_2 = tf.keras.Model(inputs , outputs)\n",
        "\n",
        "# Compile the model \n",
        "model_2.compile(loss = tf.keras.losses.CategoricalCrossentropy() , \n",
        "                optimizer = tf.keras.optimizers.Adam(), \n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "# Sumamry of the model \n",
        "model_2.summary()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None,)]                 0         \n",
            "_________________________________________________________________\n",
            "universal_sentence_encoder ( (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 256,864,133\n",
            "Trainable params: 66,309\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UNvdF0job3I",
        "outputId": "a4a19444-f3d3-465e-da02-f38a7aac10bf"
      },
      "source": [
        "# Fit the feature extractor model for 3 epochs \n",
        "model_2_history = model_2.fit(train_dataset , \n",
        "                              epochs = 3 , \n",
        "                              steps_per_epoch = int(0.1 * len(train_dataset)) , \n",
        "                              validation_data = valid_dataset , \n",
        "                              validation_steps = int(0.1 * len(valid_dataset)))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 9s 14ms/step - loss: 0.9156 - accuracy: 0.6495 - val_loss: 0.8001 - val_accuracy: 0.6875\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 7s 13ms/step - loss: 0.7718 - accuracy: 0.7005 - val_loss: 0.7587 - val_accuracy: 0.7018\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 7s 13ms/step - loss: 0.7568 - accuracy: 0.7109 - val_loss: 0.7433 - val_accuracy: 0.7104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzYPO_SPo5HF",
        "outputId": "9274ef82-f9a1-438d-8a4c-3ca4e7f738cb"
      },
      "source": [
        "# Evaluating our model on the whole valid data \n",
        "model_2.evaluate(valid_dataset)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "945/945 [==============================] - 10s 11ms/step - loss: 0.7453 - accuracy: 0.7109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7452786564826965, 0.7109426856040955]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D9kWAbBpaTE",
        "outputId": "7748aa82-db49-4fd1-b17d-81e723f4bea8"
      },
      "source": [
        "# Make predictions with our feature extraction model \n",
        "model_2_pred_probs = model_2.predict(valid_dataset)\n",
        "model_2_pred_probs"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.4198316e-01, 3.4378499e-01, 2.7465692e-03, 2.0457564e-01,\n",
              "        6.9097024e-03],\n",
              "       [3.1368777e-01, 5.3439915e-01, 4.8623034e-03, 1.4488553e-01,\n",
              "        2.1652456e-03],\n",
              "       [2.4825108e-01, 1.5527861e-01, 2.4195034e-02, 5.3953093e-01,\n",
              "        3.2744419e-02],\n",
              "       ...,\n",
              "       [1.7741235e-03, 6.3353018e-03, 5.2916419e-02, 9.3344296e-04,\n",
              "        9.3804067e-01],\n",
              "       [3.9784648e-03, 4.5391664e-02, 1.9019949e-01, 1.4154935e-03,\n",
              "        7.5901484e-01],\n",
              "       [2.0162354e-01, 2.9017770e-01, 4.4618252e-01, 7.0488988e-03,\n",
              "        5.4967288e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAt4ElTrpj5I",
        "outputId": "7e2cecba-7c52-4197-c7fc-851553833a0b"
      },
      "source": [
        "# Convert the pred probs to class preds \n",
        "model_2_preds = tf.argmax(model_2_pred_probs , axis = 1)\n",
        "model_2_preds"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 2])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjtwCEmzpwl1",
        "outputId": "9764b1e7-056d-4729-a1d8-1e251ee44f2b"
      },
      "source": [
        "# Results for our feature extraction model \n",
        "model_2_results = calculate_metrics(val_labels_encoded , \n",
        "                                    model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 71.09426717860453,\n",
              " 'F1_Score: ': 0.7079139621512185,\n",
              " 'Precision: ': 0.7119554040391881,\n",
              " 'Recall: ': 0.7109426717860453}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW0KDzGQp-WV"
      },
      "source": [
        ""
      ],
      "execution_count": 113,
      "outputs": []
    }
  ]
}