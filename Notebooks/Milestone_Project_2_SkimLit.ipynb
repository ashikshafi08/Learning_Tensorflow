{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Milestone Project 2: SkimLit.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMjEA9y/q6x5lIRT0dIpnij",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning_Tensorflow/blob/main/Notebooks/Milestone_Project_2_SkimLit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NwEKeznKJUb"
      },
      "source": [
        "# Milestone Project 2: SkimLit\n",
        "The purpose of this notebook is to build an NLP model to make reading medical abstracts easier. \n",
        "\n",
        "In this project, we're going to be putting what we've learned into practice.\n",
        "\n",
        "More specificially, we're going to be replicating the deep learning model behind the 2017 paper [PubMed 200k RCT: a Dataset for Sequenctial Sentence Classification in Medical Abstracts](https://arxiv.org/abs/1710.06071).\n",
        "\n",
        "When it was released, the paper presented a new dataset called PubMed 200k RCT which consists of ~200,000 labelled Randomized Controlled Trial (RCT) abstracts.\n",
        "\n",
        "The goal of the dataset was to explore the ability for NLP models to classify sentences which appear in sequential order. In other words, given the abstract of a RCT, what role does each sentence serve in the abstract?\n",
        "\n",
        "### What we're going to cover\n",
        "Time to take what we've learned in the NLP fundmentals notebook and build our biggest NLP model yet:\n",
        "- Downloading a text dataset (PubMed RCT200k from GitHub)\n",
        "- Writing a preprocessing function to prepare our data for modelling\n",
        "- Setting up a series of modelling experiments\n",
        "  - Making a baseline (TF-IDF classifier)\n",
        "  - Deep models with different combinations of: token  embeddings, character embeddings, pretrained embeddings, positional embeddings\n",
        "- Building our first multimodal model (taking multiple types of data inputs).\n",
        "  - Replicating the model architecture from [paper](https://arxiv.org/pdf/1612.05251.pdf)\n",
        "- Find the most wrong predictions\n",
        "- Making predictions on PubMed abstracts from the wild"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2aTpsv5MIJW"
      },
      "source": [
        "### Get Data \n",
        "Let's download the PubMed 200k PCT data. \n",
        "https://github.com/Franck-Dernoncourt/pubmed-rct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOB0c4aOhZ4W",
        "outputId": "1be0ab58-90f0-4a01-ae1d-eb311663dab6"
      },
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'pubmed-rct' already exists and is not an empty directory.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X11jn_SZhcI5"
      },
      "source": [
        "\n",
        "Checking the contents of the downloaded repository, you can see there are four folders.\n",
        "\n",
        "Each contains a different version of the PubMed 200k RCT dataset.\n",
        "\n",
        "Looking at the README file from the GitHub page, we get the following information:\n",
        "\n",
        "\n",
        "- PubMed 20k is a subset of PubMed 200k. I.e., any abstract present in PubMed 20k is also present in PubMed 200k.\n",
        "- PubMed_200k_RCT is the same as PubMed_200k_RCT_numbers_replaced_with_at_sign, except that in the latter all numbers had been replaced by @. (same for PubMed_20k_RCT vs. - PubMed_20k_RCT_numbers_replaced_with_at_sign).\n",
        "- Since Github file size limit is 100 MiB, we had to compress PubMed_200k_RCT\\train.7z and PubMed_200k_RCT_numbers_replaced_with_at_sign\\train.zip. To uncompress train.7z, you may use 7-Zip on Windows, Keka on Mac OS X, or p7zip on Linux.\n",
        "\n",
        "To begin with, the dataset we're going to be focused on is PubMed_20k_RCT_numbers_replaced_with_at_sign.\n",
        "\n",
        "Why this one?\n",
        "\n",
        "Rather than working with the whole 200k dataset, we'll keep our experiments quick by starting with a smaller subset. We could've chosen the dataset with numbers instead of having them replaced with @ but we didn't.\n",
        "Let's check the file contents.\n",
        "\n",
        "- Paper for Modelling : https://arxiv.org/abs/1612.05251\n",
        "- Application paper: https://arxiv.org/abs/1710.06071\n",
        "\n",
        "**Problem in a sentence**\n",
        "\n",
        "The number of RCT papers released is continuing to increase, those without structured abstracts can be hard to read and in turn slow down researchers moving through the literature.\n",
        "\n",
        "**Solution in a sentence**\n",
        "\n",
        "Create an NLP model to classify abstract sentences into the role they play (e.g. objective, methods, results, etc) to enable researchers to skim through the literature (hence SkimLit ðŸ¤“ðŸ”¥) and dive deeper when necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYd49SCfmcEu",
        "outputId": "5022514a-1106-41c1-8a15-cf9e6de98738"
      },
      "source": [
        "# Check what files are in the PubMed_20k dataset \n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKfCPURez8hs",
        "outputId": "4b4cb636-f813-4c2f-fb85-1de2229bf151"
      },
      "source": [
        "# # Start our experiments using thhe 20K dataset with numbers replaced by '@' sign\n",
        "data_dir = 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/'\n",
        "\n",
        "# Check all of the filenames in the target direcotry \n",
        "import os \n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cULq2iAkz8wd"
      },
      "source": [
        "## Preprocess data \n",
        "\n",
        "Now we've got some text data, it's time to become one with it. \n",
        "And one of the best ways to become one with the data is to... \n",
        "\n",
        "> Visualize , Visualize , visualize....\n",
        "\n",
        "So with that in mind, lets write a function to read in all of the lines of a target text file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sH3TbbP69Ow"
      },
      "source": [
        "# Create function to read the lines of a document \n",
        "def get_lines(filename):\n",
        "  '''\n",
        "  Reads filename (a text filename) adn returns the line of text as a list. \n",
        "\n",
        "  Args: \n",
        "    filename: a string containing the target filepth \n",
        "\n",
        " Returns: \n",
        "  A list of stings with one string per line from the target filename\n",
        "  '''\n",
        "  with open(filename , 'r') as f: \n",
        "    return f.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV3wVQU17ikr",
        "outputId": "510de1bf-37f1-4835-bd42-ad614da6ad35"
      },
      "source": [
        "# Using our function , lets read in training lines \n",
        "train_lines = get_lines(data_dir + 'train.txt') # read the lines within the training file \n",
        "train_lines[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RGOZ-MY7v2_"
      },
      "source": [
        "We can't pass this train lines straight into our model because they are quite messy and our model will start to learning something irrelavant. \n",
        "\n",
        "But we can turn this lines into our desired way from which our model can learn. \n",
        "- Every new abstract starts with a **###somenumbers** so we can differentiate between different abstracts through this.\n",
        "- And every label is at the starting line of the sentence, for instance **OBJECTIVE , METHODS** these are present at the very starting line of a sentence.\n",
        "- Each abstract ends with an **\\n** new line command.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK1ADq5h9Dyh"
      },
      "source": [
        "Lets think about how we want our data to look...\n",
        "\n",
        "How the data would be best represented? \n",
        "\n",
        "```\n",
        "[{'line_number': 0,\n",
        "  'target': 'OBJECTIVE',\n",
        "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
        "  'total_lines': 11},\n",
        "  ...]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJl6Gy0Y-KYF",
        "outputId": "ab66cc0e-e812-4e6a-f8eb-364767b51779"
      },
      "source": [
        "# Number of lines \n",
        "len(train_lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210040"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW6Y8KZ9-y30"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}