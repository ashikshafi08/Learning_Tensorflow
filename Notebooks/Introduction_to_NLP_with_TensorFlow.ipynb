{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction_to_NLP_with_TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikshafi08/Learning_Tensorflow/blob/main/Notebooks/Introduction_to_NLP_with_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P86230zG-74n",
        "outputId": "50fd813d-91dc-4785-e382-16d227f2e379"
      },
      "source": [
        "# Checking what GPU are we running \n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jun  6 04:51:56 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40J-qcUfUquQ"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZLeskK5UCWj",
        "outputId": "574d3faf-7607-4c0d-830c-9fedd3126787"
      },
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy(policy = 'mixed_float16')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
            "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORYaf-CkUgzD",
        "outputId": "842e125a-039d-4c2d-b34c-c0d8e0a8ec61"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GocVVrp_snn6"
      },
      "source": [
        "### Getting the helper functions \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo8KywfBuftm",
        "outputId": "a3834d9e-938a-43f6-eacb-946f32579d34"
      },
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-06 04:52:04--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-06 04:52:04 (110 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3-mGEurIyRH"
      },
      "source": [
        "# Import the needed helper functions for the notebook \n",
        "from helper_functions import unzip_data , create_tensorboard_callback , plot_loss_curves , compare_historys"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qah0KdlutEa4"
      },
      "source": [
        "## Get a text dataset \n",
        "\n",
        "The dataset we're going to be using is Kaggle's Introduction to NLP dataset (text sampels of tweets labelled as disaster (or) not disaster). \n",
        "\n",
        "See the original source here https://www.kaggle.com/c/nlp-getting-started/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_V6EEy0tgVP",
        "outputId": "aa70a08f-d594-4b24-9704-724e1d6d2927"
      },
      "source": [
        "# Download the data from Kaggle \n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "# Unzipping the data \n",
        "unzip_data('nlp_getting_started.zip')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-06 04:52:05--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 74.125.197.128, 74.125.142.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2021-06-06 04:52:05 (109 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkMPaEI-tm36"
      },
      "source": [
        "## Become one with the data \n",
        "\n",
        "We will Visualize , explore our test data in here. \n",
        "\n",
        "Text datasets come across in many different formats, aside from CSV files we will probably encounter `.txt` file and `.json` files too. Reading the below articles will help in those times, \n",
        "* [How to Read and Write Files in Python](https://realpython.com/read-write-files-python/)\n",
        "* [Working with JSON Data in Python](https://realpython.com/python-json/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3fUnop6WuNCn",
        "outputId": "cb3e9bfa-224a-4e7b-a618-f6e3c3f4a920"
      },
      "source": [
        "# Importing pandas to look into our csv file \n",
        "import pandas as pd \n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# What's inside our train dataframe? \n",
        "train_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dTrFXxYfvWlo",
        "outputId": "595b70d8-e6af-430e-c694-e682dc28bc85"
      },
      "source": [
        "# Getting the first sample of row 1 \n",
        "train_df['text'][0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9EC6SvCvhgr"
      },
      "source": [
        "So our goal now is to build a model to predict the target. Where our targets are it is a disaster or not a disaster. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "pTWf3W3Cvu5W",
        "outputId": "50931b23-93ef-4d7b-fa54-3d2b43c89f7b"
      },
      "source": [
        "# Shuffle the traning dataframe \n",
        "train_df_shuffled = train_df.sample(frac = 1 , \n",
        "                                    random_state = 42)\n",
        "\n",
        "# Looking into our shuffled dataframe \n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "0fVZfTzzv9sd",
        "outputId": "54ede396-8dfb-4bd2-f25d-671c67281af9"
      },
      "source": [
        "# What does the test dataframe looks like \n",
        "test_df.head() "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI8yjVHOwvBM"
      },
      "source": [
        "Same as the train dataframe but no targets. In here we are going to use the text column and predict upcoming tweets whether they are Disaster or Not. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE0WJRQ9w5Wp",
        "outputId": "617d8376-71cf-4bd4-ab2d-236e8cc9b1e0"
      },
      "source": [
        "# How many examples of each class? \n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z_ETiUIw-_Z"
      },
      "source": [
        "We can't say our targets are perfectly balanced but it's pretty much a 60-40 split balance between the targets. \n",
        "\n",
        "So if we have imabalanced target class refer this https://www.tensorflow.org/tutorials/structured_data/imbalanced_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwkWdusMxVKf",
        "outputId": "c4723a67-8d0d-4ef6-9c03-8b7f5e2b0b93"
      },
      "source": [
        "# How many total samples in both sets? \n",
        "\n",
        "len(train_df) , len(test_df)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6-1YARtx0q-",
        "outputId": "120c8304-ecea-4823-9ee3-f1d048be6a3f"
      },
      "source": [
        "# Let's visualize some random training examples. \n",
        "import random \n",
        "\n",
        "# 5 random index random numbers\n",
        "# Create random indexes not higher than the total number of samples\n",
        "random_index = random.randint(0 , len(train_df) - 5) \n",
        "\n",
        "# Will return tuples\n",
        "for row in train_df_shuffled[['text' , 'target']][random_index:random_index+5].itertuples():\n",
        "  _, text , target = row\n",
        "  print(f'Target: {target}' , \"(real disaster)\" if target > 0 else \"(not real disaster\")\n",
        "  print(f'Text:\\n{text}\\n')\n",
        "  print('----\\n')\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Strawberries are in big trouble. Scientists race to find solution. http://t.co/MqydXRLae7 http://t.co/EpJjkB4Be9\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0 (not real disaster\n",
            "Text:\n",
            "@matt_bez oh I'm not bagging her at all! Her body be bangin'. I'm saying she's going to get the rose.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "&gt; Bin Laden family plane crashed after 'avoiding microlight and landing too far down runway... http://t.co/Tu9cgLmgVR #rochdale #heywood\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "#world FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps  http://t.co/wvExJjRG6E\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0 (not real disaster\n",
            "Text:\n",
            "Sitting in a cafe enjoying a bite and cramming for my meeting during my whirlwind 14-hours in NYC! https://t.co/TO0BPiEymS\n",
            "\n",
            "----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbVgZ9cbzI1T"
      },
      "source": [
        "Though we have train and test datasets it's good to create an validation dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBsB3GYh0Lqh"
      },
      "source": [
        "### Split data into training and validation set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfeGwyUZ0WDY"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Let's split training data into train and val set\n",
        "train_sentences , val_sentences , train_labels , val_labels = train_test_split(train_df_shuffled['text'].to_numpy() , \n",
        "                                                                               train_df_shuffled['target'].to_numpy() , \n",
        "                                                                               test_size = 0.1,  # Use 10% of the training data for validation set \n",
        "                                                                               random_state = 42)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD5LXrYS0Zg8",
        "outputId": "ea8d27f3-ff92-415a-f115-f7add536e869"
      },
      "source": [
        "# Checking the shapes of our splits \n",
        "\n",
        "train_sentences.shape , train_labels.shape , val_sentences.shape , val_labels.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6851,), (6851,), (762,), (762,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVrwidP01LPO",
        "outputId": "f3163b67-0b34-4978-bb9f-8f580aa8247d"
      },
      "source": [
        "# Number of samples \n",
        "print(f'Number of sampels in train set: {len(train_sentences)}')\n",
        "print(f'Number of sampels in validation set: {len(val_sentences)}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sampels in train set: 6851\n",
            "Number of sampels in validation set: 762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xirhAYB1XAB",
        "outputId": "cbf0bbed-b6e1-4382-c496-bff27055ca05"
      },
      "source": [
        "# Check the first 10 samples \n",
        "train_sentences[:10] , train_labels[:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK1JBTgS1gqs"
      },
      "source": [
        "Great now we got to know about how our data looks. The next step would be converting our features into numbers where our targets already in number we don't have to bother about it. \n",
        "\n",
        "Next step would be turn the text into numbers! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJX4l1xd16wE"
      },
      "source": [
        "## Converting text into numbers \n",
        "\n",
        "Alright now the challenge is to convert our text into numbers we can use two techniques they are, \n",
        "\n",
        "- **Tokenization**\n",
        "- **Embeddings**\n",
        "\n",
        "Let's look into them one by one. \n",
        "\n",
        "#### Tokenization\n",
        "\n",
        "A straight mapping from word or character or sub-word to a numerical value. There are three main levels of tokenization: \n",
        "\n",
        "- Using **word-level tokenization** with the sentence 'I love TensorFlow' might result in 'I' being `0` , 'love' being `1` and TensorFlow being `2`. In this case, every word in a sequence considered as a single **token.**\n",
        "- **Character - level tokenization,** such as converting the letters A-Z to values `1-26`. In this case, every character in a sequence (or) considered as a single token.\n",
        "- **Sub-word tokenization** is in between word-level and character-level tokenization. It involves breaking individual words into smaller parts and then converting those smaller parts into numbers.\n",
        "\n",
        "    For example ' my favourite food is pineapple pizza' might become —> \" my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case every word could be considered multiple tokens. \n",
        "\n",
        "#### Embeddings\n",
        "\n",
        "A embedding is a representation of natural language which can be learned. Representation comes in the form of a **feature vector**. For example, the word 'dance' could be represented by the 5-dimensional vector `[-0.8457 , 0.4559 , -0.3332, 0.9877, 0.1112]`. \n",
        "\n",
        "It's important to note here, the size of the feature vector is tuneable (embedding_size). There are two ways to use embeddings: \n",
        "\n",
        "- **Create your own embedding** - Once your text has been turned into numbers (requires for an embedding), you can put them through an embedding layer (such as `[tf.keras.layers.Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding)`) and embedding representation will be learned during model training.\n",
        "- **Reuse a pre-learned embedding** - Many pre-trained embeddings exist online. These are pre-trained embeddings have often learned on large corpuses of a text (such as all of Wikipedia) and thus have good underlying representation of natural language. You can use pre-trained embedding to initialize your model and fine-tune it to your own specific task.\n",
        "\n",
        "Example of **tokenization** (straight mapping from word to number) and **embedding** (richer representation of relationships between tokens).\n",
        "\n",
        "> Question: What level of tokenzation should I use? What embedding should should I choose?\n",
        "\n",
        "It depends on your problem. You could try character-level tokenization/embeddings and word-level tokenization/embeddings and see which perform best. You might even want to try stacking them (e.g. combining the outputs of your embedding layers using [`tf.keras.layers.concatenate`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate) ).\n",
        "\n",
        "If you're looking for pre-trained word embeddings, [Word2vec embeddings](http://jalammar.github.io/illustrated-word2vec/), [GloVe embeddings](https://nlp.stanford.edu/projects/glove/) and many of the options available on TensorFlow Hub are great places to start.\n",
        "\n",
        "> Note: Much like searching for a pre-trained computer vision model, you can search for pre-trained word embeddings to use for your problem. Try searching for something like \"use pre-trained word embeddings in TensorFlow\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsR2_6NcO8Ln"
      },
      "source": [
        "When dealing with a text problem one of the first things you'll have to do before you can build a model is to convert your text to numbers. \n",
        "\n",
        "There are few ways to do this, namely: \n",
        "* Tokenization - direct mapping of token (a token could be a word or character) to number. \n",
        "* Embedding - create a matrix of feature vector for each token (the size of the feature vector can be defined and this embedding can be learned). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baYi22uYRUB6"
      },
      "source": [
        "### Text vectorization (tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9_Htq9NsOIt",
        "outputId": "b40180f8-c1f9-4304-da83-ed35659d4bba"
      },
      "source": [
        "# Remind ourselves how our data looks like \n",
        "train_sentences[:5]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqycIsiLsS1g"
      },
      "source": [
        "# Import the tokenization layer \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApElHNZTscyy"
      },
      "source": [
        "How does the `TextVectorization` layer works? \n",
        "- standardize each sample (lower casing + punctuation stripping). \n",
        "- split each sample into substrings (usually words). \n",
        "- recombine substrings into tokens (usually ngrams which will group words). \n",
        "- index tokens (assign a unique int value to each token). \n",
        "- transform each sample using the index, either into a vector of ints or dense float vector.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma_7BGeMuVnB"
      },
      "source": [
        "# Use the default TextVectorization parameters \n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens = None , # how many words in the vocabulary (automatically add <OOV>)\n",
        "                                   standardize = 'lower_and_strip_punctuation' , # Standardize our text data like in image (convert into lower case and strip punctu)\n",
        "                                   split = 'whitespace', # Split the sequence by whitespace\n",
        "                                   ngrams = None , # create group of n-words (None will not group them)\n",
        "                                   output_mode = 'int', # how to map tokens to numbers\n",
        "                                   output_sequence_length = None, # More like batches (padding) None will pad each sequence to normal sequence\n",
        "                                   pad_to_max_tokens = True )"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRtdEZNg0Djl"
      },
      "source": [
        "We can pad out tweets to the longer sequence but to keep our data small we will find the average words in a sequence and will pad our whole data to it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OSLY9j90YHJ",
        "outputId": "d4d452f9-3666-4326-ef24-fcb3395d4d80"
      },
      "source": [
        "ex = train_sentences[0].split()\n",
        "len(ex)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmyejPCxzvKy",
        "outputId": "cf4c6d18-1f30-42a1-9703-6c0e29397db4"
      },
      "source": [
        "# Find the average number of tokens (words) in the training tweets. \n",
        "\n",
        "round(sum([len(i.split()) for i in train_sentences]) / len(train_sentences))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHkvp4Aq0rhw"
      },
      "source": [
        "# Setup text vectorization variable \n",
        "max_vocab_length = 10000 # Max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequence will be (e.g how many words from Tweet does a model see)\n",
        "\n",
        "# Creating a instance\n",
        "text_vectorizer = TextVectorization(max_tokens= max_vocab_length , \n",
        "                                    output_mode = 'int' , \n",
        "                                    output_sequence_length = max_length)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6GktGfm0830"
      },
      "source": [
        "Now we have a instance of our `TextVectorization` layer now we will have to map this layer to our text data in order to convert them in numerical format. \n",
        "\n",
        "We can do this by using `.adapt()` method. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDjM2B-1XE4X"
      },
      "source": [
        "# Fit the text vectorizer to the training sentence\n",
        "text_vectorizer.adapt(train_sentences) # Will go through and apply the text vectorization"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOqZHuM9XyB-",
        "outputId": "f2e6e34d-492c-45ae-d130-1c0fbaac6758"
      },
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "\n",
        "# Applying our text vectorization to our above sentence \n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KerusqYXYF9v"
      },
      "source": [
        "We can observe that our word got converted into a number and rest 0 is to make sure to (pad) fill up the `output_sequence _length` we mentioned while creating our text vectorization layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kO9pfL_YdIv",
        "outputId": "5a4aee78-c210-4217-9c48-02230ca2a894"
      },
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it \n",
        "\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f'Original text:\\n {random_sentence}\\\n",
        "      \\n\\nVectorized version:')\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            " #Sismo ML 2.4  NEAR THE COAST OF WESTERN TURKEY: MagnitudeåÊåÊML 2.4RegionåÊåÊNEAR THE COAST OF WESTERN TURKEY... http://t.co/0wdAzLcM90 #CS      \n",
            "\n",
            "Vectorized version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[1475, 5106, 1335,  217,    2, 1148,    6, 1102,  613,    1,    1,\n",
              "           2, 1148,    6, 1102]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iodWj7oY45U"
      },
      "source": [
        "Great, thought our sentence is more than 15+ words long but we want to keep our sequence withing the range 0-15. \n",
        "\n",
        "We know that `max_tokens` in our text vectorizer layer, it will help us to keep track of the unique words it come across from our data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "napcRxn-ZXVz",
        "outputId": "366ab5e8-5701-4891-a598-224b304dff8e"
      },
      "source": [
        "# Get the unique words in the vocabulary \n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # Get all of the unique words in our training data\n",
        "\n",
        "# Most common words in our vocabulary\n",
        "top_5_words = words_in_vocab[:5] \n",
        "\n",
        "# Least common words in our vocabulary\n",
        "bottom_5_words = words_in_vocab[-5:]\n",
        "\n",
        "print(f'Number of words in vocab: {len(words_in_vocab)}')\n",
        "print(f'5 most common words: {top_5_words}')\n",
        "print(f'5 least common words: {bottom_5_words}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocab: 10000\n",
            "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf8O7yUKamj1"
      },
      "source": [
        "Number of unique words is **10000** its because that's what we set the max_length to. \n",
        "\n",
        "UNK - Unknown vocabulary these are words which isn't in our vocabulary. Like 10000 unique words might not cover all of the words in here. \n",
        "\n",
        "So if we increase our `max_length` parameter to 20000 then our text vectorizer can handle more unique values and there will be less [UNK] tokens. \n",
        "\n",
        "---\n",
        "\n",
        "Alright let's try out embedding and we know the best part of embedding is it can be learned. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNiZK80xcJdT"
      },
      "source": [
        "### Creating an Embedding using a Embedding Layer \n",
        "\n",
        "We have got a way to map our text into numbers. How about we find a way and turn those numbers into embeddings. \n",
        "\n",
        "To make our embedding, we're going to use a TensorFlow's embedding layer. https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "\n",
        "At first the embedding is created the number are all going to random and we know our embedding layer learns and improves as it goes. Likewise the weights in our model it will get updated to better suit the order of the representation of our words. \n",
        "\n",
        "The parameters we care most about for our embedding layer: \n",
        "- `input_dim` = the size of our vocabulary\n",
        "- `output_dim` = the size of the output embedding vector, for example, a value of 100 would mean each token gets represented by a vector 100 long. \n",
        "- `input_lenght` = length of the sequences being passed to the embedding layer (max_length) so it's going to be 15 long. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO3VHRmKc5YV",
        "outputId": "8b46d2b7-a847-43ea-8388-0d5447a4b600"
      },
      "source": [
        "# In practice \n",
        "from tensorflow.keras import layers \n",
        "\n",
        "embedding = layers.Embedding(input_dim= max_vocab_length , # set input shape\n",
        "                             output_dim = 128,  # output shape\n",
        "                             input_length = max_length # How long each input is\n",
        "                             )\n",
        "\n",
        "# Looking at our embedding layer \n",
        "embedding"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f353062d850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEe2C0JFeQpm",
        "outputId": "77a8901e-eda8-4d1d-e549-e7b166b4ede7"
      },
      "source": [
        "# Get a random sentence from our training sentence \n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f'Original text:\\n {random_sentence}')\n",
        "\n",
        "# Mapping text into numbers (turn into dense vectors of fixed size)\n",
        "tokenized_form = text_vectorizer([random_sentence]) \n",
        "print(f'\\n After turning our text into numbers:\\n\\n {tokenized_form}')\n",
        "\n",
        "# Using our embedding layer \n",
        "print(f'\\nApplying the embedding layer to our tokenized vector\\n\\n {embedding(tokenized_form)}')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            " @CarlaChamorros HILLARY A MASS MURDERER.\n",
            "\n",
            " After turning our text into numbers:\n",
            "\n",
            " [[   1 3777    3  157  538    0    0    0    0    0    0    0    0    0\n",
            "     0]]\n",
            "\n",
            "Applying the embedding layer to our tokenized vector\n",
            "\n",
            " [[[-0.005024 -0.009796  0.00965  ... -0.007717 -0.02211   0.02553 ]\n",
            "  [ 0.01373   0.03336   0.03363  ...  0.005196 -0.02548   0.007557]\n",
            "  [-0.0394   -0.01674   0.0384   ... -0.002893 -0.04794   0.02464 ]\n",
            "  ...\n",
            "  [ 0.01663   0.0335   -0.04608  ...  0.02415  -0.02083   0.02797 ]\n",
            "  [ 0.01663   0.0335   -0.04608  ...  0.02415  -0.02083   0.02797 ]\n",
            "  [ 0.01663   0.0335   -0.04608  ...  0.02415  -0.02083   0.02797 ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_86P2H8hGyg",
        "outputId": "d257d7b0-9879-464b-ad73-abfafc4373e3"
      },
      "source": [
        "sample_embed = embedding(tokenized_form)\n",
        "sample_embed"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float16, numpy=\n",
              "array([[[-0.005024, -0.009796,  0.00965 , ..., -0.007717, -0.02211 ,\n",
              "          0.02553 ],\n",
              "        [ 0.01373 ,  0.03336 ,  0.03363 , ...,  0.005196, -0.02548 ,\n",
              "          0.007557],\n",
              "        [-0.0394  , -0.01674 ,  0.0384  , ..., -0.002893, -0.04794 ,\n",
              "          0.02464 ],\n",
              "        ...,\n",
              "        [ 0.01663 ,  0.0335  , -0.04608 , ...,  0.02415 , -0.02083 ,\n",
              "          0.02797 ],\n",
              "        [ 0.01663 ,  0.0335  , -0.04608 , ...,  0.02415 , -0.02083 ,\n",
              "          0.02797 ],\n",
              "        [ 0.01663 ,  0.0335  , -0.04608 , ...,  0.02415 , -0.02083 ,\n",
              "          0.02797 ]]], dtype=float16)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJrh7mUreaO7"
      },
      "source": [
        "What is 128? \n",
        "Every single token in our sequence are now in the format of 128 long vectors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFE5xROLg_3h",
        "outputId": "42c97198-3605-43d2-fe14-40e821fcda3e"
      },
      "source": [
        "# Check out a single token's embedding \n",
        "sample_embed[0][0] , sample_embed[0][0].shape , random_sentence[0]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float16, numpy=\n",
              " array([-0.005024, -0.009796,  0.00965 , -0.04703 ,  0.02823 , -0.02725 ,\n",
              "        -0.00574 , -0.02844 ,  0.0363  ,  0.03293 ,  0.001346, -0.0387  ,\n",
              "        -0.0266  , -0.02612 , -0.009384,  0.02    ,  0.01526 ,  0.013855,\n",
              "         0.02634 , -0.0042  ,  0.03284 ,  0.0255  , -0.02672 ,  0.001781,\n",
              "        -0.0414  ,  0.012276,  0.03105 ,  0.02475 ,  0.04556 , -0.0384  ,\n",
              "        -0.00925 , -0.03976 ,  0.04822 ,  0.0466  ,  0.03099 ,  0.006214,\n",
              "        -0.03906 , -0.03093 ,  0.03317 ,  0.00942 ,  0.01113 ,  0.02339 ,\n",
              "         0.002731, -0.00827 ,  0.02336 , -0.01671 ,  0.003279,  0.005558,\n",
              "         0.00421 , -0.04288 ,  0.00475 ,  0.03345 ,  0.02403 ,  0.03925 ,\n",
              "         0.03125 ,  0.005207, -0.00828 ,  0.00285 , -0.003986,  0.03253 ,\n",
              "        -0.007336,  0.009605, -0.011665, -0.04855 , -0.03174 , -0.02472 ,\n",
              "        -0.005573, -0.02228 , -0.04205 ,  0.042   , -0.00946 ,  0.03418 ,\n",
              "        -0.02551 , -0.001414, -0.03998 ,  0.03845 , -0.028   ,  0.005543,\n",
              "         0.00209 ,  0.01079 ,  0.02295 , -0.0181  , -0.0418  , -0.04715 ,\n",
              "        -0.0453  , -0.02931 , -0.03137 , -0.02274 , -0.02466 , -0.04764 ,\n",
              "        -0.004883,  0.04797 ,  0.01779 ,  0.00547 , -0.0414  ,  0.02855 ,\n",
              "         0.005505, -0.04065 ,  0.04367 ,  0.03723 , -0.0373  , -0.03668 ,\n",
              "         0.0313  , -0.007698, -0.01412 ,  0.007782,  0.02078 , -0.0445  ,\n",
              "         0.001674, -0.02397 ,  0.00906 ,  0.011314,  0.0174  , -0.0364  ,\n",
              "        -0.01578 , -0.02437 , -0.006336, -0.01857 ,  0.003687,  0.02843 ,\n",
              "         0.0177  ,  0.001139,  0.04736 , -0.02582 , -0.01121 , -0.007717,\n",
              "        -0.02211 ,  0.02553 ], dtype=float16)>, TensorShape([128]), '@')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3jkOI1bhjr-"
      },
      "source": [
        "Alright next we wil discuss the various modelling experiments we're going to run. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcBk28ZclABH"
      },
      "source": [
        "## Modelling a text dataset (running a series of experiments) \n",
        "\n",
        "Once you've got your inputs and outputs prepared, it's a matter of figuring out which machine learning model to build in between them to bridge the gap.\n",
        "\n",
        "To get a plenty of practice, we're going to build a series of different models, each has its won experiment. We'll then compare the results of each model and see which one performed better. \n",
        "\n",
        "We're going to build, \n",
        "\n",
        "- **Model 0**: Naive Bayes (common baseline for text based data- tf-idf)\n",
        "- **Model 1**: Feed-forward neural network (dense model)\n",
        "- **Model 2**: LSTM model (RNN)\n",
        "- **Model 3**: GRU model (RNN)\n",
        "- **Model 4**: Bidirectional-LSTM model (RNN)\n",
        "- **Model 5**: 1D Convolutional Neural Network\n",
        "- **Model 6**: TensorFlow Hub Pre-trained Feature Extractor\n",
        "- **Model 7**: Same as model 6 with 10% of training data.\n",
        "\n",
        "How are we going to approach all of these? \n",
        "Use the standard steps in modelling with TensorFlow: \n",
        "- Create a Model\n",
        "- Build a Model \n",
        "- Fit a model \n",
        "- Evaluate our model\n",
        "\n",
        "Let's build a Non-deeplearning model to be more specific a Naive Bayes model from scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vjNI6I84BYx"
      },
      "source": [
        "Let's experiment before the video \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsFEx0S13tjI",
        "outputId": "d568b4c0-a147-41ac-cc11-70b17acf916a"
      },
      "source": [
        "# Checking the shapes of our splits \n",
        "train_sentences.shape , train_labels.shape , val_sentences.shape , val_labels.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6851,), (6851,), (762,), (762,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAJKkhbU5ZuR",
        "outputId": "bbb4f5f8-3ef7-4a1c-c91a-0aa3049d6965"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Creating a instance\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "# Fitting our data to our TfidfVectorizer \n",
        "tf_transformer = tfidf.fit(train_sentences)\n",
        "\n",
        "# Applying the transformation\n",
        "train_sen_trans = tf_transformer.transform(train_sentences)\n",
        "\n",
        "# Checking the shape \n",
        "train_sen_trans.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 20076)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk1wiOvw8U9f"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f_-oUXG7AFd",
        "outputId": "05a17b36-5c1c-4c15-865c-8c4fbdcc67b8"
      },
      "source": [
        "train_sen_trans[:1]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x20076 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 6 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUn77iVG4DgT",
        "outputId": "148890de-0842-4d30-b6db-c29702bec601"
      },
      "source": [
        "# Importing the naive bayes model for our classified \n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Creating a instance of our model \n",
        "clf_naive = MultinomialNB()\n",
        "\n",
        "# Fitting the data\n",
        "clf_naive.fit(train_sen_trans , train_labels)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7WsjDr_4o9z"
      },
      "source": [
        "### Model 0: Getting a baseline \n",
        "\n",
        "To create our baseline, we'll use Sklearn's multinomal Naive Bayes using the TF-IDF formula to convert our words to numbers. \n",
        "\n",
        "> 🔑 **Note**: It's common practice to use non-DL algorithms as a baseline because of their speed and then later using the DL to see if we can improve. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbCxVm415_nx",
        "outputId": "368e181e-690f-4642-a4c9-762abe507227"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3CkVvyj5H-D",
        "outputId": "c8879ec7-be06-4b60-fe3d-5310923d64f9"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer # (turn text into numbers)\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline \n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                  ('tfidf' , TfidfVectorizer()) , # Convert words to numbers using tfidf\n",
        "                  ('clf' , MultinomialNB()), # Model the text \n",
        "                ])\n",
        "\n",
        "# Fit the pipeline to the training data \n",
        "model_0.fit(train_sentences , train_labels)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u9cp5jB5peK",
        "outputId": "1da02c83-8fe9-40bb-aa8a-d9d21bb04095"
      },
      "source": [
        "# Evaluate our baseline model \n",
        "# Default evaluation metrics is accuracy\n",
        "baseline_score = model_0.score(val_sentences , val_labels)\n",
        "print(f'Our baseline mdoel achieves an accuracy of: {baseline_score*100:.2f}%')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our baseline mdoel achieves an accuracy of: 79.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl9JsXSN7ky8",
        "outputId": "86dd1489-1293-431c-8590-afab3ccf258c"
      },
      "source": [
        "# Make predictions \n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "\n",
        "# First 10 predictions\n",
        "baseline_preds[:10]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAuUiBdK78kc"
      },
      "source": [
        "Let's use some of the other evaluation metrics. We will make a handy function which will help us to reduce the hustle of writing out every evaluation metrics. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffgtOsFj81s9"
      },
      "source": [
        "def classification_evaluation_metrics(y_true , \n",
        "                                      y_preds):\n",
        "  '''\n",
        "  Arguments: \n",
        "  y_true --> true labels of the data \n",
        "  y_preds --> predicted labels of the data \n",
        "\n",
        "  Returns: \n",
        "  A dictionary of evaluation metrics like precision , recall and f1_score\n",
        "  '''\n",
        "\n",
        "  # Let's first import the needed metrics \n",
        "  from sklearn.metrics import precision_score , f1_score , accuracy_score , recall_score\n",
        "\n",
        "  # Creting the metrics \n",
        "  accuracy = accuracy_score(y_true , y_preds)\n",
        "  f1_score = f1_score(y_true , y_preds)\n",
        "  precision = precision_score(y_true , y_preds)\n",
        "  recall = recall_score(y_true , y_preds)\n",
        "\n",
        "  # Now will create a dictionary of these metrics and pack them\n",
        "  evaluation_dict = {'Accuracy:': accuracy * 100 , \n",
        "                     'F1_Score: ': f1_score , \n",
        "                     'Precision: ': precision , \n",
        "                     'Recall: ': recall }\n",
        "\n",
        "  # Return our dictionary \n",
        "  return evaluation_dict\n",
        "  "
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-3DefbG9o43",
        "outputId": "4e19df7a-4fd4-4249-df94-b3824366ec15"
      },
      "source": [
        "# Using the above function \n",
        "naive_baseline_results = classification_evaluation_metrics(val_labels , \n",
        "                                                    baseline_preds)\n",
        "\n",
        "# Looking into the dictionary of evaluation metrics \n",
        "naive_baseline_results"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 79.26509186351706,\n",
              " 'F1_Score: ': 0.734006734006734,\n",
              " 'Precision: ': 0.8861788617886179,\n",
              " 'Recall: ': 0.6264367816091954}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmYz3EG6-cGM"
      },
      "source": [
        "Great! Our baseline model worked better than we expected. Now let's build a Feed-forward neural network model for our text data.\n",
        "\n",
        "### Model 1: Feed Forward Neural Network (Dense layers) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VZoRLGGBFkl"
      },
      "source": [
        "# Create a tensorboard callback (to track the model experiments) \n",
        "# New one for each model\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save tensorboard logs \n",
        "SAVE_DIR = 'model_logs'"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khw1pA1pFaWb",
        "outputId": "5cebff16-4046-4d50-ca32-084064a5ebce"
      },
      "source": [
        "# Build model with the functional API \n",
        "from tensorflow.keras import layers \n",
        "\n",
        "# Creating our input layer (inputs are 1D strings)\n",
        "inputs = layers.Input(shape=(1,) , dtype = tf.string)\n",
        "\n",
        "# Convert strings into numbers and applying word embedding\n",
        "x = text_vectorizer(inputs) # turn input text into numbers \n",
        "x = embedding(x) # Create an embedding of the numberized inputs \n",
        "\n",
        "# Ouput layer (want binary outputs so use sigmoid activation function)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x) \n",
        "\n",
        "# Packing into a model \n",
        "model_1 = tf.keras.Model(inputs , outputs , name = 'model_1_dense')\n",
        "\n",
        "# Getting the model summary \n",
        "model_1.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 15, 1)             129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7FJjkw4GoiB"
      },
      "source": [
        "At `embedding_2 (Embedding)` our embedding layers adds a extra dimension 128 so our model's parameters gets increased in numbers.\n",
        "\n",
        "Because every single tokens (15 tokens) get represented as 128 long feature vector. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw1YnCMMG0QU"
      },
      "source": [
        "# Compile the model \n",
        "model_1.compile(loss = tf.keras.losses.BinaryCrossentropy() , \n",
        "                optimizer = tf.keras.optimizers.Adam() , \n",
        "                metrics = ['accuracy'])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu8pf9UvHqR1",
        "outputId": "8e44fbd0-0751-4a36-9fc7-ab69e9c2080c"
      },
      "source": [
        "# Fit the model \n",
        "model_1_history = model_1.fit(train_sentences ,\n",
        "                              train_labels , \n",
        "                              epochs = 5 , \n",
        "                              validation_data = (val_sentences , val_labels) , \n",
        "                              callbacks = [create_tensorboard_callback(dir_name = SAVE_DIR , \n",
        "                                                                       experiment_name = 'model_1_dense')])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20210606-045213\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 18ms/step - loss: 0.6496 - accuracy: 0.6416 - val_loss: 0.6311 - val_accuracy: 0.6475\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.5974 - accuracy: 0.6899 - val_loss: 0.6235 - val_accuracy: 0.6487\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.5772 - accuracy: 0.6923 - val_loss: 0.6262 - val_accuracy: 0.6468\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.5678 - accuracy: 0.6919 - val_loss: 0.6297 - val_accuracy: 0.6481\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.5634 - accuracy: 0.6917 - val_loss: 0.6346 - val_accuracy: 0.6475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbtEqxwhIGAc",
        "outputId": "ae822644-d121-41f5-a5ac-fc1d69e30216"
      },
      "source": [
        "# Check the results \n",
        "model_1.evaluate(val_sentences , val_labels)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.6475\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6345682740211487, 0.6475065350532532]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsjg8-aTIfqj",
        "outputId": "8c098f70-0e99-4733-d17f-1ae8d55b0985"
      },
      "source": [
        "# Make some predictions and evaluate \n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 15, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGYX8UtkIplD",
        "outputId": "c00c4e7c-3375-4ddd-9a0d-c5350b358295"
      },
      "source": [
        "model_1_pred_probs[:1]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.4294 ],\n",
              "        [0.4294 ],\n",
              "        [0.4294 ],\n",
              "        [0.165  ],\n",
              "        [0.478  ],\n",
              "        [0.4294 ],\n",
              "        [0.4294 ],\n",
              "        [0.4294 ],\n",
              "        [0.10016],\n",
              "        [0.3303 ],\n",
              "        [0.4294 ],\n",
              "        [0.9473 ],\n",
              "        [0.03906],\n",
              "        [0.4294 ],\n",
              "        [0.335  ]]], dtype=float16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXjd2qFHItvp"
      },
      "source": [
        "We want a single prediction probability for each sample but it looks like it is outputing a prediction probability for each tokens.\n",
        "\n",
        "To fix this we will be using **GlobalAveragePooling** layer. This will help us to condense the feature vector for each token to one vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvpHkavdJHG4"
      },
      "source": [
        "# Let's build the model again but with GlobalAveragePooling \n",
        "from tensorflow.keras import layers \n",
        "\n",
        "# Input layer\n",
        "inputs = layers.Input(shape = (1,) , dtype = tf.string)\n",
        "\n",
        "# Turn text into numbers and create an word embedding \n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "\n",
        "# Condense the feature vector for each token to \"one vector\"\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "# Output layer \n",
        "outputs = layers.Dense(1 , activation = 'sigmoid')(x)\n",
        "\n",
        "# Packing into a model \n",
        "model_1 = tf.keras.Model(inputs , outputs , name = 'model_1_dense')\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3nbJxUJLIMe",
        "outputId": "7fa01cf2-3fdd-4b1f-de9f-a634de8f48ce"
      },
      "source": [
        "# Checking the summary of the model\n",
        "model_1.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k35WDOFwKHPt"
      },
      "source": [
        "# Compile the model \n",
        "model_1.compile(loss = tf.keras.losses.BinaryCrossentropy() , \n",
        "                optimizer = tf.keras.optimizers.Adam() , \n",
        "                metrics = 'accuracy')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXWkThpJKRJ9",
        "outputId": "b1edf1bc-81da-48d1-8ad9-3b805fb6ace1"
      },
      "source": [
        "# Fitting the model \n",
        "model_1.fit(train_sentences , \n",
        "            train_labels , \n",
        "            epochs = 5 , \n",
        "            validation_data = (val_sentences , val_labels) , \n",
        "            callbacks = create_tensorboard_callback(dir_name= SAVE_DIR , \n",
        "                                                    experiment_name = 'model_1_dense_pool_layer'))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense_pool_layer/20210606-045234\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 17ms/step - loss: 0.5598 - accuracy: 0.7773 - val_loss: 0.5172 - val_accuracy: 0.7703\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.3931 - accuracy: 0.8533 - val_loss: 0.4613 - val_accuracy: 0.7887\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.3131 - accuracy: 0.8819 - val_loss: 0.4493 - val_accuracy: 0.7940\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2615 - accuracy: 0.9041 - val_loss: 0.4547 - val_accuracy: 0.7940\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2223 - accuracy: 0.9207 - val_loss: 0.4666 - val_accuracy: 0.7808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f352015f590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTjNQrq4Km3E",
        "outputId": "80a84423-ea86-4df1-83fc-15d764fcbcc7"
      },
      "source": [
        "# Checking the results by evaluatiing our model \n",
        "model_1.evaluate(val_sentences , val_labels)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.46662387251853943, 0.7808399200439453]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17mCz3ybKuEs",
        "outputId": "743860af-ad8e-4037-9b92-924891e9a5b6"
      },
      "source": [
        "# Making prediction \n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apxA4ntXK326",
        "outputId": "0f3e680a-1159-45d1-c335-8389b6d6aa62"
      },
      "source": [
        "# How our predictions looks now? \n",
        "model_1_pred_probs[:10]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3733],\n",
              "       [0.785 ],\n",
              "       [0.997 ],\n",
              "       [0.155 ],\n",
              "       [0.1292],\n",
              "       [0.9507],\n",
              "       [0.9053],\n",
              "       [0.996 ],\n",
              "       [0.974 ],\n",
              "       [0.2788]], dtype=float16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTjB4MpMLBAY",
        "outputId": "8d8d2119-d7f5-4de5-9730-3226e3b72540"
      },
      "source": [
        "# Convert model prediction probs to label format \n",
        "\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:20]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float16, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float16)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFxONJ5WMn0k",
        "outputId": "9b066dd1-86e4-4a35-b612-8e1b0f54ee1a"
      },
      "source": [
        "# Calculate our model_1 results \n",
        "model_1_results = classification_evaluation_metrics(y_true = val_labels , \n",
        "                                                    y_preds = model_1_preds)\n",
        "\n",
        "model_1_results"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 78.08398950131233,\n",
              " 'F1_Score: ': 0.7418856259659969,\n",
              " 'Precision: ': 0.802675585284281,\n",
              " 'Recall: ': 0.6896551724137931}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdKr9mZqM1D4",
        "outputId": "2297b78b-c709-4d5a-f1f3-988ff744ce79"
      },
      "source": [
        "# Our baseline metrics \n",
        "naive_baseline_results"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 79.26509186351706,\n",
              " 'F1_Score: ': 0.734006734006734,\n",
              " 'Precision: ': 0.8861788617886179,\n",
              " 'Recall: ': 0.6264367816091954}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBthn7ZvM-pc",
        "outputId": "9636d066-7082-4ade-a505-8217da1510d3"
      },
      "source": [
        "# Comparing our base line model with our deeplearning model\n",
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(naive_baseline_results.values()))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False,  True, False,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh1UM4cvNNci"
      },
      "source": [
        "### Visualizing our model's learned word embeddings with TensorFlow's projector tool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9pggGkfNg6n",
        "outputId": "4c181b18-2673-485e-825a-8b7adbdab62e"
      },
      "source": [
        "# Get the vocabulary from the text vectorization layer \n",
        "\n",
        "# Getting the unique vocabulary our embedding layer learnt\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab) , words_in_vocab[:10]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDE5iZC3OO2h",
        "outputId": "d47da938-0aaa-4434-f69d-39ee4bcec829"
      },
      "source": [
        "# Model 1 summary (inspect the embedding layer)\n",
        "model_1.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KOQ3yM5OnCb"
      },
      "source": [
        "Let's get the weight matrix of our embedding layer \n",
        "\n",
        "These are the numerical representation of each token in our training data, which have been learned for 5 epochs (patterns from our embedding layer). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8m8gYL4O4GN",
        "outputId": "18e1ea17-089d-48ad-d43b-fa482c8ddddd"
      },
      "source": [
        "embed_weights = model_1.get_layer('embedding').get_weights()\n",
        "embed_weights"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-2.10032295e-02, -7.21996231e-03, -8.56838375e-02, ...,\n",
              "         -1.68908797e-02,  1.56034967e-02,  6.78348169e-02],\n",
              "        [-1.73198115e-02, -2.49195062e-02, -6.18463708e-03, ...,\n",
              "         -2.29640789e-02, -7.98925851e-03,  4.15565223e-02],\n",
              "        [-6.16898686e-02, -6.00562282e-02, -8.14142972e-02, ...,\n",
              "         -2.60837004e-02,  4.00570855e-02,  1.20559391e-02],\n",
              "        ...,\n",
              "        [ 2.56976150e-02,  1.45889819e-04, -1.93693880e-02, ...,\n",
              "          3.18979733e-02, -3.92366759e-02,  3.38860042e-02],\n",
              "        [-9.46974680e-02, -5.29922545e-02, -7.91671649e-02, ...,\n",
              "         -1.02913074e-01,  1.20487392e-01,  7.10639656e-02],\n",
              "        [-1.23542853e-01, -1.01165108e-01, -1.25926480e-01, ...,\n",
              "         -1.22870386e-01,  9.89418924e-02,  1.49825722e-01]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i6XvRzsPKd_"
      },
      "source": [
        "Those are the weights learned by our embedding layers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq-6SYq9PaJA",
        "outputId": "b79c6f00-7dcf-4f55-bc4b-1a2449556acd"
      },
      "source": [
        "# The shape should be same size as vocab and embedding_dim (output_dim of our embedding layer)\n",
        "embed_weights[0].shape "
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiIR5NDZPlfx"
      },
      "source": [
        "From above we can understand that,\n",
        "1000 from every token is embedded into 128 dimension vector. \n",
        "\n",
        "Now we've got the embeddig matrix of our model has learned to represent our tokens, let's see how we visualize it. \n",
        "\n",
        "To do so, TensorFlow has a handy tool called projector: http://projector.tensorflow.org/_\n",
        "\n",
        "And TensorFlow also has a guide on Word Embeddings: https://www.tensorflow.org/tutorials/text/word_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCTJ0F4iPzZO"
      },
      "source": [
        "# Create embedding files (we got this from TensorFlow's word embeddings documentation)\n",
        "\n",
        "import io \n",
        "# Creating a vector and metadata file for our embeddings (tokens and words)\n",
        "out_v = io.open('vectors.tsv' , 'w' , encoding = 'utf-8')\n",
        "out_m = io.open('metadata.tsv' , 'w' , encoding = 'utf-8')\n",
        "\n",
        "# Loop through and write our values to the corresponding files we created above \n",
        "for index , word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue # Skip 0, its padding\n",
        "  \n",
        "  vec = embed_weights[0][index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + '\\n')\n",
        "\n",
        "out_v.close()\n",
        "out_m.close()\n",
        "\n",
        "\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "V9qXC42Ykegy",
        "outputId": "124f31f3-f2ea-4d31-be6b-c5b64d88ee48"
      },
      "source": [
        "# Download files from Colab to upload to the projector \n",
        "try: \n",
        "  from google.colab import files \n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception: \n",
        "  pass  "
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2a882b13-0461-4d75-9aa3-6876e4104f64\", \"vectors.tsv\", 15080897)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_35172ca0-511e-45b7-bfa9-63964b4275f9\", \"metadata.tsv\", 80388)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTxqHZd9lkNF"
      },
      "source": [
        "> Resources: To learn more about embedding, \n",
        "* Jay Alamars visualized word2vec: https://jalammar.github.io/illustrated-word2vec/\n",
        "* TensorFlow's Word Embedding guide: https://www.tensorflow.org/tutorials/text/word_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdpnh9E2nd4G"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "\n",
        "RNN's are useful for sequence data.\n",
        "\n",
        "The premise of a recurrent neural network is to use the representation of previous inputs to aid the representation of the later input. \n",
        "\n",
        "Use information from the past to help you with the future (this is where the term recurrent comes from). In other words, take an input (X) and compute an output (y) based on all previous inputs.\n",
        "\n",
        "> Resources to look into for learning RNN's \n",
        "- [RNN MIT Intro to deeplearning](https://www.youtube.com/watch?v=qjrad0V0uJE&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&index=2)\n",
        "- [Understanding LSTMS](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "- [Unreasonable effectiveness of RNN](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkquozhfpxZs"
      },
      "source": [
        "### Model 2: LSTM \n",
        "\n",
        "LSTM = long short term memory (one of the most popular LSTM cells). \n",
        "\n",
        "Our structure of a RNN typically looks like this: \n",
        "\n",
        "```\n",
        "Input (text) --> Tokenize --> Embedding --> Layers (RNNs/dense) --> Output (label probability)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GngA_4cErDeK",
        "outputId": "a083c9e5-0e00-4780-f940-661fb3856860"
      },
      "source": [
        "# Create an LSTM model \n",
        "from tensorflow.keras import layers \n",
        "\n",
        "# Setting up inputs \n",
        "inputs = layers.Input(shape = (1,) , dtype = tf.string)\n",
        "\n",
        "# Converting text into numbers and creating a embedding \n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(f'After embedding: {x.shape}')\n",
        "\n",
        "# Our LSTM \n",
        "#x = layers.LSTM(64 , return_sequences=True)(x) \n",
        "# When you're stacking RNN cells together you need to set return_sequences = True\n",
        "#print(f'Output with return sequence True: {x.shape}') # Output with return sequence True\n",
        "x = layers.LSTM(64)(x)\n",
        "#print(f'Output with return sequence False: {x.shape}') # Output with return sequence False\n",
        "x = layers.Dense(64 , activation = 'relu')(x)\n",
        "\n",
        "# Initializing our outputs \n",
        "outputs = layers.Dense(1 , activation = 'sigmoid')(x)\n",
        "\n",
        "# Packing into a model \n",
        "model_2 = tf.keras.Model(inputs , outputs, name = 'model_2_LSTM')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After embedding: (None, 15, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wipkr65ct1DL"
      },
      "source": [
        "`inputs`: A 3D tensor with shape `[batch, timesteps, feature]`.\n",
        "\n",
        "- batch --> None by default\n",
        "- timestaps --> treat every sequence (word) as a timestamps. \n",
        "\n",
        "The default activation function for LSTM is **`tanh`**. \n",
        "\n",
        "[LSTM layer tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuUXpE4JsUPS",
        "outputId": "2c6f07f9-e541-4925-87fe-2af1b8b805ee"
      },
      "source": [
        "# Checking the model summary \n",
        "model_2.summary()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,333,633\n",
            "Trainable params: 1,333,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4eEcO25vrU4"
      },
      "source": [
        "# Compile the model \n",
        "model_2.compile(loss = tf.keras.losses.BinaryCrossentropy()  , \n",
        "                optimizer = tf.keras.optimizers.Adam() , \n",
        "                metrics = ['accuracy'])"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSicR9HFv0tq",
        "outputId": "73add169-5194-4982-b9ee-5d097d51262e"
      },
      "source": [
        "# Fit the model \n",
        "model_2_history = model_2.fit(train_sentences , \n",
        "                              train_labels , \n",
        "                              validation_data = (val_sentences , val_labels) , \n",
        "                              epochs = 5 , \n",
        "                              callbacks = [create_tensorboard_callback(dir_name= SAVE_DIR , \n",
        "                                                                       experiment_name = 'model_2_LSTM')])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20210606-045252\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 21ms/step - loss: 0.1998 - accuracy: 0.9261 - val_loss: 0.6120 - val_accuracy: 0.7677\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.1346 - accuracy: 0.9488 - val_loss: 0.6413 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.1066 - accuracy: 0.9607 - val_loss: 0.7542 - val_accuracy: 0.7887\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0855 - accuracy: 0.9661 - val_loss: 0.9188 - val_accuracy: 0.7887\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0698 - accuracy: 0.9712 - val_loss: 1.1152 - val_accuracy: 0.7664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8XsxnUowL8J",
        "outputId": "dd7c05e0-f287-457e-8492-6d6895440399"
      },
      "source": [
        "# Make predictions with LSTM model \n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.965e-03],\n",
              "       [8.789e-01],\n",
              "       [1.000e+00],\n",
              "       [5.560e-02],\n",
              "       [1.987e-04],\n",
              "       [1.000e+00],\n",
              "       [1.153e-01],\n",
              "       [1.000e+00],\n",
              "       [1.000e+00],\n",
              "       [4.321e-01]], dtype=float16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU_SS56cwYf2",
        "outputId": "04bcc0d2-7321-4ec7-bc1c-fa3db24f10c8"
      },
      "source": [
        "# Convert model 2 pred probs to labels \n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float16, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 0.], dtype=float16)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYKB2q3EwlE0",
        "outputId": "32ca4f49-2dd2-457e-ec6b-90fe175e5f51"
      },
      "source": [
        "# Calculate model 2 results \n",
        "model_2_results = classification_evaluation_metrics(val_labels , \n",
        "                                                    model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 76.64041994750657,\n",
              " 'F1_Score: ': 0.7244582043343654,\n",
              " 'Precision: ': 0.785234899328859,\n",
              " 'Recall: ': 0.6724137931034483}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3_93CaCwueq",
        "outputId": "331f8218-0c71-4e73-9dc4-1ef9dca83727"
      },
      "source": [
        "naive_baseline_results"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 79.26509186351706,\n",
              " 'F1_Score: ': 0.734006734006734,\n",
              " 'Precision: ': 0.8861788617886179,\n",
              " 'Recall: ': 0.6264367816091954}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coDgGMK_xASa"
      },
      "source": [
        "### Model 3: GRU Model \n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters. \n",
        "\n",
        "[Understanding GRU networks](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be)\n",
        "\n",
        "Previously we used a LSTM layers to build our RNN model now we will use a GRU layer also called Gater Recurrent Unit to build our model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWAGogQyw59x",
        "outputId": "9519638e-0e9c-4369-cca5-59d4efce368a"
      },
      "source": [
        "# Create a GRU model \n",
        "inputs = layers.Input(shape = (1,) , dtype = tf.string)\n",
        "\n",
        "# Converting text into numbers and performing word embeddings. \n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "\n",
        "# Building our GRU model \n",
        "# If you want to stack recurrent layers on top of each other, you need return_sequences = True\n",
        "x = layers.GRU(64 , activation = 'tanh' , return_sequences=True)(x)\n",
        "print(x.shape)\n",
        "x = layers.LSTM(44 , return_sequences= True)(x) \n",
        "print(x.shape)\n",
        "x = layers.GRU(100)(x)\n",
        "print(x.shape)\n",
        "x = layers.Dense(64 , activation='relu')(x)\n",
        "\n",
        "# Global Average Pooling layer\n",
        "#x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "# Output layer \n",
        "outputs = layers.Dense(1 , activation= 'sigmoid')(x)\n",
        "\n",
        "# Packing into a model \n",
        "test_model_3 = tf.keras.Model(inputs , outputs)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 15, 128)\n",
            "(None, 15, 64)\n",
            "(None, 15, 44)\n",
            "(None, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5DtxMZBxqyc",
        "outputId": "8db58088-61cb-4604-f450-e8c22fc91713"
      },
      "source": [
        "# Summary of the mdoel \n",
        "test_model_3.summary()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 15, 64)            37248     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 15, 44)            19184     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 100)               43800     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                6464      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,386,761\n",
            "Trainable params: 1,386,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Pt_yjyQzz6f"
      },
      "source": [
        "Alright we did some tinkering up there, now let's create a model 3 with only one GRU layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOSurDzt0azg"
      },
      "source": [
        "# Creating a GRU model \n",
        "from tensorflow.keras import layers \n",
        "\n",
        "# Input layer \n",
        "inputs = layers.Input(shape = (1,) , dtype = tf.string)\n",
        "\n",
        "# Converting text into numbers and perform word embeddings \n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "\n",
        "# Our GRU layer \n",
        "#x = layers.GRU(64 , activation= 'tanh' , return_sequences= True)(x)\n",
        "x = layers.GRU(64)(x)\n",
        "\n",
        "# Global Average Pooling \n",
        "#x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "# Output layer \n",
        "outputs = layers.Dense(1 , activation='sigmoid')(x)\n",
        "\n",
        "# Packing into a model\n",
        "model_3 = tf.keras.Model(inputs , outputs) \n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXbsMyFc1SDY",
        "outputId": "9520ecaa-d545-49c9-db39-a9d68324c0c2"
      },
      "source": [
        "# Model summary \n",
        "model_3.summary()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 64)                37248     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEr0sTXe1WcJ"
      },
      "source": [
        "# Compile the model \n",
        "model_3.compile(loss = tf.keras.losses.BinaryCrossentropy() , \n",
        "                optimizer = tf.keras.optimizers.Adam() , \n",
        "                metrics = ['accuracy']) "
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UufQ_01E2Mqm",
        "outputId": "f1198853-9a99-44c8-d504-9dfc596e85cc"
      },
      "source": [
        "# Fit the model \n",
        "model_3_history = model_3.fit(train_sentences , \n",
        "                              train_labels , \n",
        "                              validation_data = (val_sentences , val_labels), \n",
        "                              epochs = 5 , \n",
        "                              callbacks = [create_tensorboard_callback(dir_name= SAVE_DIR , \n",
        "                                                                       experiment_name = 'model_3_GRU')]) \n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20210606-045337\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 21ms/step - loss: 0.1587 - accuracy: 0.9383 - val_loss: 0.7006 - val_accuracy: 0.7703\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0806 - accuracy: 0.9707 - val_loss: 0.7795 - val_accuracy: 0.7743\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0669 - accuracy: 0.9736 - val_loss: 0.9729 - val_accuracy: 0.7769\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0564 - accuracy: 0.9765 - val_loss: 1.0678 - val_accuracy: 0.7782\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0511 - accuracy: 0.9780 - val_loss: 1.1163 - val_accuracy: 0.7782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCNpbclc2jeg",
        "outputId": "406b154b-addf-4221-b931-3de567c80071"
      },
      "source": [
        "# Making predictions on the val set \n",
        "model_3_pred_probs = model_3.predict(val_sentences) \n",
        "model_3_pred_probs[:10]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.262e-03],\n",
              "       [7.310e-01],\n",
              "       [1.000e+00],\n",
              "       [7.996e-02],\n",
              "       [1.293e-04],\n",
              "       [1.000e+00],\n",
              "       [9.419e-01],\n",
              "       [1.000e+00],\n",
              "       [1.000e+00],\n",
              "       [8.052e-01]], dtype=float16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSiTagcC2x_R",
        "outputId": "2d4600f9-1aec-49f0-b2d3-1b7dea1465e4"
      },
      "source": [
        "# Convert model 3 pred probs to labels \n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float16, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float16)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7pWpMX329XX"
      },
      "source": [
        "# Using our evalution metrics dictionary \n",
        "model_3_results = classification_evaluation_metrics(val_labels , \n",
        "                                                    model_3_preds)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzQfjhah3Ika",
        "outputId": "bf562cb1-8323-4da8-ab58-aa55ff5d596f"
      },
      "source": [
        "model_3_results"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 77.82152230971128,\n",
              " 'F1_Score: ': 0.7443267776096822,\n",
              " 'Precision: ': 0.7859424920127795,\n",
              " 'Recall: ': 0.7068965517241379}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ0ZRbgi3KdP"
      },
      "source": [
        "### Model 4: Bidirectional RNN Model \n",
        "\n",
        "Normal RNN's go from left to right (just like you'd read an English sentence) however, a bidirectional RNN goes from right to left as well as left to right. \n",
        "\n",
        "A birdirectional wrapper works for any RNN cells. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx4xvYuz4wAT"
      },
      "source": [
        "Let's give a try before watching the video.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDaAX9OE4242",
        "outputId": "e55a67b3-56bf-419e-f56d-3fc556e36307"
      },
      "source": [
        "# Creating a Bidirectional RNN model \n",
        "from tensorflow.keras import layers\n",
        "# Input layer \n",
        "inputs = layers.Input(shape = (1, ) , dtype = tf.string)\n",
        "\n",
        "# Convert text into numbers and perform word embeddings \n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "\n",
        "# Adding a Bidirectional RNN layer \n",
        "x = layers.Bidirectional(layers.LSTM(64 , return_sequences=True))(x)\n",
        "print(x.shape)\n",
        "\n",
        "x = layers.Bidirectional(layers.GRU(64))(x)\n",
        "print(x.shape)\n",
        "\n",
        "# Output layer \n",
        "outputs = layers.Dense(1 , activation= 'sigmoid')(x)\n",
        "print(outputs.shape)\n",
        "\n",
        "# Packing into a model \n",
        "test_model_4 = tf.keras.Model(inputs , outputs)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 15, 128)\n",
            "(None, 15, 128)\n",
            "(None, 128)\n",
            "(None, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVaZDpmN7IJG"
      },
      "source": [
        "Here we have added `return_sequence = True` because we want to stack another RNN layer with our current RNN layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zllZMbRm5ljJ",
        "outputId": "f498f88e-ba63-4757-d9ab-02ffa48a85b1"
      },
      "source": [
        "# Model summary \n",
        "test_model_4.summary()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 15, 128)           98816     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 128)               74496     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,453,441\n",
            "Trainable params: 1,453,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UtEclC552Ej"
      },
      "source": [
        "Following the video \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNsJRC5M9yBN",
        "outputId": "ea6f0e40-2b87-408f-96a3-a820bfb707fd"
      },
      "source": [
        "# Creating a Bidirectional RNN model \n",
        "from tensorflow.keras import layers\n",
        "# Input layer \n",
        "inputs = layers.Input(shape = (1, ) , dtype = tf.string)\n",
        "\n",
        "# Convert text into numbers and perform word embeddings \n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "\n",
        "# Adding a Bidirectional RNN layer \n",
        "x = layers.Bidirectional(layers.LSTM(64 , return_sequences=True))(x)\n",
        "print(x.shape)\n",
        "x = layers.Bidirectional(layers.GRU(64))(x)\n",
        "print(x.shape)\n",
        "\n",
        "# Output layer \n",
        "outputs = layers.Dense(1 , activation= 'sigmoid')(x)\n",
        "print(outputs.shape)\n",
        "\n",
        "# Packing into a model \n",
        "model_4 = tf.keras.Model(inputs , outputs)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 15, 128)\n",
            "(None, 15, 128)\n",
            "(None, 128)\n",
            "(None, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfJFWjwi96VV",
        "outputId": "4c7f61ca-0dac-4c53-d211-23344ef12d96"
      },
      "source": [
        "# Model Summary \n",
        "model_4.summary()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 15, 128)           98816     \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 128)               74496     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,453,441\n",
            "Trainable params: 1,453,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xokR6cw199e9"
      },
      "source": [
        "Bidirectional wrapper doubles the units so the representation will go from **64 to 128**. \n",
        "\n",
        "Bidirectional --> representation gets doubled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gammsj0F-g-D"
      },
      "source": [
        "# Compile the model \n",
        "model_4.compile(loss = tf.keras.losses.BinaryCrossentropy() , \n",
        "                optimizer = tf.keras.optimizers.Adam() , \n",
        "                metrics = ['accuracy'])"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB0-GE-j-vIm",
        "outputId": "7b364590-7211-4bae-e4fb-ddc92e4c6983"
      },
      "source": [
        "# Fit the model \n",
        "model_4_history = model_4.fit(train_sentences , \n",
        "                              train_labels , \n",
        "                              validation_data = (val_sentences , val_labels) , \n",
        "                              epochs = 5 , \n",
        "                              callbacks = [create_tensorboard_callback(dir_name= SAVE_DIR , \n",
        "                                                                       experiment_name = 'model_4_bidirectional')])\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20210606-045359\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 12s 31ms/step - loss: 0.0924 - accuracy: 0.9689 - val_loss: 1.1260 - val_accuracy: 0.7690\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 22ms/step - loss: 0.0528 - accuracy: 0.9765 - val_loss: 1.2589 - val_accuracy: 0.7651\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 22ms/step - loss: 0.0449 - accuracy: 0.9794 - val_loss: 1.3206 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 5s 22ms/step - loss: 0.0429 - accuracy: 0.9803 - val_loss: 1.4612 - val_accuracy: 0.7677\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.0368 - accuracy: 0.9815 - val_loss: 1.5821 - val_accuracy: 0.7598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Dl7eBhm_W32"
      },
      "source": [
        "Usually adding a bidirectional to a sequences increase the trainin time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2qQW5XT_DjD",
        "outputId": "6e773628-dccf-4f26-8377-9bc9cc52e252"
      },
      "source": [
        "# Make predictions without our model 4 \n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.013e-01],\n",
              "       [8.423e-01],\n",
              "       [1.000e+00],\n",
              "       [2.554e-01],\n",
              "       [3.242e-05],\n",
              "       [1.000e+00],\n",
              "       [9.980e-01],\n",
              "       [1.000e+00],\n",
              "       [1.000e+00],\n",
              "       [1.000e+00]], dtype=float16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zOOO2mv_TAO",
        "outputId": "9f7b27c4-e3e6-478e-a972-3b3f94ec9c2f"
      },
      "source": [
        "# Convert pred probs to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float16, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float16)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmfL6HHp_meF",
        "outputId": "fa0bb996-599f-4219-9a8d-0cb0190bb06d"
      },
      "source": [
        "# Calculate the results of our bidirectional model \n",
        "model_4_results = classification_evaluation_metrics(val_labels , \n",
        "                                                    model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 75.98425196850394,\n",
              " 'F1_Score: ': 0.7404255319148935,\n",
              " 'Precision: ': 0.7310924369747899,\n",
              " 'Recall: ': 0.75}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkujnupg_wd-"
      },
      "source": [
        "Hmm.. Our bidirectional model is performing worse than our uni-directional models. \n",
        "\n",
        "We should emphasize from this that not all experiments will go well. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMWEvJvEQ21D"
      },
      "source": [
        "## Convolutional Neural Networks for Text (and other types of sequences)\n",
        "\n",
        "We've used CNN's for images but images are typically 2D (height x width).... however, our text data is 1D. \n",
        "\n",
        "Previously we've used Conv2D for our image data but now we're going to use Conv1D. \n",
        "\n",
        "The typical structure of a Conv1D model for sequences (in our case, text): \n",
        "```\n",
        "Inputs (text) --> Tokenization --> Embedding --> Layer(s) (typically Conv1D + pooling) --> Outputs (class probabilities)\n",
        "```\n",
        "\n",
        "https://stackoverflow.com/questions/42883547/intuitive-understanding-of-1d-2d-and-3d-convolutions-in-convolutional-neural-n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyHbWuM6XK4K"
      },
      "source": [
        "## Model 5: Conv1D\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwnGWxojXaRP"
      },
      "source": [
        "# Test our our embedding layer , COnv1D layer and max pooling (Let's look into inputs and outputs)\n",
        "from tensorflow.keras import layers\n",
        "# Turn target sequence into a embedding\n",
        "embedding_test = embedding(text_vectorizer(['this is a test sentence']))\n",
        "\n",
        "# Building a Conv1D layer\n",
        "conv_1d = layers.Conv1D(filters = 32 , \n",
        "                        kernel_size = 5 , # this is salso referred to as ngrams of 5 (means group of 5 words at a time)\n",
        "                        activation = 'relu' , \n",
        "                        padding = 'valid')\n",
        "\n",
        "# Conv1D output \n",
        "conv_1d_output = conv_1d(embedding_test) # pass test embedding through conv1d layer\n",
        "\n",
        "# Poolin layer \n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "\n",
        "# Output of our max pool layer \n",
        "# equivalent to get the most important features (or) get the features with highest value\n",
        "max_pool_output = max_pool(conv_1d_output)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JNjj6FIZQl3",
        "outputId": "c6d108ed-370c-4bdf-d9a5-b763f1014e23"
      },
      "source": [
        "# Checking the shapes \n",
        "embedding_test.shape , conv_1d_output.shape , max_pool_output.shape"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ICQTjQhZWZA",
        "outputId": "04c76873-cc3d-494c-ac5e-ab9fec927aa5"
      },
      "source": [
        "# Our embedding text\n",
        "embedding_test"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float16, numpy=\n",
              "array([[[-0.0547  , -0.0659  , -0.105   , ...,  0.00571 , -0.0649  ,\n",
              "          0.0919  ],\n",
              "        [-0.0866  , -0.0779  , -0.03117 , ..., -0.0707  ,  0.05228 ,\n",
              "         -0.003128],\n",
              "        [-0.09155 , -0.0555  ,  0.01539 , ..., -0.05893 , -0.04358 ,\n",
              "          0.04276 ],\n",
              "        ...,\n",
              "        [-0.01408 , -0.03009 , -0.03403 , ..., -0.01611 ,  0.003025,\n",
              "          0.0421  ],\n",
              "        [-0.01408 , -0.03009 , -0.03403 , ..., -0.01611 ,  0.003025,\n",
              "          0.0421  ],\n",
              "        [-0.01408 , -0.03009 , -0.03403 , ..., -0.01611 ,  0.003025,\n",
              "          0.0421  ]]], dtype=float16)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83mfFKX6bnK4",
        "outputId": "68fe7bc4-82b1-46cb-eca7-9e80f64abebe"
      },
      "source": [
        "# Our Conv1D output \n",
        "conv_1d_output"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 11, 32), dtype=float16, numpy=\n",
              "array([[[0.       , 0.0349   , 0.01683  , 0.04355  , 0.       ,\n",
              "         0.0894   , 0.038    , 0.       , 0.01741  , 0.0781   ,\n",
              "         0.       , 0.       , 0.0639   , 0.02168  , 0.02248  ,\n",
              "         0.06143  , 0.007637 , 0.01692  , 0.       , 0.0727   ,\n",
              "         0.       , 0.0868   , 0.1613   , 0.       , 0.       ,\n",
              "         0.       , 0.05475  , 0.02026  , 0.08746  , 0.       ,\n",
              "         0.       , 0.0244   ],\n",
              "        [0.       , 0.0779   , 0.       , 0.02107  , 0.05988  ,\n",
              "         0.       , 0.01047  , 0.0003817, 0.0535   , 0.01906  ,\n",
              "         0.       , 0.       , 0.       , 0.03552  , 0.       ,\n",
              "         0.002104 , 0.001564 , 0.0745   , 0.02745  , 0.02847  ,\n",
              "         0.0795   , 0.03918  , 0.03091  , 0.       , 0.       ,\n",
              "         0.       , 0.0139   , 0.       , 0.03802  , 0.0957   ,\n",
              "         0.       , 0.       ],\n",
              "        [0.       , 0.       , 0.       , 0.1337   , 0.       ,\n",
              "         0.       , 0.       , 0.       , 0.03964  , 0.04373  ,\n",
              "         0.       , 0.       , 0.0795   , 0.       , 0.       ,\n",
              "         0.04913  , 0.       , 0.04526  , 0.093    , 0.04938  ,\n",
              "         0.       , 0.01964  , 0.003632 , 0.01197  , 0.       ,\n",
              "         0.0341   , 0.       , 0.       , 0.0888   , 0.05838  ,\n",
              "         0.       , 0.04208  ],\n",
              "        [0.       , 0.0294   , 0.0597   , 0.       , 0.01921  ,\n",
              "         0.       , 0.       , 0.       , 0.0152   , 0.04947  ,\n",
              "         0.       , 0.0381   , 0.03186  , 0.       , 0.01749  ,\n",
              "         0.       , 0.       , 0.0677   , 0.       , 0.05423  ,\n",
              "         0.       , 0.089    , 0.01953  , 0.       , 0.       ,\n",
              "         0.       , 0.       , 0.       , 0.025    , 0.1029   ,\n",
              "         0.       , 0.03006  ],\n",
              "        [0.00475  , 0.       , 0.       , 0.06     , 0.01608  ,\n",
              "         0.       , 0.       , 0.004467 , 0.0342   , 0.04456  ,\n",
              "         0.       , 0.01213  , 0.0648   , 0.01039  , 0.005493 ,\n",
              "         0.01785  , 0.001153 , 0.00926  , 0.010826 , 0.0405   ,\n",
              "         0.0002216, 0.       , 0.       , 0.       , 0.       ,\n",
              "         0.       , 0.       , 0.0186   , 0.0985   , 0.02074  ,\n",
              "         0.       , 0.005447 ],\n",
              "        [0.       , 0.       , 0.02396  , 0.05136  , 0.02164  ,\n",
              "         0.       , 0.       , 0.       , 0.       , 0.04446  ,\n",
              "         0.       , 0.015434 , 0.0874   , 0.01671  , 0.       ,\n",
              "         0.00399  , 0.       , 0.03583  , 0.       , 0.04382  ,\n",
              "         0.01432  , 0.       , 0.002611 , 0.       , 0.       ,\n",
              "         0.       , 0.       , 0.       , 0.09424  , 0.02286  ,\n",
              "         0.       , 0.01834  ],\n",
              "        [0.       , 0.       , 0.02396  , 0.05136  , 0.02164  ,\n",
              "         0.       , 0.       , 0.       , 0.       , 0.04446  ,\n",
              "         0.       , 0.015434 , 0.0874   , 0.01671  , 0.       ,\n",
              "         0.00399  , 0.       , 0.03583  , 0.       , 0.04382  ,\n",
              "         0.01432  , 0.       , 0.002611 , 0.       , 0.       ,\n",
              "         0.       , 0.       , 0.       , 0.09424  , 0.02286  ,\n",
              "         0.       , 0.01834  ],\n",
              "        [0.       , 0.       , 0.02396  , 0.05136  , 0.02164  ,\n",
              "         0.       , 0.       , 0.       , 0.       , 0.04446  ,\n",
              "         0.       , 0.015434 , 0.0874   , 0.01671  , 0.       ,\n",
              "         0.00399  , 0.       , 0.03583  , 0.       , 0.04382  ,\n",
              "         0.01432  , 0.       , 0.002611 , 0.       , 0.       ,\n",
              "         0.       , 0.       , 0.       , 0.09424  , 0.02286  ,\n",
              "         0.       , 0.01834  ],\n",
              "        [0.       , 0.       , 0.02396  , 0.05136  , 0.02164  ,\n",
              "         0.       , 0.       , 0.       , 0.       , 0.04446  ,\n",
              "         0.       , 0.015434 , 0.0874   , 0.01671  , 0.       ,\n",
              "         0.00399  , 0.       , 0.03583  , 0.       , 0.04382  ,\n",
              "         0.01432  , 0.       , 0.002611 , 0.       , 0.       ,\n",
              "         0.       , 0.       , 0.       , 0.09424  , 0.02286  ,\n",
              "         0.       , 0.01834  ],\n",
              "        [0.       , 0.       , 0.02396  , 0.05136  , 0.02164  ,\n",
              "         0.       , 0.       , 0.       , 0.       , 0.04446  ,\n",
              "         0.       , 0.015434 , 0.0874   , 0.01671  , 0.       ,\n",
              "         0.00399  , 0.       , 0.03583  , 0.       , 0.04382  ,\n",
              "         0.01432  , 0.       , 0.002611 , 0.       , 0.       ,\n",
              "         0.       , 0.       , 0.       , 0.09424  , 0.02286  ,\n",
              "         0.       , 0.01834  ],\n",
              "        [0.       , 0.       , 0.02396  , 0.05136  , 0.02164  ,\n",
              "         0.       , 0.       , 0.       , 0.       , 0.04446  ,\n",
              "         0.       , 0.015434 , 0.0874   , 0.01671  , 0.       ,\n",
              "         0.00399  , 0.       , 0.03583  , 0.       , 0.04382  ,\n",
              "         0.01432  , 0.       , 0.002611 , 0.       , 0.       ,\n",
              "         0.       , 0.       , 0.       , 0.09424  , 0.02286  ,\n",
              "         0.       , 0.01834  ]]], dtype=float16)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0623c-mbtIq",
        "outputId": "cd4cbe01-bd0b-434a-9e62-d2d03745b9ff"
      },
      "source": [
        "# Condense our conv1d \n",
        "# We take max across [1 , 15 , 64] and condense into \n",
        "max_pool_output"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 32), dtype=float16, numpy=\n",
              "array([[0.00475 , 0.0779  , 0.0597  , 0.1337  , 0.05988 , 0.0894  ,\n",
              "        0.038   , 0.004467, 0.0535  , 0.0781  , 0.      , 0.0381  ,\n",
              "        0.0874  , 0.03552 , 0.02248 , 0.06143 , 0.007637, 0.0745  ,\n",
              "        0.093   , 0.0727  , 0.0795  , 0.089   , 0.1613  , 0.01197 ,\n",
              "        0.      , 0.0341  , 0.05475 , 0.02026 , 0.0985  , 0.1029  ,\n",
              "        0.      , 0.04208 ]], dtype=float16)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhH1fwlCcA9w"
      },
      "source": [
        "Taking on the challenge and building a Conv1D model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJUpx-6sdJjB",
        "outputId": "adea8617-f518-4c86-9c44-357625ebddc5"
      },
      "source": [
        "# Creating Conv1D sequence model \n",
        "inputs = layers.Input(shape = (1, ) , dtype = tf.string)\n",
        "\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(f'Shape after embedding: {x.shape}')\n",
        "\n",
        "# Our Conv1D layer \n",
        "x = layers.Conv1D(filters = 32 , \n",
        "                  kernel_size = 5 , \n",
        "                  padding = 'same' , \n",
        "                  activation = 'relu')(x)\n",
        "print(f'Shape after Conv1D: {x.shape}')\n",
        "x = layers.Dense(64 , activation= 'relu')(x)\n",
        "print(f'Shape after into the Dense layer: {x.shape}')\n",
        "# GlobalMaxPool1D works better\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "print(f'Shape after into the GlobalMaxPool layer: {x.shape}')\n",
        "\n",
        "# Output layer \n",
        "outputs = layers.Dense(1 , activation= 'sigmoid')(x)\n",
        "\n",
        "# Packing into a model \n",
        "test_model_5 = tf.keras.Model(inputs , outputs)\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape after embedding: (None, 15, 128)\n",
            "Shape after Conv1D: (None, 15, 32)\n",
            "Shape after into the Dense layer: (None, 15, 64)\n",
            "Shape after into the GlobalMaxPool layer: (None, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAafruRsej-j"
      },
      "source": [
        "# Compile the model \n",
        "test_model_5.compile(loss = tf.keras.losses.BinaryCrossentropy(), \n",
        "                   optimizer = tf.keras.optimizers.Adam() ,\n",
        "                   metrics = ['accuracy'])"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztwx5_SNe1HR",
        "outputId": "9dfc8038-a4fc-4dc9-c8be-3f24b5ed7089"
      },
      "source": [
        "# Fitting the model \n",
        "test_model_5.fit(train_sentences , \n",
        "                 train_labels , \n",
        "                 validation_data = (val_sentences , val_labels), \n",
        "                 epochs = 5 )"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 18ms/step - loss: 0.1211 - accuracy: 0.9645 - val_loss: 0.9255 - val_accuracy: 0.7703\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0617 - accuracy: 0.9765 - val_loss: 1.0244 - val_accuracy: 0.7559\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0535 - accuracy: 0.9778 - val_loss: 1.2176 - val_accuracy: 0.7730\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0459 - accuracy: 0.9803 - val_loss: 1.2438 - val_accuracy: 0.7651\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0432 - accuracy: 0.9810 - val_loss: 1.1624 - val_accuracy: 0.7703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f350c4b1e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8snmQxifFXr"
      },
      "source": [
        "Now following the video \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enQkza5Af0lt",
        "outputId": "87eebda2-c19c-4d90-b914-891b384357ef"
      },
      "source": [
        "# Creating Conv1D sequence model \n",
        "inputs = layers.Input(shape = (1, ) , dtype = tf.string)\n",
        "\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(f'Shape after embedding: {x.shape}')\n",
        "\n",
        "# Our Conv1D layer \n",
        "x = layers.Conv1D(filters = 32 , \n",
        "                  kernel_size = 5 , \n",
        "                  padding = 'same' , \n",
        "                  activation = 'relu')(x)\n",
        "print(f'Shape after Conv1D: {x.shape}')\n",
        "#x = layers.Dense(64 , activation= 'relu')(x)\n",
        "#print(f'Shape after into the Dense layer: {x.shape}')\n",
        "# GlobalMaxPool1D works better\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "print(f'Shape after into the GlobalMaxPool layer: {x.shape}')\n",
        "\n",
        "# Output layer \n",
        "outputs = layers.Dense(1 , activation= 'sigmoid')(x)\n",
        "\n",
        "# Packing into a model \n",
        "model_5 = tf.keras.Model(inputs , outputs , name = 'model_5_conv_1d')\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape after embedding: (None, 15, 128)\n",
            "Shape after Conv1D: (None, 15, 32)\n",
            "Shape after into the GlobalMaxPool layer: (None, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxDJ5Jxef8oR"
      },
      "source": [
        "# Compile the model \n",
        "model_5.compile(loss = tf.keras.losses.BinaryCrossentropy(), \n",
        "                   optimizer = tf.keras.optimizers.Adam() ,\n",
        "                   metrics = ['accuracy'])"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7QwQAH7f_bY",
        "outputId": "9be6a3c9-2ea0-472b-ed32-f8bb697e5ca6"
      },
      "source": [
        "model_5.summary()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5_conv_1d\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 15, 32)            20512     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,300,545\n",
            "Trainable params: 1,300,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctHZYYTHgCTd",
        "outputId": "ecdba93a-aa3a-48a5-ddc9-a722eec91838"
      },
      "source": [
        "# Fitting the model \n",
        "model_5.fit(train_sentences , \n",
        "                 train_labels , \n",
        "                 validation_data = (val_sentences , val_labels), \n",
        "                 epochs = 5 , \n",
        "            callbacks = [create_tensorboard_callback(dir_name = SAVE_DIR , \n",
        "                                                     experiment_name = 'model_5_1d_conv_layer')])"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_5_1d_conv_layer/20210606-045516\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 20ms/step - loss: 0.1035 - accuracy: 0.9664 - val_loss: 0.8781 - val_accuracy: 0.7756\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0533 - accuracy: 0.9783 - val_loss: 1.0289 - val_accuracy: 0.7664\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0468 - accuracy: 0.9807 - val_loss: 1.1177 - val_accuracy: 0.7533\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0432 - accuracy: 0.9823 - val_loss: 1.1731 - val_accuracy: 0.7572\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0429 - accuracy: 0.9818 - val_loss: 1.2141 - val_accuracy: 0.7480\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f350c139ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVPdSIt4ghNh",
        "outputId": "4acf6f9d-0631-4cb2-c5e1-6ad7efbebfcf"
      },
      "source": [
        "# Make some predictions with our Conv1D model \n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03644],\n",
              "       [0.6616 ],\n",
              "       [1.     ],\n",
              "       [0.04434],\n",
              "       [0.     ],\n",
              "       [0.995  ],\n",
              "       [0.9316 ],\n",
              "       [1.     ],\n",
              "       [1.     ],\n",
              "       [0.766  ]], dtype=float16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6UABkWeg163",
        "outputId": "b7a9f9f9-e533-4e83-81ea-b5a1fc198513"
      },
      "source": [
        "# Convert model 5 pred probs to labels \n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float16, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float16)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI6f_kVCg-zf"
      },
      "source": [
        "# Evaluate model 5 predictions \n",
        "model_5_results = classification_evaluation_metrics(val_labels , \n",
        "                                                    model_5_preds)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fXsTp0EhHIS",
        "outputId": "49088bde-d039-4bd8-9a04-fb15326c3eda"
      },
      "source": [
        "model_5_results"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 74.80314960629921,\n",
              " 'F1_Score: ': 0.709090909090909,\n",
              " 'Precision: ': 0.75,\n",
              " 'Recall: ': 0.6724137931034483}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP0YwMplhKSf",
        "outputId": "d41ab10c-00a5-4c85-aef7-bfc61975176d"
      },
      "source": [
        "# Our base line model \n",
        "naive_baseline_results"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 79.26509186351706,\n",
              " 'F1_Score: ': 0.734006734006734,\n",
              " 'Precision: ': 0.8861788617886179,\n",
              " 'Recall: ': 0.6264367816091954}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbdRn1kphO4U"
      },
      "source": [
        "##   Using TensorFlow Hub for pretrained word embeddings (transfer learning for NLP)\n",
        "\n",
        "\n",
        "For our next model, instead of using our own embedding layer, we're going to replace it with a pretrained embedding layer.\n",
        "\n",
        "We have built few of our own models, now let's use a pretrained one.\n",
        "\n",
        "Now we're gonna build a feature extractor called USE that is Universal Sentence Encoder.\n",
        "- **Encoder** —> Encodes sequence into numerical representation.\n",
        "- **Decoder** —> Decode sequence into a desired output.\n",
        "\n",
        "More specifically, we're going to be using the [Universal Sentence Encoder](https://tfhub.dev/google/collections/universal-sentence-encoder/1)from TensorFlow Hub (a great resource containing a plethora of pretrained model resources for a variety of tasks)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ng7R_cc2Y8gP",
        "outputId": "d2313b11-cd3f-488a-a62b-045cee5e6cfa"
      },
      "source": [
        "sample_sentence"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"There's a flood in my street!\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_ZHypGPUijD",
        "outputId": "9842e2c0-d6f6-4153-e926-058c8fc54882"
      },
      "source": [
        "# Importing the tensorflow hub \n",
        "import tensorflow_hub as hub \n",
        "embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n",
        "\n",
        "# Getting a glimpse of the pretrained model \n",
        "embed_samples = embed([sample_sentence , \n",
        "                       'When you call a universal sentence encoder on a sentence, it turns it into a numbers.'])\n",
        "print(embed_samples)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.01157027  0.0248591   0.02878048 ... -0.00186125  0.02315824\n",
            "  -0.01485021]\n",
            " [ 0.02950276 -0.08060793 -0.01373591 ... -0.0278922   0.02430332\n",
            "  -0.0008201 ]], shape=(2, 512), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4FEMIxkZMZj"
      },
      "source": [
        "It turned our sentence into a numerical representation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYUcY7X3Zh6V",
        "outputId": "87d5b6ec-bf08-4f9f-9dcd-0d8687145881"
      },
      "source": [
        "# Shape of the embed_sample \n",
        "embed_samples[0].shape"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkluCP0ZaBzn"
      },
      "source": [
        "**Creating a Keras layer using USE pre-trained layer from tensorflow hub.**\n",
        "\n",
        "We can use the link of the pre-trained model and use it in a Keras layer and turn this into. feature extractor layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb_8jA6vaa01"
      },
      "source": [
        "# Creating a Keras layer \n",
        "sentence_encoder_layer = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4' , \n",
        "                                        input_shape = [] , # Defining a input shape so our layer will take anything sequence as a input (any variable length)\n",
        "                                        dtype = tf.string , \n",
        "                                        trainable = False , \n",
        "                                        name = 'USE_Layer'\n",
        "                                        )"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTuF8w5pQ1R0",
        "outputId": "85cf4874-93f5-4d32-e65a-1f677d221b3f"
      },
      "source": [
        "# Create model using Sequential API \n",
        "model_6 = tf.keras.Sequential([\n",
        "  # We don't need a text vectorizer and embedding layer this will take care of the pre processing behind the scenes\n",
        "  sentence_encoder_layer, \n",
        "  #layers.Dense(64 , activation = 'relu'), \n",
        "  layers.Dense(1 , activation ='sigmoid')\n",
        "]  , name = 'model_6_USE')\n",
        "\n",
        "# Compiling the model \n",
        "model_6.compile(loss = tf.keras.losses.BinaryCrossentropy() , \n",
        "                optimizer = tf.keras.optimizers.Adam() , \n",
        "                metrics = ['accuracy'])\n",
        "# Model 6 summary \n",
        "model_6.summary()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE_Layer (KerasLayer)       (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 256,798,337\n",
            "Trainable params: 513\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAQvYK_kRfxj",
        "outputId": "53b320fa-e4f9-4678-f347-40be6fa40853"
      },
      "source": [
        "model_6.summary()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE_Layer (KerasLayer)       (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 256,798,337\n",
            "Trainable params: 513\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q4EkgbwdMkG",
        "outputId": "b3497fa3-ad80-4f51-8c6c-d90fc368180d"
      },
      "source": [
        "# Train a classifier on top of USE pretrained embeddings \n",
        "model_6_history = model_6.fit(train_sentences , \n",
        "                              train_labels , \n",
        "                              epochs = 5 , \n",
        "                              validation_data = (val_sentences , val_labels), \n",
        "                              callbacks = [create_tensorboard_callback(dir_name = SAVE_DIR , \n",
        "                                                                       experiment_name = 'tf_hub_sentence_encoder')])"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20210606-045557\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 23ms/step - loss: 0.6484 - accuracy: 0.7313 - val_loss: 0.6141 - val_accuracy: 0.7835\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.5811 - accuracy: 0.7851 - val_loss: 0.5645 - val_accuracy: 0.7769\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.5384 - accuracy: 0.7921 - val_loss: 0.5326 - val_accuracy: 0.7861\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.5098 - accuracy: 0.7978 - val_loss: 0.5116 - val_accuracy: 0.7874\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.4898 - accuracy: 0.8006 - val_loss: 0.4972 - val_accuracy: 0.7900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9WmP8a1lxcx",
        "outputId": "628f04fd-9ba7-4983-cec5-b438790c0a2d"
      },
      "source": [
        "# Does it beating our baseline model? \n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:5]"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3733],\n",
              "       [0.6733],\n",
              "       [0.8643],\n",
              "       [0.3525],\n",
              "       [0.6406]], dtype=float16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xC-YfPwmJuI",
        "outputId": "41e51d27-06f4-4cc5-9735-29827f6326a7"
      },
      "source": [
        "# Convert prediction probabilities to labels \n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float16, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float16)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Expm1YwmYHI",
        "outputId": "30e00af9-d37b-4f58-b8d4-77c38b454279"
      },
      "source": [
        "# Calculate model 6 performance metrics \n",
        "model_6_results = classification_evaluation_metrics(val_labels , \n",
        "                                                    model_6_preds )\n",
        "model_6_results"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 79.00262467191601,\n",
              " 'F1_Score: ': 0.7583081570996978,\n",
              " 'Precision: ': 0.7993630573248408,\n",
              " 'Recall: ': 0.7212643678160919}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZjXOfwTmlp8",
        "outputId": "c8464edb-adb8-461c-c4e8-66c9cb5c3e8b"
      },
      "source": [
        "# Baseline model\n",
        "naive_baseline_results"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 79.26509186351706,\n",
              " 'F1_Score: ': 0.734006734006734,\n",
              " 'Precision: ': 0.8861788617886179,\n",
              " 'Recall: ': 0.6264367816091954}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eppIFiBnGmX"
      },
      "source": [
        "Adding one dense layer to our pretrained model. We call this is as `improv_model_6`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJVTYBOlnn3S",
        "outputId": "715b58b5-5234-438f-bf79-8e92e72aac79"
      },
      "source": [
        "# Creating the model 6 again \n",
        "tf.random.set_seed(42)\n",
        "\n",
        "improv_model_6 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer , \n",
        "  layers.Dense(64 , activation= 'relu'), \n",
        "  layers.Dense(1 , activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "# Compiling the model \n",
        "improv_model_6.compile(loss = tf.keras.losses.BinaryCrossentropy() , \n",
        "                       optimizer = tf.keras.optimizers.Adam() , \n",
        "                       metrics = ['accuracy'])\n",
        "\n",
        "# Fit the model \n",
        "improv_model_6.fit(train_sentences , \n",
        "                   train_labels , \n",
        "                   validation_data = (val_sentences , val_labels) , \n",
        "                   epochs = 5 )"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 12ms/step - loss: 0.5050 - accuracy: 0.7808 - val_loss: 0.4473 - val_accuracy: 0.7966\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.4143 - accuracy: 0.8149 - val_loss: 0.4355 - val_accuracy: 0.8123\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3992 - accuracy: 0.8225 - val_loss: 0.4309 - val_accuracy: 0.8110\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3914 - accuracy: 0.8254 - val_loss: 0.4263 - val_accuracy: 0.8136\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3846 - accuracy: 0.8305 - val_loss: 0.4284 - val_accuracy: 0.8176\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f347356c6d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjCNtqlU7Yq4",
        "outputId": "92d72103-f9b4-4a4f-9ee0-de8bb535715f"
      },
      "source": [
        "# Model summary \n",
        "improv_model_6.summary()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE_Layer (KerasLayer)       (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KylPzQCVoT0H"
      },
      "source": [
        "OHH BOY! Atlast adding one additional dense layer managed to beat our base line model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLU142kAokpj",
        "outputId": "66b17f92-8725-4723-b879-e0f7461b9856"
      },
      "source": [
        "# Getting the prediction probs \n",
        "improv_model_6_pred_probs = improv_model_6.predict(val_sentences)\n",
        "improv_model_6_pred_probs[:5]"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.1592],\n",
              "       [0.7427],\n",
              "       [0.992 ],\n",
              "       [0.2134],\n",
              "       [0.717 ]], dtype=float16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQXe_zKnoyDW",
        "outputId": "4ceb5517-460d-4e7f-a8e1-1e314c450161"
      },
      "source": [
        "# Converting into labels \n",
        "improv_model_6_preds = tf.squeeze(tf.round(improv_model_6_pred_probs))\n",
        "improv_model_6_pred_probs[:10]"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.1592],\n",
              "       [0.7427],\n",
              "       [0.992 ],\n",
              "       [0.2134],\n",
              "       [0.717 ],\n",
              "       [0.675 ],\n",
              "       [0.9863],\n",
              "       [0.978 ],\n",
              "       [0.931 ],\n",
              "       [0.0875]], dtype=float16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdCvofKLo87s",
        "outputId": "17bf8b6a-061b-48f3-af69-31c30bedf716"
      },
      "source": [
        "# Getting our classification report \n",
        "improv_model_6_results = classification_evaluation_metrics(val_labels , \n",
        "                                                           improv_model_6_preds)\n",
        "improv_model_6_results"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 81.75853018372703,\n",
              " 'F1_Score: ': 0.785824345146379,\n",
              " 'Precision: ': 0.8471760797342193,\n",
              " 'Recall: ': 0.7327586206896551}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3oC0EZApJGl",
        "outputId": "ad0c9822-bb45-4ede-d65b-f999b9b7c918"
      },
      "source": [
        "# Our base line results \n",
        "naive_baseline_results"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 79.26509186351706,\n",
              " 'F1_Score: ': 0.734006734006734,\n",
              " 'Precision: ': 0.8861788617886179,\n",
              " 'Recall: ': 0.6264367816091954}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjrJB-Y7pOPg"
      },
      "source": [
        "## Model 7: TF Hub Pretrained USE but with 10% of the training data \n",
        "\n",
        "Transfer learning really helps when you don't have a large dataset. To see how our model performs on a smaller dataset, let's replicate `model_6` except train with 10% of the training data. \n",
        "\n",
        ">Note: Always experiment with a small portion of your data so that we can run more experiments on our data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udwLJqqS9nJI",
        "outputId": "75f15ff4-09b3-4d36-b6d5-3aa6b4e65c9f"
      },
      "source": [
        "# NOTE: Making data splits like below leads to data leakages (model_7 trained on 10% data, outperforms model trained on the whole data)\n",
        "# DO NOT MAKE DATA SPLITS WHICH LEAK DATA FROM VALIDATION/TEST SETS INTO TRAINING SET\n",
        "\n",
        "# Create subsets of 10% of the training data \n",
        "train_10_percent = train_df_shuffled[['text' , 'target']].sample(frac = 0.1 , random_state = 42)\n",
        "print(f'Only the 10% of the train data shuffled: {train_10_percent.shape[0]}') \n",
        "print(f'The whole data: {train_df_shuffled.shape[0]}')"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Only the 10% of the train data shuffled: 761\n",
            "The whole data: 7613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emi2B36R-i72",
        "outputId": "e7c72f07-9003-4f98-96af-5011576fd52e"
      },
      "source": [
        "# Now the same with train_sentences (scraping just the text)\n",
        "train_sentences_10_percent = train_10_percent['text'].to_list()\n",
        "train_sentences_10_percent[:5] , len(train_sentences_10_percent) # 761 that is 10% of the text data"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['DFR EP016 Monthly Meltdown - On Dnbheaven 2015.08.06 http://t.co/EjKRf8N8A8 #Drum and Bass #heavy #nasty http://t.co/SPHWE6wFI5',\n",
              "  'FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps http://t.co/qZQc8WWwcN via @usatoday',\n",
              "  'Gunmen kill four in El Salvador bus attack: Suspected Salvadoran gang members killed four people and wounded s... http://t.co/CNtwB6ScZj',\n",
              "  '@camilacabello97 Internally and externally screaming',\n",
              "  'Radiation emergency #preparedness starts with knowing to: get inside stay inside and stay tuned http://t.co/RFFPqBAz2F via @CDCgov'],\n",
              " 761)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtxB7ERl_O1Z",
        "outputId": "cb69057f-a0c2-4c1c-fd5f-7e63ba8f6557"
      },
      "source": [
        "# Scraping 10% of the labels \n",
        "train_labels_10_percent = train_10_percent['target'].to_list()\n",
        "len(train_labels_10_percent) "
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "761"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEDTbskt_kJG",
        "outputId": "250d159c-a078-482d-e0eb-c62cdb0a518a"
      },
      "source": [
        "# Check the number of targets in our subset of data \n",
        "train_10_percent['target'].value_counts()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    413\n",
              "1    348\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVX7WNJ__xlM",
        "outputId": "e46f1cbd-5c8c-4bca-f30d-8d2780d6bc5f"
      },
      "source": [
        "# Checking if the ratio is similar (or very close)\n",
        "train_df_shuffled['target'].value_counts()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSiDsPUMABDL"
      },
      "source": [
        "While creating a subset of our data we should pay real attention to the distribution is fairly close or equal distribution. \n",
        "\n",
        "**Building a similar model to `model_6` but with only 10% of the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Vhcn9eNAxJq"
      },
      "source": [
        "# Trying to build the sentence encoder layer with no input shape and dtype \n",
        "func_sentence_encoder_layer = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4' , \n",
        "                                             trainable = False , \n",
        "                                             name = 'Functional_USE_layer')"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHASb6C4COn2"
      },
      "source": [
        "To fix the shape error https://stackoverflow.com/questions/60634839/using-tf-hub-keraslayer-in-tf-2-1-functional-api-throws-valueerror-python-input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MM4dqddRAJCy",
        "outputId": "201eb8c1-79ff-4eac-dae8-0261d6f93b26"
      },
      "source": [
        "# Creating model_7 (Using functional API)\n",
        "inputs = layers.Input(shape=() , dtype = tf.string , name = 'input_layer')\n",
        "\n",
        "# Getting our functional sentence encoder in our model\n",
        "x = func_sentence_encoder_layer(inputs)\n",
        "x = layers.Dense(64 , activation=  'relu')(x)\n",
        "\n",
        "# Our ouputs \n",
        "outputs = layers.Dense(1 , activation = 'sigmoid' , name = 'output_layer')(x)\n",
        "\n",
        "# Packing into a model \n",
        "functional_model_7 = tf.keras.Model(inputs , outputs , name = 'functional_model_7')\n",
        "\n",
        "# Compiling the model \n",
        "functional_model_7.compile(loss = tf.keras.losses.BinaryCrossentropy() , \n",
        "                           optimizer = tf.keras.optimizers.Adam() , \n",
        "                           metrics = ['accuracy'])\n",
        "\n",
        "# Getting the summary of the model \n",
        "functional_model_7.summary()\n"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (InputLayer)     [(None,)]                 0         \n",
            "_________________________________________________________________\n",
            "Functional_USE_layer (KerasL (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_ZySmexBhO8",
        "outputId": "030c2b7d-9425-4a54-acc7-ae2cc9cc2310"
      },
      "source": [
        "# Fitting the functional model with only the 10% of the data \n",
        "functional_model_7_history = functional_model_7.fit(train_sentences_10_percent , \n",
        "                                                    train_labels_10_percent , \n",
        "                                                    epochs = 5 , \n",
        "                                                    validation_data = (val_sentences , val_labels))"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "24/24 [==============================] - 3s 34ms/step - loss: 0.6725 - accuracy: 0.6544 - val_loss: 0.6340 - val_accuracy: 0.7835\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.5993 - accuracy: 0.7911 - val_loss: 0.5541 - val_accuracy: 0.7992\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.5211 - accuracy: 0.8042 - val_loss: 0.4833 - val_accuracy: 0.8136\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.4623 - accuracy: 0.8108 - val_loss: 0.4363 - val_accuracy: 0.8189\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.4245 - accuracy: 0.8160 - val_loss: 0.4052 - val_accuracy: 0.8281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s4eVxlOCrM7"
      },
      "source": [
        "Doing the same with a sequential API to see both the results are same"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XrfdiiWEACY",
        "outputId": "18eaa0ef-e88f-441e-b3e1-52d226b49a14"
      },
      "source": [
        "# Building model 7 with a sequential api \n",
        "\n",
        "model_7 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer, \n",
        "  layers.Dense(64 , activation ='relu'), \n",
        "  layers.Dense(1 , activation = 'sigmoid')\n",
        "] , name = 'model_7')\n",
        "\n",
        "# Compiling the model \n",
        "model_7.compile(loss = tf.keras.losses.BinaryCrossentropy() , \n",
        "                optimizer = tf.keras.optimizers.Adam() , \n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the model \n",
        "model_7_history = model_7.fit(train_sentences_10_percent , \n",
        "                              train_labels_10_percent  , \n",
        "                              validation_data = (val_sentences , val_labels) , \n",
        "                              epochs = 5)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "24/24 [==============================] - 2s 35ms/step - loss: 0.6739 - accuracy: 0.6518 - val_loss: 0.6376 - val_accuracy: 0.7782\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.6048 - accuracy: 0.7832 - val_loss: 0.5616 - val_accuracy: 0.7900\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5292 - accuracy: 0.7963 - val_loss: 0.4914 - val_accuracy: 0.7979\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.4696 - accuracy: 0.8055 - val_loss: 0.4427 - val_accuracy: 0.8189\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.4299 - accuracy: 0.8121 - val_loss: 0.4102 - val_accuracy: 0.8215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IisSD8YfEqEh"
      },
      "source": [
        "# Getting the prediction probabilities for both \n",
        "functional_model_7_pred_probs = functional_model_7.predict(val_sentences)\n",
        "model_7_pred_probs = model_7.predict(val_sentences)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUe-Pj8BE3Sx",
        "outputId": "9cb12d71-9ee6-4cbf-abf3-c1b898b9a31b"
      },
      "source": [
        "\n",
        "# Converting into labels of prediction \n",
        "functional_model_7_preds = tf.squeeze(tf.round(functional_model_7_pred_probs))\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "\n",
        "functional_model_7_preds[:5] , model_7_preds[:5]"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(5,), dtype=float16, numpy=array([0., 1., 1., 0., 1.], dtype=float16)>,\n",
              " <tf.Tensor: shape=(5,), dtype=float16, numpy=array([0., 1., 1., 0., 1.], dtype=float16)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDGnsfV5FLCf",
        "outputId": "6f2d3db0-7930-415c-a6b7-c528a58d5caa"
      },
      "source": [
        "# Comparing the results with the classification metrics we have \n",
        "\n",
        "functional_model_7_results = classification_evaluation_metrics(val_labels , \n",
        "                                                               functional_model_7_preds)\n",
        "model_7_results = classification_evaluation_metrics(val_labels , \n",
        "                                                    model_7_preds)\n",
        "\n",
        "functional_model_7_results"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 82.80839895013123,\n",
              " 'F1_Score: ': 0.8070692194403535,\n",
              " 'Precision: ': 0.8277945619335347,\n",
              " 'Recall: ': 0.7873563218390804}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCvnnJ9IFhrz",
        "outputId": "f5d0d020-d00a-4ffb-8fc6-402388899e3f"
      },
      "source": [
        "model_7_results"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 82.1522309711286,\n",
              " 'F1_Score: ': 0.8,\n",
              " 'Precision: ': 0.8192771084337349,\n",
              " 'Recall: ': 0.7816091954022989}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nkw67BFFjUS"
      },
      "source": [
        "Alright looking at the video now came to know daniel is using clone model here will give a try!\n",
        "\n",
        "**Clone Model: Copies only the architecture of the model leaving behind the weights / patterns it learned during the training.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1407Tyr-Gv5T",
        "outputId": "8904c08e-426e-49a4-eaf4-3847d296b523"
      },
      "source": [
        "# Cloning the model \n",
        "clone_model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# Compile the model \n",
        "clone_model_7.compile(loss = tf.keras.losses.BinaryCrossentropy() , \n",
        "                      optimizer = tf.keras.optimizers.Adam() , \n",
        "                      metrics = ['accuracy'] ) \n",
        "\n",
        "# Get summary of the model (will be same as model_6)\n",
        "clone_model_7.summary()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE_Layer (KerasLayer)       (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 256,798,337\n",
            "Trainable params: 513\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMWSRLs5Hswt"
      },
      "source": [
        ">**How a model which we trained with 10 times less data out performs a model that it has been trained on the full data?**\n",
        "\n",
        "The answer is data leakage! The problem is how we split our data into training and test data of 10%. \n",
        "\n",
        "When we created our `train_sentences_10_percent` we performed the split from `train_data_shuffled` and it will have some of the data's of `val_sentences`. This is the reason why our model was able to perform well. \n",
        "\n",
        "Data from `val_sentences` leaked into our newly created `train_sentences_10_percent`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI3RRDAqJgfI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d4d558-36ed-438e-8267-53f6f2b9cde2"
      },
      "source": [
        "# Making a better dataset split (no data leakage)\n",
        "train_10_percent_split = int(0.1 * len(train_sentences)) # Directly taking 10% from our train data\n",
        "print(train_10_percent_split)\n",
        "\n",
        "# Splitting our train data with the actual train_data (no double dipping this time)\n",
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "len(train_10_percent)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "685\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "761"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGTuugh4utyZ",
        "outputId": "f56bf3f0-bb5b-4cbc-d09f-b3609057cd71"
      },
      "source": [
        "# Now our 10% data is ready\n",
        "train_sentences_10_percent[:10]"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "       '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "       'destroy the free fandom honestly',\n",
              "       'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "       '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "       'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79alfs69vBOG",
        "outputId": "1137645f-06e7-4e3b-b6e8-660aeeed1d35"
      },
      "source": [
        "# Doing the same but with the train labels \n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]\n",
        "len(train_labels_10_percent) , train_labels_10_percent[:5]"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(685, array([0, 0, 1, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFZS7O6mvdTu",
        "outputId": "67bce15d-1064-438e-fbd3-bd994658e3ea"
      },
      "source": [
        "# How many 1s and 0s are there? \n",
        "pd.Series(np.array(train_labels_10_percent)).value_counts()"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    406\n",
              "1    279\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XEZN87cvv_1",
        "outputId": "4ca6f7ff-ff82-44a2-afb2-f1be9c15a3a3"
      },
      "source": [
        "# Building model 7 with a sequential api \n",
        "\n",
        "model_7 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer, \n",
        "  layers.Dense(64 , activation ='relu'), \n",
        "  layers.Dense(1 , activation = 'sigmoid')\n",
        "] , name = 'model_7')\n",
        "\n",
        "# Compiling the model \n",
        "model_7.compile(loss = tf.keras.losses.BinaryCrossentropy() , \n",
        "                optimizer = tf.keras.optimizers.Adam() , \n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the model \n",
        "model_7_history = model_7.fit(train_sentences_10_percent , \n",
        "                              train_labels_10_percent  , \n",
        "                              validation_data = (val_sentences , val_labels) , \n",
        "                              epochs = 5)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 37ms/step - loss: 0.6709 - accuracy: 0.6978 - val_loss: 0.6493 - val_accuracy: 0.7297\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6013 - accuracy: 0.8146 - val_loss: 0.5905 - val_accuracy: 0.7572\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.5230 - accuracy: 0.8073 - val_loss: 0.5341 - val_accuracy: 0.7612\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.4610 - accuracy: 0.8088 - val_loss: 0.5037 - val_accuracy: 0.7743\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.4196 - accuracy: 0.8307 - val_loss: 0.4878 - val_accuracy: 0.7769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVIiXkSGxzZ7",
        "outputId": "28b7e3d0-53a0-4994-80d7-5613ab3653a5"
      },
      "source": [
        "# Getting the prediction probabilities  \n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "\n",
        "# Converting into labels of prediction \n",
        "\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "\n",
        "model_7_preds[:5]"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=float16, numpy=array([0., 1., 1., 0., 1.], dtype=float16)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuh4oRk-x9S2",
        "outputId": "f0047dd1-c0b6-42fa-b53a-b54e99c2eb50"
      },
      "source": [
        "# Comparing the results with the classification metrics we have \n",
        "model_7_results = classification_evaluation_metrics(val_labels , \n",
        "                                                    model_7_preds)\n",
        "\n",
        "model_7_results"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 77.69028871391076,\n",
              " 'F1_Score: ': 0.7376543209876544,\n",
              " 'Precision: ': 0.7966666666666666,\n",
              " 'Recall: ': 0.6867816091954023}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MysF-Z5WyJ6C"
      },
      "source": [
        "> **🔑 NOTE**: Be very careful when creating training/val/test splits that you don't leak data across the datasets, otherwise your model evaluation metrics will be wrong. If something looks too good to be true (a model trained on 10% of data outperforming the same model trained on 100% of data) trust your gut and go back through to find where the error may lie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miYGHMYPy62Z"
      },
      "source": [
        "## Comparing the performance of each of our models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "LlSbDIFe_CsA",
        "outputId": "8cad7513-8fec-4ffc-ef2a-87a346a427ba"
      },
      "source": [
        "# Combine model results into a dataframe \n",
        "all_model_results = pd.DataFrame({'0_baseline': naive_baseline_results , \n",
        "                                  '1_simple_dense': model_1_results , \n",
        "                                  '2_lstm':model_2_results ,\n",
        "                                  '3_gru': model_3_results , \n",
        "                                  '4_bidirectional': model_4_results , \n",
        "                                  '5_conv1d': model_5_results , \n",
        "                                  '6_tf_hub_use_encoder': model_6_results , \n",
        "                                  '7_tf_hub_use_encoder_10_percent': model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy:</th>\n",
              "      <th>F1_Score:</th>\n",
              "      <th>Precision:</th>\n",
              "      <th>Recall:</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_baseline</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>0.734007</td>\n",
              "      <td>0.886179</td>\n",
              "      <td>0.626437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>78.083990</td>\n",
              "      <td>0.741886</td>\n",
              "      <td>0.802676</td>\n",
              "      <td>0.689655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_lstm</th>\n",
              "      <td>76.640420</td>\n",
              "      <td>0.724458</td>\n",
              "      <td>0.785235</td>\n",
              "      <td>0.672414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_gru</th>\n",
              "      <td>77.821522</td>\n",
              "      <td>0.744327</td>\n",
              "      <td>0.785942</td>\n",
              "      <td>0.706897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>75.984252</td>\n",
              "      <td>0.740426</td>\n",
              "      <td>0.731092</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1d</th>\n",
              "      <td>74.803150</td>\n",
              "      <td>0.709091</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.672414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_use_encoder</th>\n",
              "      <td>79.002625</td>\n",
              "      <td>0.758308</td>\n",
              "      <td>0.799363</td>\n",
              "      <td>0.721264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
              "      <td>77.690289</td>\n",
              "      <td>0.737654</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.686782</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Accuracy:  F1_Score:   Precision:   Recall: \n",
              "0_baseline                       79.265092    0.734007     0.886179  0.626437\n",
              "1_simple_dense                   78.083990    0.741886     0.802676  0.689655\n",
              "2_lstm                           76.640420    0.724458     0.785235  0.672414\n",
              "3_gru                            77.821522    0.744327     0.785942  0.706897\n",
              "4_bidirectional                  75.984252    0.740426     0.731092  0.750000\n",
              "5_conv1d                         74.803150    0.709091     0.750000  0.672414\n",
              "6_tf_hub_use_encoder             79.002625    0.758308     0.799363  0.721264\n",
              "7_tf_hub_use_encoder_10_percent  77.690289    0.737654     0.796667  0.686782"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "vzgE1iuZ_dBQ",
        "outputId": "606a7a12-e499-4c7b-bf9e-62d88a2445ed"
      },
      "source": [
        "# Reduce the accuracy to the same scale as other metrics \n",
        "all_model_results['Accuracy:'] = all_model_results['Accuracy:'] / 100\n",
        "all_model_results"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy:</th>\n",
              "      <th>F1_Score:</th>\n",
              "      <th>Precision:</th>\n",
              "      <th>Recall:</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.734007</td>\n",
              "      <td>0.886179</td>\n",
              "      <td>0.626437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>0.780840</td>\n",
              "      <td>0.741886</td>\n",
              "      <td>0.802676</td>\n",
              "      <td>0.689655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_lstm</th>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.724458</td>\n",
              "      <td>0.785235</td>\n",
              "      <td>0.672414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_gru</th>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.744327</td>\n",
              "      <td>0.785942</td>\n",
              "      <td>0.706897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.740426</td>\n",
              "      <td>0.731092</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1d</th>\n",
              "      <td>0.748031</td>\n",
              "      <td>0.709091</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.672414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_use_encoder</th>\n",
              "      <td>0.790026</td>\n",
              "      <td>0.758308</td>\n",
              "      <td>0.799363</td>\n",
              "      <td>0.721264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
              "      <td>0.776903</td>\n",
              "      <td>0.737654</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.686782</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Accuracy:  F1_Score:   Precision:   Recall: \n",
              "0_baseline                        0.792651    0.734007     0.886179  0.626437\n",
              "1_simple_dense                    0.780840    0.741886     0.802676  0.689655\n",
              "2_lstm                            0.766404    0.724458     0.785235  0.672414\n",
              "3_gru                             0.778215    0.744327     0.785942  0.706897\n",
              "4_bidirectional                   0.759843    0.740426     0.731092  0.750000\n",
              "5_conv1d                          0.748031    0.709091     0.750000  0.672414\n",
              "6_tf_hub_use_encoder              0.790026    0.758308     0.799363  0.721264\n",
              "7_tf_hub_use_encoder_10_percent   0.776903    0.737654     0.796667  0.686782"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "Z09_s-9gAp8K",
        "outputId": "f2584efc-5797-4d13-e9d2-45fcac6ffe74"
      },
      "source": [
        "# Plot and compare all of the model results \n",
        "all_model_results.plot(kind = 'bar' , figsize = (10 , 7)).legend(bbox_to_anchor = (1.0 , 1.0))\n"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f350d285e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "ZnhpI6-SBLXc",
        "outputId": "5819f669-8f9c-4499-abbc-45d9093d615e"
      },
      "source": [
        "# Sort models results by f1-scores \n",
        "all_model_results.sort_values('F1_Score: ' , ascending = False)['F1_Score: '].plot(kind = 'barh' , figsize = (10 , 7))\n"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f350d2aad50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5shYhSpddQD"
      },
      "source": [
        "### Uploading our model training logs to TensorBoard.dev\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVtljrntd_Ha"
      },
      "source": [
        "# View TenosrBoard logs of transfer learning modelling experiments (plus all of our other models)\n",
        "# Upload TensorBoard dev records \n",
        "!tensorboard dev upload --logdir ./model_logs/ \\\n",
        "  --name 'NLP Modelling Experiments' \\\n",
        "  --description 'Comparing multiple different types of model architecture on the Kaggle disaster tweet classification' \\\n",
        "  --one_shot # Exit the upload once uploading is finished"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZujZ_1SIg5Si"
      },
      "source": [
        "The TensorBoard is live here ---> https://tensorboard.dev/experiment/aPF2BVNJRwq0aMCkCMxUog/#scalars"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsdIScl-hTLU"
      },
      "source": [
        "# If you need to delete an experiment from TensorBoard, you can run the following\n",
        "# !tensorboard dev list # Gives list of all experiments \n",
        "\n",
        "# To delete the experiment \n",
        "#!tensorboard dev delete --experiment_id"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2Nid9mgiHfB"
      },
      "source": [
        "## Saving and loading a trained model \n",
        "\n",
        "There are two main formats to save a model in TensorFlow: \n",
        "1. The HDF5 Format. \n",
        "2. The `SaveModel` format (this is the default when using TensorFlow) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juRHkxgay1g4",
        "outputId": "63b64b0c-2184-431c-eabf-40db97cde402",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Our best performing model \n",
        "model_6_results"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 79.00262467191601,\n",
              " 'F1_Score: ': 0.7583081570996978,\n",
              " 'Precision: ': 0.7993630573248408,\n",
              " 'Recall: ': 0.7212643678160919}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqnYC39Jy5AX"
      },
      "source": [
        "# Save TF Hub sentence encoder model to HDF5 format \n",
        "model_6.save('model_6.h5')"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq9e1R96zGAK"
      },
      "source": [
        "# Load model with custom Hub Layer (required HDF5 format)\n",
        "import tensorflow_hub as hub\n",
        "loaded_model_6 = tf.keras.models.load_model('model_6.h5' , \n",
        "                                            custom_objects = {'KerasLayer': hub.KerasLayer})"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gugwB960NFV",
        "outputId": "01cc651e-d304-425a-b401-8a2257a1b7f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# How does our loaded model perform?\n",
        "loaded_model_6.evaluate(val_sentences , val_labels)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4972 - accuracy: 0.7900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4972369074821472, 0.7900262475013733]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbQIZp4f0ZXS",
        "outputId": "3b8146bb-6977-4b12-c621-8cf35a6ae8e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the accuracy value (there will little changes due to precision in computing)\n",
        "model_6_results"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy:': 79.00262467191601,\n",
              " 'F1_Score: ': 0.7583081570996978,\n",
              " 'Precision: ': 0.7993630573248408,\n",
              " 'Recall: ': 0.7212643678160919}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik0v06u60dAb"
      },
      "source": [
        "Now let's save to the `SaveModel` format. \n",
        "\n",
        "Check this for more information: https://www.tensorflow.org/tutorials/keras/save_and_load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4_Q_wer0qM_",
        "outputId": "90b5d92e-8219-40c8-8974-3e2aba610c42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Save TF Hub Sentence Encoder model to SaveModel format (default)\n",
        "model_6.save('model_6_SaveModel_format') # no extension "
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_Layer_input with unsupported characters which will be renamed to use_layer_input in the SavedModel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SaveModel_format/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SaveModel_format/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "golBxX410zob"
      },
      "source": [
        "# Load in a model from the SavedModel format \n",
        "loaded_model_6_SaveModel_format = tf.keras.models.load_model('model_6_SaveModel_format/')"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O5lUKn91Nzd",
        "outputId": "f1dcd105-e57c-44e3-982c-88a7d170ff6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate model on SaveModel format \n",
        "loaded_model_6_SaveModel_format.evaluate(val_sentences , val_labels)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4972 - accuracy: 0.7900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4972369074821472, 0.7900262475013733]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0g1wX7o1sTo"
      },
      "source": [
        "To download files from google colab workspace \n",
        "\n",
        "```\n",
        "from google.colab import files \n",
        "files.download('example.txt')\n",
        "```\n",
        "\n",
        "https://stackoverflow.com/questions/48774285/how-to-download-file-created-in-colaboratory-workspace#:~:text=Click%20on%20%3E%20icon.,you%20are%20good%20to%20go."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scU-5Ocv2AJm",
        "outputId": "aab9de99-8445-4cfa-a7ab-1311bdb9b5a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Checking the summary \n",
        "loaded_model_6_SaveModel_format.summary()"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE_Layer (KerasLayer)       (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 256,798,337\n",
            "Trainable params: 513\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnWyYEAd2PV7"
      },
      "source": [
        "## Finding the most wrong examples \n",
        "\n",
        "Since we are working on a Binary Classification problem it's obvious our prediction probs are going to between 0 and 1. \n",
        "\n",
        "However just because we are using a `sigmoid` activation function, the classes our model is predicting on the negative class (disaster tweets) are going to very close to 0 and for the positive class (not disaster tweets) are going to be very close 1. \n",
        "\n",
        "- If our best model still isn't perfect, what example is it getting wrong? \n",
        "- And of these wrong examples which ones is it getting *most* wrong (those will prediction probabilities closest to the opposite class)\n",
        "\n",
        "For example if a sample should have label of 0 but our model predicts a prediction prob of 0.999 (which is close to 1) and vice versa. \n",
        "\n",
        "And what we are doing here is called **Model Driven Data Exploration** that is we are using our model to know about our data better. Also called as Active Learning. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y-43AP434c1",
        "outputId": "03147204-aa7f-4179-9a7a-6f4d59551395",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Download a pretrained model from Google storage. \n",
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
        "!unzip 08_model_6_USE_feature_extractor.zip"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-06 05:51:48--  https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.202.128, 74.125.20.128, 74.125.142.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.202.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 960779165 (916M) [application/zip]\n",
            "Saving to: ‘08_model_6_USE_feature_extractor.zip’\n",
            "\n",
            "08_model_6_USE_feat 100%[===================>] 916.27M   255MB/s    in 3.7s    \n",
            "\n",
            "2021-06-06 05:51:52 (248 MB/s) - ‘08_model_6_USE_feature_extractor.zip’ saved [960779165/960779165]\n",
            "\n",
            "Archive:  08_model_6_USE_feature_extractor.zip\n",
            "   creating: 08_model_6_USE_feature_extractor/\n",
            "   creating: 08_model_6_USE_feature_extractor/assets/\n",
            "   creating: 08_model_6_USE_feature_extractor/variables/\n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.data-00000-of-00001  \n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.index  \n",
            "  inflating: 08_model_6_USE_feature_extractor/saved_model.pb  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXQKcWSm4ak0",
        "outputId": "c46a3155-04ef-43e9-9d29-0e061c8007a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Import previously trained model from Google Storage \n",
        "model_6_pretrained = tf.keras.models.load_model('08_model_6_USE_feature_extractor/')\n",
        "model_6_pretrained.evaluate(val_sentences , val_labels)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4272 - accuracy: 0.8163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42723122239112854, 0.8162729740142822]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9wYPtoa4qwT",
        "outputId": "17530c91-fca7-409a-9a16-87c98e2dc51d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Make predictions with the loaded model from GS \n",
        "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
        "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
        "model_6_pretrained_preds[:10] # should be in label format"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEnhCFZc2XI7",
        "outputId": "30317484-51cc-46f1-d668-6f7fd1b332af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Create a DataFrame with validation sentences and best performing model predictions labels + probabilities\n",
        "\n",
        "val_df = pd.DataFrame({'text': val_sentences ,\n",
        "                       'targets': val_labels , \n",
        "                       'pred': model_6_pretrained_preds , \n",
        "                       'pred_prob': tf.squeeze(model_6_pretrained_pred_probs)})\n",
        "val_df.head()"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>targets</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.747162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.196229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.707808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  targets  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...        0   0.0   0.159757\n",
              "1  FedEx no longer to transport bioterror germs i...        0   1.0   0.747162\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...        1   1.0   0.988749\n",
              "3  @camilacabello97 Internally and externally scr...        1   0.0   0.196229\n",
              "4  Radiation emergency #preparedness starts with ...        1   1.0   0.707808"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPMdudDq5VJa",
        "outputId": "7f00ff3a-be4e-420d-c238-b317a30c1178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities \n",
        "# Comparing our target labels and pred labels\n",
        "most_wrong = val_df[val_df['targets'] != val_df['pred']].sort_values('pred_prob' , ascending = False)\n",
        "\n",
        "most_wrong[:10] # These are False Positives"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>targets</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.876982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.835454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.827213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.814816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.810840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.803122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>@freefromwolves GodsLove &amp;amp; #thankU brother...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>Air Group is here to the rescue! We have 24/7 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  ...  pred_prob\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...  ...   0.910196\n",
              "759  FedEx will no longer transport bioterror patho...  ...   0.876982\n",
              "628  @noah_anyname That's where the concentration c...  ...   0.852300\n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...  ...   0.835454\n",
              "251  @AshGhebranious civil rights continued in the ...  ...   0.827213\n",
              "393  @SonofLiberty357 all illuminated by the bright...  ...   0.814816\n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...  ...   0.810840\n",
              "49   @madonnamking RSPCA site multiple 7 story high...  ...   0.803122\n",
              "119  @freefromwolves GodsLove &amp; #thankU brother...  ...   0.766901\n",
              "344  Air Group is here to the rescue! We have 24/7 ...  ...   0.766625\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVGSljzK6MMj"
      },
      "source": [
        "This happens because we are using `sigmoid` activation function, so that if our prediction prob is over **0.5** it will predict the label as 1.\n",
        "\n",
        "Let's remind ourselves of the target labels....\n",
        "\n",
        "* `0` --> not disaster\n",
        "* `1` --> disaster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYfKKCB87FTZ",
        "outputId": "c1151c9d-0d7b-4f57-bfbb-22090679e1e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# These are False Negatives\n",
        "most_wrong.tail()"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>targets</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>I get to smoke my shit in peace</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Why are you deluged with low self-image? Take ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  ...  pred_prob\n",
              "411  @SoonerMagic_ I mean I'm a fan but I don't nee...  ...   0.043918\n",
              "233                    I get to smoke my shit in peace  ...   0.042087\n",
              "38   Why are you deluged with low self-image? Take ...  ...   0.038998\n",
              "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...  ...   0.038949\n",
              "23   Ron &amp; Fez - Dave's High School Crush https...  ...   0.037186\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DImKNqrY7I7t",
        "outputId": "7dde5a14-8993-4ff7-f779-e0112ed3493e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the false positives (model predicted 1 when should've been 0) \n",
        "for row in most_wrong[:10].itertuples():\n",
        "  _ , text , target , pred , pred_prob = row \n",
        "  print(f'Target: {target}, Pred: {pred} , Prob: {pred_prob}')\n",
        "  print(f'Text:\\n{text}\\n')\n",
        "  print('----\\n')"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 0, Pred: 1.0 , Prob: 0.9101957678794861\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0 , Prob: 0.8769820928573608\n",
            "Text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0 , Prob: 0.8523000478744507\n",
            "Text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0 , Prob: 0.8354544043540955\n",
            "Text:\n",
            "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0 , Prob: 0.8272132873535156\n",
            "Text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0 , Prob: 0.814815878868103\n",
            "Text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0 , Prob: 0.8108396530151367\n",
            "Text:\n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0 , Prob: 0.80312180519104\n",
            "Text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0 , Prob: 0.7669008374214172\n",
            "Text:\n",
            "@freefromwolves GodsLove &amp; #thankU brother Danny for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0 , Prob: 0.766625165939331\n",
            "Text:\n",
            "Air Group is here to the rescue! We have 24/7 Emergency Service! Learn more about it here - http://t.co/9lyx7zMtHE http://t.co/5PbC96rTMJ\n",
            "\n",
            "----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijdQAD_D7Ve-",
        "outputId": "510c4fb5-9c8d-4381-f646-8f6db51ad8c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the False Negatives (model predicted 0 when should've been 1)\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "  _ , text , target , pred , pred_prob = row \n",
        "  print(f'Target: {target}, Pred: {pred} , Prob: {pred_prob}')\n",
        "  print(f'Text:\\n{text}\\n')\n",
        "  print('----\\n')"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 1, Pred: 0.0 , Prob: 0.06730346381664276\n",
            "Text:\n",
            "@DavidVonderhaar At least you were sincere ??\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0 , Prob: 0.055075809359550476\n",
            "Text:\n",
            "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0 , Prob: 0.05460337549448013\n",
            "Text:\n",
            "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0 , Prob: 0.054597001522779465\n",
            "Text:\n",
            "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0 , Prob: 0.04963728412985802\n",
            "Text:\n",
            "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0 , Prob: 0.043918490409851074\n",
            "Text:\n",
            "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0 , Prob: 0.04208686202764511\n",
            "Text:\n",
            "I get to smoke my shit in peace\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0 , Prob: 0.03899793699383736\n",
            "Text:\n",
            "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0 , Prob: 0.038949452340602875\n",
            "Text:\n",
            "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0 , Prob: 0.037185799330472946\n",
            "Text:\n",
            "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
            "\n",
            "----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maIMz51NLgUk"
      },
      "source": [
        "## Making predictions on the test dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttMfBLAJLs5N",
        "outputId": "bf30a7ff-abcc-4947-d0a0-4a91cd13d201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Our test dataframe \n",
        "test_df.head()"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G64zt5JPKvxv",
        "outputId": "97f7ff52-c44f-491d-910c-3e10e12bb42a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_sentences = test_df['text']\n",
        "test_sentences = test_sentences.to_list()\n",
        "len(test_sentences) , len(val_sentences)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3263, 762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDkfn5tPLOT4",
        "outputId": "b1b62042-d9ca-4219-ea80-7b282b0eb100",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Getting the pred probs\n",
        "test_pred_probs = model_6_pretrained.predict(test_sentences)\n",
        "\n",
        "# Converting them into labels of predictions \n",
        "test_preds = tf.squeeze(tf.round(test_pred_probs))\n",
        "test_preds[:10]"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 0., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZoA_Zw5L7z5",
        "outputId": "a1a56772-b52e-45cf-a5c5-e8e668e3fb7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pd.Series(test_preds).value_counts()"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    2049\n",
              "1.0    1214\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YpXs9TzMM_w",
        "outputId": "3d764962-a14f-4d29-9395-9cce57122c15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Building a dataframe with our test sentences with preds aside \n",
        "\n",
        "test_df_performance = pd.DataFrame({'text': test_sentences , \n",
        "                                    'pred_probs': tf.squeeze(test_pred_probs) , \n",
        "                                    'preds': test_preds})\n",
        "test_df_performance.head()"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>pred_probs</th>\n",
              "      <th>preds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "      <td>0.519970</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "      <td>0.875251</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "      <td>0.827833</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "      <td>0.933507</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "      <td>0.967958</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  pred_probs  preds\n",
              "0                 Just happened a terrible car crash    0.519970    1.0\n",
              "1  Heard about #earthquake is different cities, s...    0.875251    1.0\n",
              "2  there is a forest fire at spot pond, geese are...    0.827833    1.0\n",
              "3           Apocalypse lighting. #Spokane #wildfires    0.933507    1.0\n",
              "4      Typhoon Soudelor kills 28 in China and Taiwan    0.967958    1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y_uYYvaM4KB",
        "outputId": "4f452278-4d7d-4b44-99e1-89df120c292c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Visualizing by tweet and their preds / pred_probs \n",
        "test_samples = random.sample(test_sentences , 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6_pretrained.predict([test_sample]))\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f'Pred: {int(pred)} , Prob: {pred_prob}')\n",
        "  print(f'Text:\\n{test_sample}\\n')\n",
        "  print(f'------\\n')"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred: 1 , Prob: 0.9806947708129883\n",
            "Text:\n",
            "Aya KanoÛªs family has taken two nuclear hits: First #Hiroshima. Then #Fukushima. http://t.co/kcx9w2EJ8A http://t.co/aC50jw3Xmw\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 0 , Prob: 0.07694442570209503\n",
            "Text:\n",
            "Economic Wisdom ÛÒ Great Economists Demolish Establishment Nonsense http://t.co/H8NKtqU5O9 The Case for #Logic and #Reason\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 0 , Prob: 0.2263944298028946\n",
            "Text:\n",
            "A new favorite: Hardwell &amp; Dannic - Survivors (Remake) [FLP Family] by @FLP_Family https://t.co/yGVMztP1rt on #SoundCloud\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 1 , Prob: 0.9593697190284729\n",
            "Text:\n",
            "One Year After Massacre IraqÛªs Yazidis a Broken People http://t.co/pHqK28doni\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 1 , Prob: 0.9491786956787109\n",
            "Text:\n",
            "Striking views of Super Typhoon Soudelor as it tracks toward Taiwan China http://t.co/hsjp6Hoffe\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 1 , Prob: 0.6810218095779419\n",
            "Text:\n",
            "Is it time to hedge against catastrophic risks such as climate change asteroid impacts or bioterrorism? https://t.co/HQ6WqsgSJX\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 0 , Prob: 0.27308768033981323\n",
            "Text:\n",
            "Open forex detonation indicator is irretrievable after this fashion a financial airborne controls: SjFEb http://t.co/RzQkzM7rb8\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 0 , Prob: 0.09048875421285629\n",
            "Text:\n",
            "Listen to Apollo Brown - Detonate (feat. M.O.P.) by Mello Music Group #np on #SoundCloud https://t.co/C0Fex1XAlG\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 0 , Prob: 0.08317165076732635\n",
            "Text:\n",
            "Awful refereeing has ruined the balance of the game. Guy is a bloody mess #IMFC\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 1 , Prob: 0.9718626141548157\n",
            "Text:\n",
            "Photo: #NJTurnpike å_ NJ Turnpike Reopens Hours After Truck Fire In Linden; Driver Dead | NJ Turnpike... http://t.co/8SRT9rGaX7\n",
            "\n",
            "------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVvtNtvTNUUN"
      },
      "source": [
        "### Predicting on tweets from the wild \n",
        "\n",
        "Grabbing tweets from the wild and making our model to make predictions on it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IYp1jvCQZFJ"
      },
      "source": [
        "daniel_tweets = ['Fight your friends more often' , \n",
        "                 'ML/math tidbit that took me a long time to realise Why is \"X\" a capital and \"y\" not? • X (often features) is typically a matrix so the convention is to use an uppercase letter • y (often labels) is typically a vector so the convention is to use a lowercase letter' , \n",
        "                 'Friends, the latest issue of Machine Learning Monthly has been delivered with grace to your inboxes.' , \n",
        "                 'That guy at the gym who comes up to you and says \"wait til you get to my age\"',\n",
        "                 'Money describes wealth like words describe reality.' , \n",
        "                 'Closing all the extra tabs in your browser is the digital version of Friday afternoon' , \n",
        "                 'Been raining here. Haven’t seen the sun in ~3-4 days. Feel like I’m running on 73% energy.No sun messes with you']\n",
        "\n",
        "daniel_tweets_target = [0 , 0 , 0 , 0 , 0 , 0 , 0]\n"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7doT8OoQdwR",
        "outputId": "feff9eef-b630-4d1e-ec46-37ac35653e23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "daniel_tweets_pred_probs = model_6_pretrained.predict(daniel_tweets)\n",
        "daniel_tweets_preds = tf.squeeze(tf.round(daniel_tweets_pred_probs))\n",
        "\n",
        "daniel_tweets_preds"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(7,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8Qw6brnRvqI",
        "outputId": "ab5e2ad8-56c3-4237-a183-a229b5c0bdf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "# Creating a dataframe with tweets , targets , pred and pred_probs \n",
        "\n",
        "daniel_df = pd.DataFrame({'text': daniel_tweets , \n",
        "                          'target': daniel_tweets_target , \n",
        "                          'pred': daniel_tweets_preds , \n",
        "                          'pred_probs': tf.squeeze(daniel_tweets_pred_probs)})\n",
        "daniel_df"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_probs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fight your friends more often</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.031134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ML/math tidbit that took me a long time to rea...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.082705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Friends, the latest issue of Machine Learning ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>That guy at the gym who comes up to you and sa...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.026416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Money describes wealth like words describe rea...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.057142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Closing all the extra tabs in your browser is ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.082519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Been raining here. Haven’t seen the sun in ~3-...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.312030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target  pred  pred_probs\n",
              "0                      Fight your friends more often       0   0.0    0.031134\n",
              "1  ML/math tidbit that took me a long time to rea...       0   0.0    0.082705\n",
              "2  Friends, the latest issue of Machine Learning ...       0   0.0    0.043992\n",
              "3  That guy at the gym who comes up to you and sa...       0   0.0    0.026416\n",
              "4  Money describes wealth like words describe rea...       0   0.0    0.057142\n",
              "5  Closing all the extra tabs in your browser is ...       0   0.0    0.082519\n",
              "6  Been raining here. Haven’t seen the sun in ~3-...       0   0.0    0.312030"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2dUCY0IUMkq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}